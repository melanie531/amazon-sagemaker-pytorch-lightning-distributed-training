{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0cd07d0",
   "metadata": {},
   "source": [
    "# Train Sementic Segmentation model using Pytorch Lightning on Amazon SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1f7e0f",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This notebook will demonstrate how you can train a semantic segmentation model by using custom training script with Pytorch lightning, similar to those you would use outside of SageMaker, with SageMaker's prebuilt containers for various frameworks.\n",
    "\n",
    "SageMaker Script Mode is flexible so you'll also be seeing examples of how to include your own dependencies, such as a custom Python library, in your training and inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97947bf6",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "To follow along, you need to create an IAM role, SageMaker Notebook instance, and S3 bucket. \n",
    "Once the SageMaker Notebook instance is created, choose conda_python3 as the kernel.\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0328dcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import subprocess\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import os\n",
    "import boto3\n",
    "import numpy as np\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.s3 import S3Uploader, s3_path_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "842c89c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (2.103.0)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: attrs<22,>=20.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from sagemaker) (21.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from sagemaker) (21.3)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from sagemaker) (1.3.4)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from sagemaker) (1.21.2)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from sagemaker) (4.8.2)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from sagemaker) (0.2.8)\n",
      "Requirement already satisfied: boto3<2.0,>=1.20.21 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from sagemaker) (1.24.42)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from sagemaker) (3.19.4)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.42 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from boto3<2.0,>=1.20.21->sagemaker) (1.27.51)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from boto3<2.0,>=1.20.21->sagemaker) (0.6.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from boto3<2.0,>=1.20.21->sagemaker) (0.10.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (3.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from packaging>=20.0->sagemaker) (3.0.6)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from pandas->sagemaker) (2021.3)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from pathos->sagemaker) (1.6.6.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.12 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from pathos->sagemaker) (0.70.12.2)\n",
      "Requirement already satisfied: pox>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.0)\n",
      "Requirement already satisfied: dill>=0.3.4 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from botocore<1.28.0,>=1.27.42->boto3<2.0,>=1.20.21->sagemaker) (1.26.8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p38/bin/python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# SageMaker Python SDK version 2.x is required\n",
    "original_version = sagemaker.__version__\n",
    "if sagemaker.__version__ != \"2.103.1\":\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"sagemaker\"])\n",
    "    import importlib\n",
    "\n",
    "    importlib.reload(sagemaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0aeae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip this step if you have already downloaded and unzipped the data\n",
    "!wget https://s3.eu-central-1.amazonaws.com/avg-kitti/data_semantics.zip\n",
    "!unzip data_semantics.zip -d data_semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4311d119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redirecting to /bin/systemctl stop docker.service\n",
      "Warning: Stopping docker.service, but it can still be activated by:\n",
      "  docker.socket\n",
      "Redirecting to /bin/systemctl start docker.service\n"
     ]
    }
   ],
   "source": [
    "# only run the below cells when you are using sagemaker notebook instances\n",
    "!bash ./prepare-docker.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e928c689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvidia-docker2 already installed. We are good to go!\n",
      "SageMaker instance route table setup is ok. We are good to go.\n",
      "SageMaker instance routing for Docker is ok. We are good to go!\n"
     ]
    }
   ],
   "source": [
    "!wget -q https://raw.githubusercontent.com/aws-samples/amazon-sagemaker-script-mode/master/local_mode_setup.sh\n",
    "!/bin/bash ./local_mode_setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98993876",
   "metadata": {},
   "source": [
    "### define parameters and upload files to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1ca7b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_session = sagemaker.session.Session()\n",
    "bucket = sm_session.default_bucket()\n",
    "prefix = 'sagemaker/pytorch-lightning-example'\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2651ab0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading data to s3://sagemaker-us-east-1-631450739534/sagemaker/pytorch-lightning-example/data\n"
     ]
    }
   ],
   "source": [
    "data_path = s3_path_join(\"s3://\", bucket, prefix + \"/data\")\n",
    "print(f\"Uploading data to {data_path}\")\n",
    "data_url = S3Uploader.upload('data_semantics', data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa4d136b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-631450739534/sagemaker/pytorch-lightning-example/data'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_url #= 's3://sagemaker-us-east-1-631450739534/sagemaker/pytorch-lightning-example/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c9baf7",
   "metadata": {},
   "source": [
    "## PyTorch\n",
    "In this PyTorch example, we show how to using pytorch lightning to train a semantic segmentation model with multiple gpus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50f1b48f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 5jfl2hnhwa-algo-1-5y4z8 ... \n",
      "Creating 5jfl2hnhwa-algo-1-5y4z8 ... done\n",
      "Attaching to 5jfl2hnhwa-algo-1-5y4z8\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m 2022-08-16 02:49:20,901 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m 2022-08-16 02:49:20,977 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m 2022-08-16 02:49:20,978 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m 2022-08-16 02:49:20,981 sagemaker_pytorch_container.training INFO     Pytorch_ddp_enabled is:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m 2022-08-16 02:49:20,981 sagemaker_pytorch_container.training INFO     True\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m 2022-08-16 02:49:20,982 sagemaker_pytorch_container.training INFO     Invoking SMDataParallel for native PT DDP job\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m 2022-08-16 02:49:20,982 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m 2022-08-16 02:49:21,209 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m /opt/conda/bin/python3.8 -m pip install -r requirements.txt\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.12.0+cu113)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: torchvision in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (0.13.0+cu113)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (1.6.3)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch->-r requirements.txt (line 1)) (4.3.0)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from torchvision->-r requirements.txt (line 2)) (2.28.1)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from torchvision->-r requirements.txt (line 2)) (1.22.2)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.8/site-packages (from torchvision->-r requirements.txt (line 2)) (9.2.0)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: pyDeprecate<0.4.0,>=0.3.1 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning->-r requirements.txt (line 3)) (0.3.2)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: torchmetrics>=0.4.1 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning->-r requirements.txt (line 3)) (0.9.3)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning->-r requirements.txt (line 3)) (5.4.1)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning->-r requirements.txt (line 3)) (2022.5.0)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning->-r requirements.txt (line 3)) (21.3)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning->-r requirements.txt (line 3)) (4.64.0)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: tensorboard>=2.2.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning->-r requirements.txt (line 3)) (2.10.0)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: aiohttp in /opt/conda/lib/python3.8/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->-r requirements.txt (line 3)) (3.8.1)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=17.0->pytorch-lightning->-r requirements.txt (line 3)) (3.0.9)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (2.10.0)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (1.47.0)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (1.2.0)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (0.4.6)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (3.4.1)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (63.2.0)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (1.8.1)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (2.1.2)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (0.37.1)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (0.6.1)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (3.19.4)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision->-r requirements.txt (line 2)) (1.26.10)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision->-r requirements.txt (line 2)) (3.3)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision->-r requirements.txt (line 2)) (2.1.0)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision->-r requirements.txt (line 2)) (2022.6.15)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (1.16.0)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (5.2.0)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (4.7.2)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (0.2.8)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (1.3.1)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (4.12.0)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->-r requirements.txt (line 3)) (1.3.1)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->-r requirements.txt (line 3)) (4.0.2)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->-r requirements.txt (line 3)) (1.2.0)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->-r requirements.txt (line 3)) (1.8.1)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->-r requirements.txt (line 3)) (21.4.0)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->-r requirements.txt (line 3)) (6.0.2)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (3.8.1)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (0.4.8)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (3.2.0)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [notice] A new release of pip available: 22.2 -> 22.2.2\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [notice] To update, run: pip install --upgrade pip\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m 2022-08-16 02:49:23,143 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m 2022-08-16 02:49:23,143 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m 2022-08-16 02:49:23,225 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m 2022-08-16 02:49:23,304 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m 2022-08-16 02:49:23,305 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m 2022-08-16 02:49:23,305 sagemaker-training-toolkit INFO     Creating SSH daemon.\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m 2022-08-16 02:49:23,309 sagemaker-training-toolkit INFO     Waiting for MPI workers to establish their SSH connections\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m 2022-08-16 02:49:23,310 sagemaker-training-toolkit INFO     Network interface name: eth0\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m 2022-08-16 02:49:23,310 sagemaker-training-toolkit INFO     Host: ['algo-1-5y4z8']\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m 2022-08-16 02:49:23,311 sagemaker-training-toolkit INFO     instance type: local_gpu\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m 2022-08-16 02:49:23,311 sagemaker-training-toolkit INFO     Env Hosts: ['algo-1-5y4z8'] Hosts: ['algo-1-5y4z8'] process_per_hosts: 8 num_processes: 8\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m 2022-08-16 02:49:23,386 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m 2022-08-16 02:49:23,386 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m \n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Training Env:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m \n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m {\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     \"additional_framework_parameters\": {\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m         \"sagemaker_pytorch_ddp_enabled\": true,\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m         \"sagemaker_instance_type\": \"local_gpu\"\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     },\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m         \"data_path\": \"/opt/ml/input/data/data_path\"\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     },\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     \"current_host\": \"algo-1-5y4z8\",\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     \"current_instance_group\": \"homogeneousCluster\",\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     \"current_instance_group_hosts\": [],\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     \"current_instance_type\": \"local\",\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     \"distribution_hosts\": [\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m         \"algo-1-5y4z8\"\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     ],\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     \"distribution_instance_groups\": [\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m         \"homogeneousCluster\"\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     ],\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     \"hosts\": [\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m         \"algo-1-5y4z8\"\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     ],\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m         \"batch_size\": 8\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     },\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m         \"data_path\": {\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m         }\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     },\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     \"instance_groups\": [],\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     \"instance_groups_dict\": {},\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     \"is_hetero\": false,\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     \"is_modelparallel_enabled\": null,\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     \"job_name\": \"pytorch-lightning-2022-08-16-02-49-17-400\",\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     \"master_hostname\": \"algo-1-5y4z8\",\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-631450739534/pytorch-lightning-2022-08-16-02-49-17-400/source/sourcedir.tar.gz\",\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     \"module_name\": \"semantic_segmentation_single\",\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     \"num_cpus\": 64,\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     \"num_gpus\": 8,\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m         \"current_host\": \"algo-1-5y4z8\",\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m         \"hosts\": [\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m             \"algo-1-5y4z8\"\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m         ]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     },\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m     \"user_entry_point\": \"semantic_segmentation_single.py\"\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m }\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m \n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Environment variables:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m \n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m SM_HOSTS=[\"algo-1-5y4z8\"]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m SM_HPS={\"batch_size\":8}\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m SM_USER_ENTRY_POINT=semantic_segmentation_single.py\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m SM_FRAMEWORK_PARAMS={\"sagemaker_instance_type\":\"local_gpu\",\"sagemaker_pytorch_ddp_enabled\":true}\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-5y4z8\",\"hosts\":[\"algo-1-5y4z8\"]}\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m SM_INPUT_DATA_CONFIG={\"data_path\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m SM_CHANNELS=[\"data_path\"]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m SM_CURRENT_HOST=algo-1-5y4z8\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m SM_CURRENT_INSTANCE_TYPE=local\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m SM_CURRENT_INSTANCE_GROUP_HOSTS=[]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m SM_INSTANCE_GROUPS=[]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m SM_INSTANCE_GROUPS_DICT={}\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m SM_DISTRIBUTION_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m SM_IS_HETERO=false\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m SM_MODULE_NAME=semantic_segmentation_single\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m SM_NUM_CPUS=64\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m SM_NUM_GPUS=8\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-631450739534/pytorch-lightning-2022-08-16-02-49-17-400/source/sourcedir.tar.gz\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_instance_type\":\"local_gpu\",\"sagemaker_pytorch_ddp_enabled\":true},\"channel_input_dirs\":{\"data_path\":\"/opt/ml/input/data/data_path\"},\"current_host\":\"algo-1-5y4z8\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[],\"current_instance_type\":\"local\",\"distribution_hosts\":[\"algo-1-5y4z8\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-5y4z8\"],\"hyperparameters\":{\"batch_size\":8},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"data_path\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[],\"instance_groups_dict\":{},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"pytorch-lightning-2022-08-16-02-49-17-400\",\"log_level\":20,\"master_hostname\":\"algo-1-5y4z8\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-631450739534/pytorch-lightning-2022-08-16-02-49-17-400/source/sourcedir.tar.gz\",\"module_name\":\"semantic_segmentation_single\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-5y4z8\",\"hosts\":[\"algo-1-5y4z8\"]},\"user_entry_point\":\"semantic_segmentation_single.py\"}\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m SM_USER_ARGS=[\"--batch_size\",\"8\"]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m SM_CHANNEL_DATA_PATH=/opt/ml/input/data/data_path\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m SM_HP_BATCH_SIZE=8\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m PYTHONPATH=/opt/ml/code:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220722-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m \n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m \n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m mpirun --host algo-1-5y4z8 -np 8 --allow-run-as-root --tag-output --oversubscribe -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -mca btl_vader_single_copy_mechanism none -mca plm_rsh_num_concurrent 1 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x SMDATAPARALLEL_USE_SINGLENODE=1 -x FI_PROVIDER=efa -x RDMAV_FORK_SAFE=1 -x LD_PRELOAD=/opt/conda/lib/python3.8/site-packages/gethostname.cpython-38-x86_64-linux-gnu.so smddprun /opt/conda/bin/python3.8 -m mpi4py semantic_segmentation_single.py --batch_size 8\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m \n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m \n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stderr>:Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/8\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stderr>:Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/8\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stderr>:Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/8\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stderr>:Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/8\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stderr>:Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/8\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stderr>:Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/8\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stderr>:Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/8\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stderr>:Using 16bit native Automatic Mixed Precision (AMP)\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stderr>:GPU available: True, used: True\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stderr>:TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stderr>:IPU available: False, using: 0 IPUs\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stderr>:HPU available: False, using: 0 HPUs\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stderr>:Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/8\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stderr>:----------------------------------------------------------------------------------------------------\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stderr>:distributed_backend=nccl\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stderr>:All distributed processes registered. Starting with 8 processes\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stderr>:----------------------------------------------------------------------------------------------------\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stderr>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stderr>:Missing logger folder: /opt/ml/code/lightning_logs\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stderr>:Missing logger folder: /opt/ml/code/lightning_logs\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stderr>:Missing logger folder: /opt/ml/code/lightning_logs\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stderr>:Missing logger folder: /opt/ml/code/lightning_logs\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stderr>:Missing logger folder: /opt/ml/code/lightning_logs\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stderr>:Missing logger folder: /opt/ml/code/lightning_logs\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stderr>:Missing logger folder: /opt/ml/code/lightning_logs\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stderr>:Missing logger folder: /opt/ml/code/lightning_logs\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:587 [0] NCCL INFO Bootstrap : Using eth0:172.18.0.2<0>\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:587 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:587 [0] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:587 [0] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:587 [0] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:587 [0] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:587 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:587 [0] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:587 [0] NCCL INFO Using network Socket\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:NCCL version 2.10.3+cuda11.3\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:134 [7] NCCL INFO Bootstrap : Using eth0:172.18.0.2<0>\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:134 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:134 [7] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:134 [7] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:131 [5] NCCL INFO Bootstrap : Using eth0:172.18.0.2<0>\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:131 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:131 [5] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:131 [5] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:134 [7] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:134 [7] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:134 [7] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:134 [7] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:134 [7] NCCL INFO Using network Socket\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:131 [5] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:131 [5] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:131 [5] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:133 [6] NCCL INFO Bootstrap : Using eth0:172.18.0.2<0>\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:131 [5] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:131 [5] NCCL INFO Using network Socket\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:133 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:133 [6] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:133 [6] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:124 [2] NCCL INFO Bootstrap : Using eth0:172.18.0.2<0>\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:129 [4] NCCL INFO Bootstrap : Using eth0:172.18.0.2<0>\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:121 [1] NCCL INFO Bootstrap : Using eth0:172.18.0.2<0>\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:124 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:124 [2] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:124 [2] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:129 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:129 [4] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:129 [4] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:121 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:121 [1] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:121 [1] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:133 [6] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:133 [6] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:133 [6] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:133 [6] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:133 [6] NCCL INFO Using network Socket\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:124 [2] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:124 [2] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:124 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:124 [2] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:124 [2] NCCL INFO Using network Socket\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:129 [4] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:129 [4] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:129 [4] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:121 [1] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:121 [1] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:129 [4] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:129 [4] NCCL INFO Using network Socket\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:121 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:121 [1] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:121 [1] NCCL INFO Using network Socket\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:127 [3] NCCL INFO Bootstrap : Using eth0:172.18.0.2<0>\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:127 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:127 [3] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:127 [3] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:127 [3] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:127 [3] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:127 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:127 [3] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:127 [3] NCCL INFO Using network Socket\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:740 [1] NCCL INFO Trees [0] 5/-1/-1->1->2 [1] 5/-1/-1->1->2 [2] 2/-1/-1->1->5 [3] 2/-1/-1->1->5 [4] 3/-1/-1->1->0 [5] -1/-1/-1->1->3 [6] 5/-1/-1->1->2 [7] 5/-1/-1->1->2 [8] 2/-1/-1->1->5 [9] 2/-1/-1->1->5 [10] 3/-1/-1->1->0 [11] -1/-1/-1->1->3\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:738 [2] NCCL INFO Trees [0] 1/-1/-1->2->3 [1] 1/-1/-1->2->3 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] -1/-1/-1->2->6 [5] 6/-1/-1->2->0 [6] 1/-1/-1->2->3 [7] 1/-1/-1->2->3 [8] 3/-1/-1->2->1 [9] 3/-1/-1->2->1 [10] -1/-1/-1->2->6 [11] 6/-1/-1->2->0\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:734 [0] NCCL INFO Channel 00/12 :    0   3   2   1   5   6   7   4\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:734 [0] NCCL INFO Channel 01/12 :    0   3   2   1   5   6   7   4\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:734 [0] NCCL INFO Channel 02/12 :    0   4   7   6   5   1   2   3\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:734 [0] NCCL INFO Channel 03/12 :    0   4   7   6   5   1   2   3\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:734 [0] NCCL INFO Channel 04/12 :    0   1   3   7   5   4   6   2\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:734 [0] NCCL INFO Channel 05/12 :    0   2   6   4   5   7   3   1\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:734 [0] NCCL INFO Channel 06/12 :    0   3   2   1   5   6   7   4\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:739 [4] NCCL INFO Trees [0] -1/-1/-1->4->7 [1] -1/-1/-1->4->7 [2] 7/-1/-1->4->0 [3] 7/-1/-1->4->0 [4] 6/-1/-1->4->5 [5] 5/-1/-1->4->6 [6] -1/-1/-1->4->7 [7] -1/-1/-1->4->7 [8] 7/-1/-1->4->0 [9] 7/-1/-1->4->0 [10] 6/-1/-1->4->5 [11] 5/-1/-1->4->6\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:741 [3] NCCL INFO Trees [0] 2/-1/-1->3->0 [1] 2/-1/-1->3->0 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] 7/-1/-1->3->1 [5] 1/-1/-1->3->7 [6] 2/-1/-1->3->0 [7] 2/-1/-1->3->0 [8] -1/-1/-1->3->2 [9] -1/-1/-1->3->2 [10] 7/-1/-1->3->1 [11] 1/-1/-1->3->7\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:734 [0] NCCL INFO Channel 07/12 :    0   3   2   1   5   6   7   4\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:734 [0] NCCL INFO Channel 08/12 :    0   4   7   6   5   1   2   3\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:734 [0] NCCL INFO Channel 09/12 :    0   4   7   6   5   1   2   3\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:737 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 5/-1/-1->6->7 [3] 5/-1/-1->6->7 [4] 2/-1/-1->6->4 [5] 4/-1/-1->6->2 [6] 7/-1/-1->6->5 [7] 7/-1/-1->6->5 [8] 5/-1/-1->6->7 [9] 5/-1/-1->6->7 [10] 2/-1/-1->6->4 [11] 4/-1/-1->6->2\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:735 [7] NCCL INFO Trees [0] 4/-1/-1->7->6 [1] 4/-1/-1->7->6 [2] 6/-1/-1->7->4 [3] 6/-1/-1->7->4 [4] 5/-1/-1->7->3 [5] 3/-1/-1->7->5 [6] 4/-1/-1->7->6 [7] 4/-1/-1->7->6 [8] 6/-1/-1->7->4 [9] 6/-1/-1->7->4 [10] 5/-1/-1->7->3 [11] 3/-1/-1->7->5\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:736 [5] NCCL INFO Trees [0] 6/-1/-1->5->1 [1] 6/-1/-1->5->1 [2] 1/-1/-1->5->6 [3] 1/-1/-1->5->6 [4] 4/-1/-1->5->7 [5] 7/-1/-1->5->4 [6] 6/-1/-1->5->1 [7] 6/-1/-1->5->1 [8] 1/-1/-1->5->6 [9] 1/-1/-1->5->6 [10] 4/-1/-1->5->7 [11] 7/-1/-1->5->4\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:734 [0] NCCL INFO Channel 10/12 :    0   1   3   7   5   4   6   2\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:734 [0] NCCL INFO Channel 11/12 :    0   2   6   4   5   7   3   1\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:734 [0] NCCL INFO Trees [0] 3/-1/-1->0->-1 [1] 3/-1/-1->0->-1 [2] 4/-1/-1->0->-1 [3] 4/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 3/-1/-1->0->-1 [7] 3/-1/-1->0->-1 [8] 4/-1/-1->0->-1 [9] 4/-1/-1->0->-1 [10] 1/-1/-1->0->-1 [11] 2/-1/-1->0->-1\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:739 [4] NCCL INFO Channel 05 : 4[1b0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:734 [0] NCCL INFO Channel 04 : 0[170] -> 1[180] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:739 [4] NCCL INFO Channel 11 : 4[1b0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:734 [0] NCCL INFO Channel 10 : 0[170] -> 1[180] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:740 [1] NCCL INFO Channel 02 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:736 [5] NCCL INFO Channel 00 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:740 [1] NCCL INFO Channel 03 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:736 [5] NCCL INFO Channel 01 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:738 [2] NCCL INFO Channel 02 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:740 [1] NCCL INFO Channel 08 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:738 [2] NCCL INFO Channel 03 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:737 [6] NCCL INFO Channel 00 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:736 [5] NCCL INFO Channel 06 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:740 [1] NCCL INFO Channel 09 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:736 [5] NCCL INFO Channel 07 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:738 [2] NCCL INFO Channel 08 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:737 [6] NCCL INFO Channel 01 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:738 [2] NCCL INFO Channel 09 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:737 [6] NCCL INFO Channel 06 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:734 [0] NCCL INFO Channel 05 : 0[170] -> 2[190] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:737 [6] NCCL INFO Channel 07 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:739 [4] NCCL INFO Channel 04 : 4[1b0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:734 [0] NCCL INFO Channel 11 : 0[170] -> 2[190] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:739 [4] NCCL INFO Channel 10 : 4[1b0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:740 [1] NCCL INFO Channel 04 : 1[180] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:736 [5] NCCL INFO Channel 05 : 5[1c0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:740 [1] NCCL INFO Channel 10 : 1[180] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:736 [5] NCCL INFO Channel 11 : 5[1c0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:734 [0] NCCL INFO Channel 00 : 0[170] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:739 [4] NCCL INFO Channel 02 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:734 [0] NCCL INFO Channel 01 : 0[170] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:739 [4] NCCL INFO Channel 03 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:738 [2] NCCL INFO Channel 05 : 2[190] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:734 [0] NCCL INFO Channel 06 : 0[170] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:737 [6] NCCL INFO Channel 04 : 6[1d0] -> 2[190] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:740 [1] NCCL INFO Channel 00 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:739 [4] NCCL INFO Channel 08 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:734 [0] NCCL INFO Channel 07 : 0[170] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:738 [2] NCCL INFO Channel 11 : 2[190] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:736 [5] NCCL INFO Channel 02 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:740 [1] NCCL INFO Channel 01 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:737 [6] NCCL INFO Channel 10 : 6[1d0] -> 2[190] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:739 [4] NCCL INFO Channel 09 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:736 [5] NCCL INFO Channel 03 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:740 [1] NCCL INFO Channel 06 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:736 [5] NCCL INFO Channel 08 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:740 [1] NCCL INFO Channel 07 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:736 [5] NCCL INFO Channel 09 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:738 [2] NCCL INFO Channel 04 : 2[190] -> 0[170] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:737 [6] NCCL INFO Channel 05 : 6[1d0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:738 [2] NCCL INFO Channel 10 : 2[190] -> 0[170] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:737 [6] NCCL INFO Channel 11 : 6[1d0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:741 [3] NCCL INFO Channel 04 : 3[1a0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:735 [7] NCCL INFO Channel 05 : 7[1e0] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:741 [3] NCCL INFO Channel 10 : 3[1a0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:734 [0] NCCL INFO Channel 02 : 0[170] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:735 [7] NCCL INFO Channel 11 : 7[1e0] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:734 [0] NCCL INFO Channel 03 : 0[170] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:739 [4] NCCL INFO Channel 00 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:739 [4] NCCL INFO Channel 01 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:734 [0] NCCL INFO Channel 08 : 0[170] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:739 [4] NCCL INFO Channel 06 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:734 [0] NCCL INFO Channel 09 : 0[170] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:741 [3] NCCL INFO Channel 02 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:735 [7] NCCL INFO Channel 00 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:739 [4] NCCL INFO Channel 07 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:741 [3] NCCL INFO Channel 03 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:735 [7] NCCL INFO Channel 01 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:741 [3] NCCL INFO Channel 08 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:735 [7] NCCL INFO Channel 06 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:741 [3] NCCL INFO Channel 09 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:735 [7] NCCL INFO Channel 07 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:741 [3] NCCL INFO Channel 05 : 3[1a0] -> 1[180] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:735 [7] NCCL INFO Channel 04 : 7[1e0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:741 [3] NCCL INFO Channel 11 : 3[1a0] -> 1[180] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:735 [7] NCCL INFO Channel 10 : 7[1e0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:741 [3] NCCL INFO Channel 00 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:735 [7] NCCL INFO Channel 02 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:741 [3] NCCL INFO Channel 01 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:735 [7] NCCL INFO Channel 03 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:741 [3] NCCL INFO Channel 06 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:735 [7] NCCL INFO Channel 08 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:741 [3] NCCL INFO Channel 07 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:735 [7] NCCL INFO Channel 09 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:738 [2] NCCL INFO Channel 00 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:740 [1] NCCL INFO Channel 05 : 1[180] -> 0[170] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:736 [5] NCCL INFO Channel 04 : 5[1c0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:737 [6] NCCL INFO Channel 02 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:738 [2] NCCL INFO Channel 01 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:736 [5] NCCL INFO Channel 10 : 5[1c0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:740 [1] NCCL INFO Channel 11 : 1[180] -> 0[170] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:737 [6] NCCL INFO Channel 03 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:738 [2] NCCL INFO Channel 06 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:737 [6] NCCL INFO Channel 08 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:738 [2] NCCL INFO Channel 07 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:739 [4] NCCL INFO Connected all rings\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:734 [0] NCCL INFO Connected all rings\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:737 [6] NCCL INFO Channel 09 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:739 [4] NCCL INFO Channel 04 : 4[1b0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:739 [4] NCCL INFO Channel 10 : 4[1b0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:741 [3] NCCL INFO Connected all rings\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:735 [7] NCCL INFO Connected all rings\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:740 [1] NCCL INFO Connected all rings\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:736 [5] NCCL INFO Connected all rings\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:740 [1] NCCL INFO Channel 00 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:738 [2] NCCL INFO Connected all rings\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:737 [6] NCCL INFO Connected all rings\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:740 [1] NCCL INFO Channel 01 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:740 [1] NCCL INFO Channel 06 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:736 [5] NCCL INFO Channel 02 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:740 [1] NCCL INFO Channel 07 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:736 [5] NCCL INFO Channel 03 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:736 [5] NCCL INFO Channel 08 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:738 [2] NCCL INFO Channel 00 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:736 [5] NCCL INFO Channel 09 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:737 [6] NCCL INFO Channel 02 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:738 [2] NCCL INFO Channel 01 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:737 [6] NCCL INFO Channel 03 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:738 [2] NCCL INFO Channel 06 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:737 [6] NCCL INFO Channel 08 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:739 [4] NCCL INFO Channel 05 : 4[1b0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:738 [2] NCCL INFO Channel 07 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:737 [6] NCCL INFO Channel 09 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:739 [4] NCCL INFO Channel 11 : 4[1b0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:740 [1] NCCL INFO Channel 05 : 1[180] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:740 [1] NCCL INFO Channel 11 : 1[180] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:736 [5] NCCL INFO Channel 04 : 5[1c0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:736 [5] NCCL INFO Channel 10 : 5[1c0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:738 [2] NCCL INFO Channel 04 : 2[190] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:741 [3] NCCL INFO Channel 05 : 3[1a0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:738 [2] NCCL INFO Channel 10 : 2[190] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:739 [4] NCCL INFO Channel 00 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:741 [3] NCCL INFO Channel 11 : 3[1a0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:739 [4] NCCL INFO Channel 01 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:740 [1] NCCL INFO Channel 02 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:737 [6] NCCL INFO Channel 05 : 6[1d0] -> 2[190] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:739 [4] NCCL INFO Channel 06 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:740 [1] NCCL INFO Channel 03 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:736 [5] NCCL INFO Channel 00 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:737 [6] NCCL INFO Channel 11 : 6[1d0] -> 2[190] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:739 [4] NCCL INFO Channel 07 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:740 [1] NCCL INFO Channel 08 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:736 [5] NCCL INFO Channel 01 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:740 [1] NCCL INFO Channel 09 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:736 [5] NCCL INFO Channel 06 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:736 [5] NCCL INFO Channel 07 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:737 [6] NCCL INFO Channel 04 : 6[1d0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:738 [2] NCCL INFO Channel 05 : 2[190] -> 0[170] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:739 [4] NCCL INFO Channel 02 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:737 [6] NCCL INFO Channel 10 : 6[1d0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:739 [4] NCCL INFO Channel 03 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:738 [2] NCCL INFO Channel 11 : 2[190] -> 0[170] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:735 [7] NCCL INFO Channel 04 : 7[1e0] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:739 [4] NCCL INFO Channel 08 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:739 [4] NCCL INFO Channel 09 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:735 [7] NCCL INFO Channel 10 : 7[1e0] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:735 [7] NCCL INFO Channel 02 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:741 [3] NCCL INFO Channel 00 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:735 [7] NCCL INFO Channel 03 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:741 [3] NCCL INFO Channel 01 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:735 [7] NCCL INFO Channel 08 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:741 [3] NCCL INFO Channel 06 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:735 [7] NCCL INFO Channel 09 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:741 [3] NCCL INFO Channel 07 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:735 [7] NCCL INFO Channel 05 : 7[1e0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:741 [3] NCCL INFO Channel 04 : 3[1a0] -> 1[180] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:735 [7] NCCL INFO Channel 11 : 7[1e0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:741 [3] NCCL INFO Channel 10 : 3[1a0] -> 1[180] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:735 [7] NCCL INFO Channel 00 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:741 [3] NCCL INFO Channel 02 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:735 [7] NCCL INFO Channel 01 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:741 [3] NCCL INFO Channel 03 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:735 [7] NCCL INFO Channel 06 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:741 [3] NCCL INFO Channel 08 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:735 [7] NCCL INFO Channel 07 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:741 [3] NCCL INFO Channel 09 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:737 [6] NCCL INFO Channel 00 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:736 [5] NCCL INFO Channel 05 : 5[1c0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:738 [2] NCCL INFO Channel 02 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:740 [1] NCCL INFO Channel 04 : 1[180] -> 0[170] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:737 [6] NCCL INFO Channel 01 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:736 [5] NCCL INFO Channel 11 : 5[1c0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:738 [2] NCCL INFO Channel 03 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:740 [1] NCCL INFO Channel 10 : 1[180] -> 0[170] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:737 [6] NCCL INFO Channel 06 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:738 [2] NCCL INFO Channel 08 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:739 [4] NCCL INFO Connected all trees\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:739 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:737 [6] NCCL INFO Channel 07 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:734 [0] NCCL INFO Connected all trees\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:738 [2] NCCL INFO Channel 09 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:734 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:739 [4] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:734 [0] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:735 [7] NCCL INFO Connected all trees\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:735 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:741 [3] NCCL INFO Connected all trees\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:741 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:736 [5] NCCL INFO Connected all trees\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:736 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:740 [1] NCCL INFO Connected all trees\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:740 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:737 [6] NCCL INFO Connected all trees\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:737 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:738 [2] NCCL INFO Connected all trees\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:738 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:735 [7] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:741 [3] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:736 [5] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:740 [1] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:741 [3] NCCL INFO Channel 01 : 3[1a0] -> 4[1b0] via P2P/indirect/0[170]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:735 [7] NCCL INFO Channel 01 : 7[1e0] -> 0[170] via P2P/indirect/4[1b0]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:737 [6] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:738 [2] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:735 [7] NCCL INFO Channel 09 : 7[1e0] -> 0[170] via P2P/indirect/4[1b0]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:738 [2] NCCL INFO Channel 02 : 2[190] -> 4[1b0] via P2P/indirect/0[170]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:737 [6] NCCL INFO Channel 02 : 6[1d0] -> 0[170] via P2P/indirect/4[1b0]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:741 [3] NCCL INFO Channel 09 : 3[1a0] -> 4[1b0] via P2P/indirect/0[170]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:735 [7] NCCL INFO Channel 02 : 7[1e0] -> 1[180] via P2P/indirect/5[1c0]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:738 [2] NCCL INFO Channel 10 : 2[190] -> 4[1b0] via P2P/indirect/0[170]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:737 [6] NCCL INFO Channel 10 : 6[1d0] -> 0[170] via P2P/indirect/4[1b0]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:735 [7] NCCL INFO Channel 10 : 7[1e0] -> 1[180] via P2P/indirect/5[1c0]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:741 [3] NCCL INFO Channel 02 : 3[1a0] -> 5[1c0] via P2P/indirect/1[180]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:741 [3] NCCL INFO Channel 10 : 3[1a0] -> 5[1c0] via P2P/indirect/1[180]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:735 [7] NCCL INFO Channel 03 : 7[1e0] -> 2[190] via P2P/indirect/3[1a0]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:735 [7] NCCL INFO Channel 11 : 7[1e0] -> 2[190] via P2P/indirect/3[1a0]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:741 [3] NCCL INFO Channel 03 : 3[1a0] -> 6[1d0] via P2P/indirect/7[1e0]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:740 [1] NCCL INFO Channel 03 : 1[180] -> 4[1b0] via P2P/indirect/0[170]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:741 [3] NCCL INFO Channel 11 : 3[1a0] -> 6[1d0] via P2P/indirect/7[1e0]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:737 [6] NCCL INFO Channel 03 : 6[1d0] -> 1[180] via P2P/indirect/5[1c0]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:740 [1] NCCL INFO Channel 11 : 1[180] -> 4[1b0] via P2P/indirect/0[170]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:737 [6] NCCL INFO Channel 11 : 6[1d0] -> 1[180] via P2P/indirect/5[1c0]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:738 [2] NCCL INFO Channel 03 : 2[190] -> 5[1c0] via P2P/indirect/1[180]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:736 [5] NCCL INFO Channel 03 : 5[1c0] -> 0[170] via P2P/indirect/4[1b0]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:736 [5] NCCL INFO Channel 11 : 5[1c0] -> 0[170] via P2P/indirect/4[1b0]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:738 [2] NCCL INFO Channel 11 : 2[190] -> 5[1c0] via P2P/indirect/1[180]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:739 [4] NCCL INFO Channel 05 : 4[1b0] -> 1[180] via P2P/indirect/5[1c0]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:734 [0] NCCL INFO Channel 05 : 0[170] -> 5[1c0] via P2P/indirect/1[180]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:739 [4] NCCL INFO Channel 13 : 4[1b0] -> 1[180] via P2P/indirect/5[1c0]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:734 [0] NCCL INFO Channel 13 : 0[170] -> 5[1c0] via P2P/indirect/1[180]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:740 [1] NCCL INFO Channel 05 : 1[180] -> 6[1d0] via P2P/indirect/5[1c0]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:737 [6] NCCL INFO Channel 05 : 6[1d0] -> 3[1a0] via P2P/indirect/2[190]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:736 [5] NCCL INFO Channel 05 : 5[1c0] -> 2[190] via P2P/indirect/1[180]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:738 [2] NCCL INFO Channel 05 : 2[190] -> 7[1e0] via P2P/indirect/6[1d0]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:740 [1] NCCL INFO Channel 13 : 1[180] -> 6[1d0] via P2P/indirect/5[1c0]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:737 [6] NCCL INFO Channel 13 : 6[1d0] -> 3[1a0] via P2P/indirect/2[190]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:736 [5] NCCL INFO Channel 13 : 5[1c0] -> 2[190] via P2P/indirect/1[180]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:738 [2] NCCL INFO Channel 13 : 2[190] -> 7[1e0] via P2P/indirect/6[1d0]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:739 [4] NCCL INFO Channel 06 : 4[1b0] -> 2[190] via P2P/indirect/6[1d0]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:734 [0] NCCL INFO Channel 06 : 0[170] -> 6[1d0] via P2P/indirect/4[1b0]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:739 [4] NCCL INFO Channel 14 : 4[1b0] -> 2[190] via P2P/indirect/6[1d0]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:736 [5] NCCL INFO Channel 06 : 5[1c0] -> 3[1a0] via P2P/indirect/1[180]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:740 [1] NCCL INFO Channel 06 : 1[180] -> 7[1e0] via P2P/indirect/3[1a0]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:734 [0] NCCL INFO Channel 14 : 0[170] -> 6[1d0] via P2P/indirect/4[1b0]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:736 [5] NCCL INFO Channel 14 : 5[1c0] -> 3[1a0] via P2P/indirect/1[180]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:740 [1] NCCL INFO Channel 14 : 1[180] -> 7[1e0] via P2P/indirect/3[1a0]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:739 [4] NCCL INFO Channel 07 : 4[1b0] -> 3[1a0] via P2P/indirect/0[170]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:739 [4] NCCL INFO Channel 15 : 4[1b0] -> 3[1a0] via P2P/indirect/0[170]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:734 [0] NCCL INFO Channel 07 : 0[170] -> 7[1e0] via P2P/indirect/4[1b0]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:734 [0] NCCL INFO Channel 15 : 0[170] -> 7[1e0] via P2P/indirect/4[1b0]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-5y4z8:127:741 [3] NCCL INFO comm 0x7f7cc0002fb0 rank 3 nranks 8 cudaDev 3 busId 1a0 - Init COMPLETE\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-5y4z8:121:740 [1] NCCL INFO comm 0x7f00a4002fb0 rank 1 nranks 8 cudaDev 1 busId 180 - Init COMPLETE\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-5y4z8:134:735 [7] NCCL INFO comm 0x7f1bc4002fb0 rank 7 nranks 8 cudaDev 7 busId 1e0 - Init COMPLETE\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:734 [0] NCCL INFO comm 0x7f787c002fb0 rank 0 nranks 8 cudaDev 0 busId 170 - Init COMPLETE\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-5y4z8:124:738 [2] NCCL INFO comm 0x7f36d8002fb0 rank 2 nranks 8 cudaDev 2 busId 190 - Init COMPLETE\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-5y4z8:131:736 [5] NCCL INFO comm 0x7f2b28002fb0 rank 5 nranks 8 cudaDev 5 busId 1c0 - Init COMPLETE\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-5y4z8:133:737 [6] NCCL INFO comm 0x7f3908002fb0 rank 6 nranks 8 cudaDev 6 busId 1d0 - Init COMPLETE\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-5y4z8:129:739 [4] NCCL INFO comm 0x7fb24c002fb0 rank 4 nranks 8 cudaDev 4 busId 1b0 - Init COMPLETE\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-5y4z8:587:587 [0] NCCL INFO Launch mode Parallel\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stderr>:LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stderr>:LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stderr>:LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stderr>:LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stderr>:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stderr>:LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stderr>:LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stderr>:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stderr>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stderr>:  | Name | Type | Params\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stderr>:------------------------------\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stderr>:0 | net  | UNet | 31.0 M\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stderr>:------------------------------\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stderr>:31.0 M    Trainable params\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stderr>:0         Non-trainable params\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stderr>:31.0 M    Total params\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stderr>:62.089    Total estimated model params size (MB)\n",
      "Sanity Checking: 0it [00:00, ?it/s][1,mpirank:0,algo-1]<stdout>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stderr>:  rank_zero_warn(\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:[2022-08-16 02:49:32.149 algo-1-5y4z8:131 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:[2022-08-16 02:49:32.149 algo-1-5y4z8:124 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:[2022-08-16 02:49:32.149 algo-1-5y4z8:121 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:[2022-08-16 02:49:32.150 algo-1-5y4z8:134 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:[2022-08-16 02:49:32.150 algo-1-5y4z8:133 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:[2022-08-16 02:49:32.150 algo-1-5y4z8:587 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:[2022-08-16 02:49:32.150 algo-1-5y4z8:129 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:[2022-08-16 02:49:32.153 algo-1-5y4z8:127 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220722-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220722-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220722-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220722-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220722-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220722-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220722-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220722-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220722-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220722-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220722-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220722-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220722-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220722-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220722-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220722-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:[2022-08-16 02:49:32.301 algo-1-5y4z8:121 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:[2022-08-16 02:49:32.301 algo-1-5y4z8:131 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:[2022-08-16 02:49:32.302 algo-1-5y4z8:133 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:[2022-08-16 02:49:32.302 algo-1-5y4z8:124 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:[2022-08-16 02:49:32.303 algo-1-5y4z8:587 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:[2022-08-16 02:49:32.305 algo-1-5y4z8:134 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:[2022-08-16 02:49:32.306 algo-1-5y4z8:129 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:[2022-08-16 02:49:32.311 algo-1-5y4z8:127 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "Sanity Checking DataLoader 0:   0% 0/1 [00:00<?, ?it/s]<stdout>:\n",
      "Sanity Checking DataLoader 0: 100% 1/1 [00:05<00:00,  5.31s/it]:\n",
      "Sanity Checking DataLoader 0: 100% 1/1 [00:05<00:00,  5.31s/it]:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stderr>:  rank_zero_warn(\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1927: PossibleUserWarning: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stderr>:  rank_zero_warn(\n",
      "Training: 0it [00:00, ?it/s] |\u001b[0m [1,mpirank:0,algo-1]<stdout>:\n",
      "Training:   0% 0/4 [00:00<?, ?it/s][1,mpirank:0,algo-1]<stdout>:\n",
      "Epoch 0:   0% 0/4 [00:00<?, ?it/s] [1,mpirank:0,algo-1]<stdout>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:5,algo-1]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:6,algo-1]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:3,algo-1]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:4,algo-1]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:7,algo-1]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:1,algo-1]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:2,algo-1]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "Epoch 0:  25% 1/4 [00:11<00:34, 11.48s/it]ank:0,algo-1]<stdout>:\n",
      "Epoch 0:  25% 1/4 [00:11<00:34, 11.48s/it, loss=2.99, v_num=0]>:\n",
      "Epoch 0:  50% 2/4 [00:12<00:12,  6.23s/it, loss=2.99, v_num=0][1,mpirank:0,algo-1]<stdout>:\n",
      "Epoch 0:  50% 2/4 [00:12<00:12,  6.23s/it, loss=2.84, v_num=0]>:\n",
      "Epoch 0:  75% 3/4 [00:20<00:06,  6.99s/it, loss=2.84, v_num=0]>:\n",
      "Epoch 0:  75% 3/4 [00:20<00:06,  6.99s/it, loss=2.75, v_num=0]>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:\n",
      "Validation: 0it [00:00, ?it/s][1,mpirank:0,algo-1]<stdout>:\u001b[A>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:\n",
      "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[Airank:0,algo-1]<stdout>:\n",
      "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A1]<stdout>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:\n",
      "Validation DataLoader 0: 100% 1/1 [00:00<00:00, 77.77it/s]\u001b[At>:\n",
      "Epoch 0: 100% 4/4 [00:21<00:00,  5.30s/it, loss=2.75, v_num=0][1,mpirank:0,algo-1]<stdout>:\n",
      "Epoch 0: 100% 4/4 [00:21<00:00,  5.32s/it, loss=2.75, v_num=0]>:\n",
      "                                                          \u001b[At>:\n",
      "Epoch 0: 100% 4/4 [00:21<00:00,  5.32s/it, loss=2.75, v_num=0]>:\n",
      "Epoch 1:   0% 0/4 [00:00<?, ?it/s, loss=2.75, v_num=0]        >:\n",
      "Epoch 1:  25% 1/4 [00:00<00:02,  1.15it/s, loss=2.75, v_num=0]>:\n",
      "Epoch 1:  25% 1/4 [00:00<00:02,  1.15it/s, loss=2.65, v_num=0]>:\n",
      "Epoch 1:  50% 2/4 [00:01<00:01,  1.18it/s, loss=2.65, v_num=0]>:\n",
      "Epoch 1:  50% 2/4 [00:01<00:01,  1.18it/s, loss=2.53, v_num=0]>:\n",
      "Epoch 1:  75% 3/4 [00:02<00:00,  1.43it/s, loss=2.53, v_num=0][1,mpirank:0,algo-1]<stdout>:\n",
      "Epoch 1:  75% 3/4 [00:02<00:00,  1.43it/s, loss=2.48, v_num=0]>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:\n",
      "Validation: 0it [00:00, ?it/s]\u001b[Am [1,mpirank:0,algo-1]<stdout>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:\n",
      "Validation:   0% 0/1 [00:00<?, ?it/s][1,mpirank:0,algo-1]<stdout>:\u001b[A[1,mpirank:0,algo-1]<stdout>:\n",
      "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A1]<stdout>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:\n",
      "Validation DataLoader 0: 100% 1/1 [00:00<00:00, 80.15it/s]\u001b[At>:\n",
      "Epoch 1: 100% 4/4 [00:02<00:00,  1.73it/s, loss=2.48, v_num=0][1,mpirank:0,algo-1]<stdout>:\n",
      "Epoch 1: 100% 4/4 [00:02<00:00,  1.67it/s, loss=2.48, v_num=0][1,mpirank:0,algo-1]<stdout>:\n",
      "                                                          \u001b[At>:\n",
      "Epoch 1: 100% 4/4 [00:02<00:00,  1.67it/s, loss=2.48, v_num=0]>:\n",
      "Epoch 2:   0% 0/4 [00:00<?, ?it/s, loss=2.48, v_num=0]        >:\n",
      "Epoch 2:  25% 1/4 [00:01<00:03,  1.20s/it, loss=2.48, v_num=0][1,mpirank:0,algo-1]<stdout>:\n",
      "Epoch 2:  25% 1/4 [00:01<00:03,  1.20s/it, loss=2.42, v_num=0]>:\n",
      "Epoch 2:  50% 2/4 [00:02<00:02,  1.04s/it, loss=2.42, v_num=0]>:\n",
      "Epoch 2:  50% 2/4 [00:02<00:02,  1.04s/it, loss=2.36, v_num=0]>:\n",
      "Epoch 2:  75% 3/4 [00:02<00:00,  1.20it/s, loss=2.36, v_num=0][1,mpirank:0,algo-1]<stdout>:\n",
      "Epoch 2:  75% 3/4 [00:02<00:00,  1.20it/s, loss=2.31, v_num=0]>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:\n",
      "Validation: 0it [00:00, ?it/s]\u001b[Am [1,mpirank:0,algo-1]<stdout>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:\n",
      "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[Airank:0,algo-1]<stdout>:\n",
      "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A1]<stdout>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:\n",
      "Validation DataLoader 0: 100% 1/1 [00:00<00:00, 80.54it/s]\u001b[At>:\n",
      "Epoch 2: 100% 4/4 [00:02<00:00,  1.47it/s, loss=2.31, v_num=0][1,mpirank:0,algo-1]<stdout>:\n",
      "Epoch 2: 100% 4/4 [00:02<00:00,  1.43it/s, loss=2.31, v_num=0]>:\n",
      "                                                          \u001b[At>:\n",
      "Epoch 2: 100% 4/4 [00:02<00:00,  1.43it/s, loss=2.31, v_num=0]>:\n",
      "Epoch 3:   0% 0/4 [00:00<?, ?it/s, loss=2.31, v_num=0]        >:\n",
      "Epoch 3:  25% 1/4 [00:00<00:02,  1.21it/s, loss=2.31, v_num=0]>:\n",
      "Epoch 3:  25% 1/4 [00:00<00:02,  1.21it/s, loss=2.25, v_num=0]>:\n",
      "Epoch 3:  50% 2/4 [00:01<00:01,  1.18it/s, loss=2.25, v_num=0]>:\n",
      "Epoch 3:  50% 2/4 [00:01<00:01,  1.18it/s, loss=2.23, v_num=0]>:\n",
      "Epoch 3:  75% 3/4 [00:02<00:00,  1.43it/s, loss=2.23, v_num=0]>:\n",
      "Epoch 3:  75% 3/4 [00:02<00:00,  1.43it/s, loss=2.2, v_num=0]t>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:\n",
      "Validation: 0it [00:00, ?it/s]\u001b[Am [1,mpirank:0,algo-1]<stdout>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:\n",
      "Validation:   0% 0/1 [00:00<?, ?it/s][1,mpirank:0,algo-1]<stdout>:\u001b[A\n",
      "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A1]<stdout>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:\n",
      "Validation DataLoader 0: 100% 1/1 [00:00<00:00, 86.40it/s]\u001b[At>:\n",
      "Epoch 3: 100% 4/4 [00:02<00:00,  1.74it/s, loss=2.2, v_num=0][1,mpirank:0,algo-1]<stdout>:\n",
      "Epoch 3: 100% 4/4 [00:02<00:00,  1.67it/s, loss=2.2, v_num=0][1,mpirank:0,algo-1]<stdout>:\n",
      "                                                          [1,mpirank:0,algo-1]<stdout>:\u001b[A\n",
      "Epoch 3: 100% 4/4 [00:02<00:00,  1.67it/s, loss=2.2, v_num=0]t>:\n",
      "Epoch 4:   0% 0/4 [00:00<?, ?it/s, loss=2.2, v_num=0]        t>:\n",
      "Epoch 4:  25% 1/4 [00:00<00:02,  1.23it/s, loss=2.2, v_num=0]t>:\n",
      "Epoch 4:  25% 1/4 [00:00<00:02,  1.23it/s, loss=2.16, v_num=0]>:\n",
      "Epoch 4:  50% 2/4 [00:01<00:01,  1.19it/s, loss=2.16, v_num=0]>:\n",
      "Epoch 4:  50% 2/4 [00:01<00:01,  1.19it/s, loss=2.12, v_num=0]>:\n",
      "Epoch 4:  75% 3/4 [00:02<00:00,  1.44it/s, loss=2.12, v_num=0]>:\n",
      "Epoch 4:  75% 3/4 [00:02<00:00,  1.44it/s, loss=2.09, v_num=0]>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:\n",
      "Validation: 0it [00:00, ?it/s][1,mpirank:0,algo-1]<stdout>:\u001b[A>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:\n",
      "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[Airank:0,algo-1]<stdout>:\n",
      "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A1]<stdout>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:\n",
      "Validation DataLoader 0: 100% 1/1 [00:00<00:00, 86.06it/s]\u001b[At>:\n",
      "Epoch 4: 100% 4/4 [00:02<00:00,  1.75it/s, loss=2.09, v_num=0][1,mpirank:0,algo-1]<stdout>:\n",
      "Epoch 4: 100% 4/4 [00:02<00:00,  1.67it/s, loss=2.09, v_num=0][1,mpirank:0,algo-1]<stdout>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:\u001b[A\n",
      "Epoch 4: 100% 4/4 [00:02<00:00,  1.67it/s, loss=2.09, v_num=0]>:\n",
      "Epoch 5:   0% 0/4 [00:00<?, ?it/s, loss=2.09, v_num=0]        >:\n",
      "Epoch 5:  25% 1/4 [00:00<00:02,  1.21it/s, loss=2.09, v_num=0]>:\n",
      "Epoch 5:  25% 1/4 [00:00<00:02,  1.21it/s, loss=2.06, v_num=0]>:\n",
      "Epoch 5:  50% 2/4 [00:01<00:01,  1.18it/s, loss=2.06, v_num=0]>:\n",
      "Epoch 5:  50% 2/4 [00:01<00:01,  1.18it/s, loss=2.04, v_num=0]>:\n",
      "Epoch 5:  75% 3/4 [00:02<00:00,  1.43it/s, loss=2.04, v_num=0][1,mpirank:0,algo-1]<stdout>:\n",
      "Epoch 5:  75% 3/4 [00:02<00:00,  1.43it/s, loss=2.01, v_num=0]>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:\n",
      "Validation: 0it [00:00, ?it/s]\u001b[Am [1,mpirank:0,algo-1]<stdout>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:\n",
      "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A[1,mpirank:0,algo-1]<stdout>:\n",
      "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A1]<stdout>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:\n",
      "Validation DataLoader 0: 100% 1/1 [00:00<00:00, 85.78it/s]\u001b[At>:\n",
      "Epoch 5: 100% 4/4 [00:02<00:00,  1.74it/s, loss=2.01, v_num=0][1,mpirank:0,algo-1]<stdout>:\n",
      "Epoch 5: 100% 4/4 [00:02<00:00,  1.67it/s, loss=2.01, v_num=0][1,mpirank:0,algo-1]<stdout>:\n",
      "                                                          \u001b[At>:\n",
      "Epoch 5: 100% 4/4 [00:02<00:00,  1.67it/s, loss=2.01, v_num=0]>:\n",
      "Epoch 5: 100% 4/4 [00:03<00:00,  1.16it/s, loss=2.01, v_num=0]>:\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m 2022-08-16 02:50:19,725 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m 2022-08-16 02:50:19,725 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 |\u001b[0m 2022-08-16 02:50:19,726 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\u001b[36m5jfl2hnhwa-algo-1-5y4z8 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {\"batch_size\": 8}\n",
    "enable_local_mode_training = True\n",
    "\n",
    "if enable_local_mode_training:\n",
    "    train_instance_type = \"local_gpu\"\n",
    "    inputs = {\"data_path\": f\"file:///home/ec2-user/SageMaker/amazon-sagemaker-pytorch-lightning-distributed-training/data_semantics\"}\n",
    "else:\n",
    "    train_instance_type = \"ml.g4dn.12xlarge\"\n",
    "    inputs = {\"data_path\": data_url}\n",
    "\n",
    "estimator_parameters = {\n",
    "    \"entry_point\": \"semantic_segmentation_single.py\",\n",
    "    \"source_dir\": \"code\",\n",
    "    \"instance_type\": train_instance_type,\n",
    "    \"instance_count\": 1,\n",
    "    \"hyperparameters\": hyperparameters,\n",
    "    \"role\": role,\n",
    "    \"base_job_name\": \"pytorch-lightning\",\n",
    "    \"image_uri\": \"570106654206.dkr.ecr.us-east-1.amazonaws.com/pt-ddp-custom:1.12.0-gpu-py38-cu113-ubuntu20.04-sagemaker-2.6.0-numproc\",\n",
    "    \"py_version\": \"py3\",\n",
    "    \"distribution\": {\"pytorchddp\":{\"enabled\": True}},\n",
    "}\n",
    "\n",
    "estimator = PyTorch(**estimator_parameters)\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed881a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-16 04:40:38 Starting - Starting the training job...ProfilerReport-1660624838: InProgress\n",
      "...\n",
      "2022-08-16 04:41:34 Starting - Preparing the instances for training............\n",
      "2022-08-16 04:43:21 Downloading - Downloading input data......\n",
      "2022-08-16 04:44:35 Training - Downloading the training image.....................\n",
      "2022-08-16 04:48:03 Training - Training image download completed. Training in progress..\u001b[35mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[35mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[35m2022-08-16 04:48:09,412 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[35m2022-08-16 04:48:09,489 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[35m2022-08-16 04:48:09,492 sagemaker_pytorch_container.training INFO     Pytorch_ddp_enabled is:\u001b[0m\n",
      "\u001b[35m2022-08-16 04:48:09,492 sagemaker_pytorch_container.training INFO     True\u001b[0m\n",
      "\u001b[35m2022-08-16 04:48:09,492 sagemaker_pytorch_container.training INFO     Invoking SMDataParallel for native PT DDP job\u001b[0m\n",
      "\u001b[35m2022-08-16 04:48:09,492 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[35m2022-08-16 04:48:10,110 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[35m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.12.0+cu113)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: torchvision in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (0.13.0+cu113)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (1.6.3)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch->-r requirements.txt (line 1)) (4.3.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from torchvision->-r requirements.txt (line 2)) (1.22.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.8/site-packages (from torchvision->-r requirements.txt (line 2)) (9.2.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from torchvision->-r requirements.txt (line 2)) (2.28.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning->-r requirements.txt (line 3)) (4.64.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: torchmetrics>=0.4.1 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning->-r requirements.txt (line 3)) (0.9.3)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: tensorboard>=2.2.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning->-r requirements.txt (line 3)) (2.10.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pyDeprecate<0.4.0,>=0.3.1 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning->-r requirements.txt (line 3)) (0.3.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning->-r requirements.txt (line 3)) (2022.5.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning->-r requirements.txt (line 3)) (5.4.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning->-r requirements.txt (line 3)) (21.3)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.8/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->-r requirements.txt (line 3)) (3.8.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=17.0->pytorch-lightning->-r requirements.txt (line 3)) (3.0.9)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (63.2.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (2.1.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (2.10.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (1.8.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (1.47.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (0.4.6)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (0.37.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (3.4.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (0.6.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (3.19.4)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (1.2.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision->-r requirements.txt (line 2)) (1.26.10)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision->-r requirements.txt (line 2)) (2.1.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision->-r requirements.txt (line 2)) (2022.6.15)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision->-r requirements.txt (line 2)) (3.3)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (0.2.8)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (4.7.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (1.16.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (5.2.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (1.3.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (4.12.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->-r requirements.txt (line 3)) (1.8.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->-r requirements.txt (line 3)) (6.0.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->-r requirements.txt (line 3)) (21.4.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->-r requirements.txt (line 3)) (4.0.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->-r requirements.txt (line 3)) (1.3.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->-r requirements.txt (line 3)) (1.2.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (3.8.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (0.4.8)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (3.2.0)\u001b[0m\n",
      "\u001b[34m2022-08-16 04:48:12,043 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-08-16 04:48:12,122 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-08-16 04:48:12,125 sagemaker_pytorch_container.training INFO     Pytorch_ddp_enabled is:\u001b[0m\n",
      "\u001b[34m2022-08-16 04:48:12,125 sagemaker_pytorch_container.training INFO     True\u001b[0m\n",
      "\u001b[34m2022-08-16 04:48:12,125 sagemaker_pytorch_container.training INFO     Invoking SMDataParallel for native PT DDP job\u001b[0m\n",
      "\u001b[34m2022-08-16 04:48:12,125 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[35mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[35m[notice] A new release of pip available: 22.2 -> 22.2.2\u001b[0m\n",
      "\u001b[35m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[35m2022-08-16 04:48:12,590 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[35m2022-08-16 04:48:12,590 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[35m2022-08-16 04:48:12,743 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\u001b[0m\n",
      "\u001b[35m2022-08-16 04:48:12,743 sagemaker-training-toolkit INFO     Waiting for MPI Master to create SSH daemon.\u001b[0m\n",
      "\u001b[35m2022-08-16 04:48:12,744 sagemaker-training-toolkit INFO     Cannot connect to host algo-1\u001b[0m\n",
      "\u001b[35m2022-08-16 04:48:12,744 sagemaker-training-toolkit INFO     Connection failed with exception: \n",
      " [Errno None] Unable to connect to port 22 on 10.2.236.66\u001b[0m\n",
      "\u001b[34m2022-08-16 04:48:13,125 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[35m2022-08-16 04:48:13,745 sagemaker-training-toolkit INFO     Cannot connect to host algo-1\u001b[0m\n",
      "\u001b[35m2022-08-16 04:48:13,746 sagemaker-training-toolkit INFO     Connection failed with exception: \n",
      " [Errno None] Unable to connect to port 22 on 10.2.236.66\u001b[0m\n",
      "\u001b[35m2022-08-16 04:48:14,748 sagemaker-training-toolkit INFO     Cannot connect to host algo-1\u001b[0m\n",
      "\u001b[35m2022-08-16 04:48:14,748 sagemaker-training-toolkit INFO     Connection failed with exception: \n",
      " [Errno None] Unable to connect to port 22 on 10.2.236.66\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.12.0+cu113)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torchvision in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (0.13.0+cu113)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (1.6.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch->-r requirements.txt (line 1)) (4.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from torchvision->-r requirements.txt (line 2)) (2.28.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from torchvision->-r requirements.txt (line 2)) (1.22.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.8/site-packages (from torchvision->-r requirements.txt (line 2)) (9.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyDeprecate<0.4.0,>=0.3.1 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning->-r requirements.txt (line 3)) (0.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning->-r requirements.txt (line 3)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning->-r requirements.txt (line 3)) (4.64.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torchmetrics>=0.4.1 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning->-r requirements.txt (line 3)) (0.9.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning->-r requirements.txt (line 3)) (2022.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tensorboard>=2.2.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning->-r requirements.txt (line 3)) (2.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning->-r requirements.txt (line 3)) (21.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.8/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->-r requirements.txt (line 3)) (3.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=17.0->pytorch-lightning->-r requirements.txt (line 3)) (3.0.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (0.37.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (3.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (63.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (2.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (2.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (1.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (0.6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (0.4.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (1.47.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (3.19.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision->-r requirements.txt (line 2)) (2.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision->-r requirements.txt (line 2)) (3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision->-r requirements.txt (line 2)) (1.26.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision->-r requirements.txt (line 2)) (2022.6.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (4.7.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (5.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (0.2.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (4.12.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->-r requirements.txt (line 3)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->-r requirements.txt (line 3)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->-r requirements.txt (line 3)) (4.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->-r requirements.txt (line 3)) (1.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->-r requirements.txt (line 3)) (6.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->-r requirements.txt (line 3)) (21.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (3.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (0.4.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 3)) (3.2.0)\u001b[0m\n",
      "\u001b[35m2022-08-16 04:48:15,749 sagemaker-training-toolkit INFO     Cannot connect to host algo-1\u001b[0m\n",
      "\u001b[35m2022-08-16 04:48:15,750 sagemaker-training-toolkit INFO     Connection failed with exception: \n",
      " [Errno None] Unable to connect to port 22 on 10.2.236.66\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.2 -> 22.2.2\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2022-08-16 04:48:15,824 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2022-08-16 04:48:15,824 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2022-08-16 04:48:15,979 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\u001b[0m\n",
      "\u001b[34m2022-08-16 04:48:15,979 sagemaker-training-toolkit INFO     Creating SSH daemon.\u001b[0m\n",
      "\u001b[34m2022-08-16 04:48:15,987 sagemaker-training-toolkit INFO     Waiting for MPI workers to establish their SSH connections\u001b[0m\n",
      "\u001b[34m2022-08-16 04:48:15,988 sagemaker-training-toolkit INFO     Cannot connect to host algo-2 at port 22. Retrying...\u001b[0m\n",
      "\u001b[34m2022-08-16 04:48:15,989 sagemaker-training-toolkit INFO     Connection closed\u001b[0m\n",
      "\u001b[35m2022-08-16 04:48:16,762 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_8.2p1)\u001b[0m\n",
      "\u001b[35m2022-08-16 04:48:16,859 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[35m2022-08-16 04:48:16,859 sagemaker-training-toolkit INFO     Can connect to host algo-1\u001b[0m\n",
      "\u001b[35m2022-08-16 04:48:16,859 sagemaker-training-toolkit INFO     MPI Master online, creating SSH daemon.\u001b[0m\n",
      "\u001b[35m2022-08-16 04:48:16,859 sagemaker-training-toolkit INFO     Writing environment variables to /etc/environment for the MPI process.\u001b[0m\n",
      "\u001b[35m2022-08-16 04:48:16,866 sagemaker-training-toolkit INFO     Waiting for MPI process to finish.\u001b[0m\n",
      "\u001b[35m2022-08-16 04:48:17,869 sagemaker-training-toolkit INFO     Process[es]: [psutil.Process(pid=128, name='orted', status='sleeping', started='04:48:17'), psutil.Process(pid=131, name='orted', status='running', started='04:48:17')]\u001b[0m\n",
      "\u001b[35m2022-08-16 04:48:17,870 sagemaker-training-toolkit INFO     Orted process found [psutil.Process(pid=128, name='orted', status='running', started='04:48:17'), psutil.Process(pid=131, name='smddprun', status='running', started='04:48:17')]\u001b[0m\n",
      "\u001b[35m2022-08-16 04:48:17,870 sagemaker-training-toolkit INFO     Waiting for orted process [psutil.Process(pid=128, name='orted', status='running', started='04:48:17'), psutil.Process(pid=131, name='smddprun', status='running', started='04:48:17')]\u001b[0m\n",
      "\u001b[34m2022-08-16 04:48:17,001 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_8.2p1)\u001b[0m\n",
      "\u001b[34m2022-08-16 04:48:17,104 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[34m2022-08-16 04:48:17,104 sagemaker-training-toolkit INFO     Can connect to host algo-2 at port 22\u001b[0m\n",
      "\u001b[34m2022-08-16 04:48:17,104 sagemaker-training-toolkit INFO     Connection closed\u001b[0m\n",
      "\u001b[34m2022-08-16 04:48:17,104 sagemaker-training-toolkit INFO     Worker algo-2 available for communication\u001b[0m\n",
      "\u001b[34m2022-08-16 04:48:17,104 sagemaker-training-toolkit INFO     Network interface name: eth0\u001b[0m\n",
      "\u001b[34m2022-08-16 04:48:17,105 sagemaker-training-toolkit INFO     Host: ['algo-1', 'algo-2']\u001b[0m\n",
      "\u001b[34m2022-08-16 04:48:17,106 sagemaker-training-toolkit INFO     instance type: ml.p3.16xlarge\u001b[0m\n",
      "\u001b[34m2022-08-16 04:48:17,106 sagemaker-training-toolkit INFO     Env Hosts: ['algo-1', 'algo-2'] Hosts: ['algo-1:8', 'algo-2:8'] process_per_hosts: 8 num_processes: 16\u001b[0m\n",
      "\u001b[34m2022-08-16 04:48:17,186 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_instance_type\": \"ml.p3.16xlarge\",\n",
      "        \"sagemaker_pytorch_ddp_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"data_path\": \"/opt/ml/input/data/data_path\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.p3.16xlarge\",\n",
      "    \"distribution_hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"distribution_instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 8\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"data_path\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.p3.16xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\",\n",
      "                \"algo-2\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"job_name\": \"pytorch-lightning-2022-08-16-04-40-37-950\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-631450739534/pytorch-lightning-2022-08-16-04-40-37-950/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"semantic_segmentation\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 64,\n",
      "    \"num_gpus\": 8,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.16xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.16xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"semantic_segmentation.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":8}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=semantic_segmentation.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_pytorch_ddp_enabled\":true}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.16xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"data_path\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"data_path\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.p3.16xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=semantic_segmentation\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=64\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-631450739534/pytorch-lightning-2022-08-16-04-40-37-950/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_pytorch_ddp_enabled\":true},\"channel_input_dirs\":{\"data_path\":\"/opt/ml/input/data/data_path\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.p3.16xlarge\",\"distribution_hosts\":[\"algo-1\",\"algo-2\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"batch_size\":8},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"data_path\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"pytorch-lightning-2022-08-16-04-40-37-950\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-631450739534/pytorch-lightning-2022-08-16-04-40-37-950/source/sourcedir.tar.gz\",\"module_name\":\"semantic_segmentation\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.16xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"semantic_segmentation.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"8\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_DATA_PATH=/opt/ml/input/data/data_path\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=8\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220722-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34mmpirun --host algo-1:8,algo-2:8 -np 16 --allow-run-as-root --tag-output --oversubscribe -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -mca btl_vader_single_copy_mechanism none -mca plm_rsh_num_concurrent 2 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x SMDATAPARALLEL_USE_HOMOGENEOUS=1 -x FI_PROVIDER=efa -x RDMAV_FORK_SAFE=1 -x LD_PRELOAD=/opt/conda/lib/python3.8/site-packages/gethostname.cpython-38-x86_64-linux-gnu.so -x SMDATAPARALLEL_SERVER_ADDR=algo-1 -x SMDATAPARALLEL_SERVER_PORT=7592 -x SAGEMAKER_INSTANCE_TYPE=ml.p3.16xlarge smddprun /opt/conda/bin/python3.8 -m mpi4py semantic_segmentation.py --batch_size 8\u001b[0m\n",
      "\u001b[34mWarning: Permanently added 'algo-2,10.2.242.254' (ECDSA) to the list of known hosts.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:environ({'OMPI_MCA_orte_app_num': '0', 'NVIDIA_VISIBLE_DEVICES': 'all', 'OMPI_MCA_btl_vader_single_copy_mechanism': 'none', 'SAGEMAKER_JOB_NAME': 'pytorch-lightning-2022-08-16-04-40-37-950', 'SM_CHANNELS': '[\"data_path\"]', 'SM_FRAMEWORK_MODULE': 'sagemaker_pytorch_container.training:main', 'OMPI_MCA_orte_precondition_transports': '2c6b6180696abc4e-99036dffeeb77785', 'PYTHONUNBUFFERED': '1', 'OMPI_MCA_shmem_RUNTIME_QUERY_hint': 'mmap', 'OMPI_UNIVERSE_SIZE': '16', 'OMPI_MCA_rmaps_base_oversubscribe': '1', 'PMIX_MCA_mca_base_component_show_load_errors': '1', 'SM_HOSTS': '[\"algo-1\",\"algo-2\"]', 'LOCAL_RANK': '0', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-0f66adf8f3e516732efee12a20cd80ab606b21ea2a19d5d7fde97a2cf76019bf-customer', 'PMIX_HOSTNAME': 'algo-1', 'SAGEMAKER_TRAINING_MODULE': 'sagemaker_pytorch_container.training:main', 'HOSTNAME': 'ip-10-2-236-66.ec2.internal', 'OMPI_COMM_WORLD_NODE_RANK': '0', 'OMPI_MCA_ess_base_vpid': '0', 'SM_MODULE_NAME': 'semantic_segmentation', 'PMIX_SECURITY_MODE': 'native', 'MASTER_PORT': '7592', 'OMPI_MCA_orte_hnp_uri': '2694709248.0;tcp://10.2.236.66:44785', 'NVIDIA_REQUIRE_CUDA': 'cuda>=11.3 brand=tesla,driver>=418,driver<419 driver>=450', 'SMDATAPARALLEL_USE_ENA': '1', 'OMPI_MCA_plm_rsh_num_concurrent': '2', 'MANUAL_BUILD': '0', 'SM_INSTANCE_GROUPS_DICT': '{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}}', 'BRANCH_OFI': '1.3.0-aws', 'TORCH_NVCC_FLAGS': '-Xfatbin -compress-all', 'OMPI_MCA_btl': '^openib', 'SAGEMAKER_INSTANCE_TYPE': 'ml.p3.16xlarge', 'OMPI_COMM_WORLD_LOCAL_RANK': '0', 'TORCH_CUDA_ARCH_LIST': '3.7 5.0 7.0+PTX 8.0', 'NCCL_VERSION': '2.10.3', 'NCCL_SOCKET_IFNAME': 'eth0', 'HFI_NO_BACKTRACE': '1', 'AWS_REGION': 'us-east-1', 'PMIX_GDS_MODULE': 'ds21,ds12,hash', 'PWD': '/opt/ml/code', 'SMDATAPARALLEL_WORLD_RANK': '0', 'OMPI_MCA_orte_abort_on_non_zero_status': '1', 'OMPI_MCA_orte_local_daemon_uri': '2694709248.0;tcp://10.2.236.66:44785', 'RDMAV_FORK_SAFE': '1', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility,compat32,graphics,video', 'OMPI_MCA_oob_tcp_if_include': 'eth0', 'NCCL_DEBUG': 'INFO', 'OMPI_MCA_pml': 'ob1', 'HOROVOD_VERSION': '0.24.3', '_': '/opt/conda/bin/python3.8', 'PMIX_SYSTEM_TMPDIR': '/tmp', 'WORLD_SIZE': '16', 'SM_USER_ENTRY_POINT': 'semantic_segmentation.py', 'OPEN_MPI_PATH': '/opt/amazon/openmpi', 'OMPI_ARGV': '/opt/conda/bin/python3.8 -m mpi4py semantic_segmentation.py --batch_size 8', 'PMIX_BFROP_BUFFER_TYPE': 'PMIX_BFROP_BUFFER_NON_DESC', 'LD_PRELOAD': '/opt/conda/lib/python3.8/site-packages/gethostname.cpython-38-x86_64-linux-gnu.so', 'NV_CUDA_CUDART_VERSION': '11.3.109-1', 'PMIX_PTL_MODULE': 'tcp,usock', 'HOME': '/root', 'FI_PROVIDER': 'efa', 'OMPI_NUM_APP_CTX': '1', 'LANG': 'C.UTF-8', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'PMIX_DSTORE_21_BASE_PATH': '/tmp/ompi.algo-1.0/pid.120/pmix_dstor_ds21_120', 'SM_IS_HETERO': 'false', 'OMPI_MCA_orte_num_nodes': '2', 'SM_CURRENT_INSTANCE_TYPE': 'ml.p3.16xlarge', 'PMIX_VERSION': '3.2.3', 'CUDA_VERSION': '11.3.1', 'SMDATAPARALLEL_LOCAL_RANK': '0', 'DMLC_INTERFACE': 'eth0', 'OMPI_MCA_orte_tag_output': '1', 'SM_NUM_CPUS': '64', 'CMAKE_PREFIX_PATH': '$(dirname $(which conda))/../', 'DGLBACKEND': 'pytorch', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_HP_BATCH_SIZE': '8', 'USE_SMDEBUG': '0', 'OMPI_MCA_orte_tmpdir_base': '/tmp', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'PMIX_RANK': '0', 'PMIX_SERVER_URI2': '2694709248.0;tcp4://127.0.0.1:32795', 'PMIX_SERVER_URI3': '2694709248.0;tcp4://127.0.0.1:32795', 'SM_CURRENT_HOST': 'algo-1', 'OMPI_MCA_initial_wdir': '/opt/ml/code', 'OMPI_FIRST_RANKS': '0', 'SM_INSTANCE_GROUPS': '[\"homogeneousCluster\"]', 'OMPI_MCA_mpi_oversubscribe': '0', 'SMDATAPARALLEL_WORLD_SIZE': '16', 'OMPI_MCA_orte_jobfam_session_dir': '/tmp/ompi.algo-1.0/pid.120', 'MASTER_ADDR': 'algo-1', 'SM_INPUT_DATA_CONFIG': '{\"data_path\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}', 'SM_NUM_GPUS': '8', 'SM_I[1,mpirank:3,algo-1]<stdout>:environ({'OMPI_MCA_orte_app_num': '0', 'NVIDIA_VISIBLE_DEVICES': 'all', 'OMPI_MCA_btl_vader_single_copy_mechanism': 'none', 'SAGEMAKER_JOB_NAME': 'pytorch-lightning-2022-08-16-04-40-37-950', 'SM_CHANNELS': '[\"data_path\"]', 'SM_FRAMEWORK_MODULE': 'sagemaker_pytorch_container.training:main', 'OMPI_MCA_orte_precondition_transports': '2c6b6180696abc4e-99036dffeeb77785', 'PYTHONUNBUFFERED': '1', 'OMPI_MCA_shmem_RUNTIME_QUERY_hint': 'mmap', 'OMPI_UNIVERSE_SIZE': '16', 'OMPI_MCA_rmaps_base_oversubscribe': '1', 'PMIX_MCA_mca_base_component_show_load_errors': '1', 'SM_HOSTS': '[\"algo-1\",\"algo-2\"]', 'LOCAL_RANK': '3', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-0f66adf8f3e516732efee12a20cd80ab606b21ea2a19d5d7fde97a2cf76019bf-customer', 'PMIX_HOSTNAME': 'algo-1', 'SAGEMAKER_TRAINING_MODULE': 'sagemaker_pytorch_container.training:main', 'HOSTNAME': 'ip-10-2-236-66.ec2.internal', 'OMPI_COMM_WORLD_NODE_RANK': '3', 'OMPI_MCA_ess_base_vpid': '3', 'SM_MODULE_NAME': 'semantic_segmentation', 'PMIX_SECURITY_MODE': 'native', 'MASTER_PORT': '7592', 'OMPI_MCA_orte_hnp_uri': '2694709248.0;tcp://10.2.236.66:44785', 'NVIDIA_REQUIRE_CUDA': 'cuda>=11.3 brand=tesla,driver>=418,driver<419 driver>=450', 'SMDATAPARALLEL_USE_ENA': '1', 'OMPI_MCA_plm_rsh_num_concurrent': '2', 'MANUAL_BUILD': '0', 'SM_INSTANCE_GROUPS_DICT': '{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}}', 'BRANCH_OFI': '1.3.0-aws', 'TORCH_NVCC_FLAGS': '-Xfatbin -compress-all', 'OMPI_MCA_btl': '^openib', 'SAGEMAKER_INSTANCE_TYPE': 'ml.p3.16xlarge', 'OMPI_COMM_WORLD_LOCAL_RANK': '3', 'TORCH_CUDA_ARCH_LIST': '3.7 5.0 7.0+PTX 8.0', 'NCCL_VERSION': '2.10.3', 'NCCL_SOCKET_IFNAME': 'eth0', 'HFI_NO_BACKTRACE': '1', 'AWS_REGION': 'us-east-1', 'PMIX_GDS_MODULE': 'ds21,ds12,hash', 'PWD': '/opt/ml/code', 'SMDATAPARALLEL_WORLD_RANK': '3', 'OMPI_MCA_orte_abort_on_non_zero_status': '1', 'OMPI_MCA_orte_local_daemon_uri': '2694709248.0;tcp://10.2.236.66:44785', 'RDMAV_FORK_SAFE': '1', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility,compat32,graphics,video', 'OMPI_MCA_oob_tcp_if_include': 'eth0', 'NCCL_DEBUG': 'INFO', 'OMPI_MCA_pml': 'ob1', 'HOROVOD_VERSION': '0.24.3', '_': '/opt/conda/bin/python3.8', 'PMIX_SYSTEM_TMPDIR': '/tmp', 'WORLD_SIZE': '16', 'SM_USER_ENTRY_POINT': 'semantic_segmentation.py', 'OPEN_MPI_PATH': '/opt/amazon/openmpi', 'OMPI_ARGV': '/opt/conda/bin/python3.8 -m mpi4py semantic_segmentation.py --batch_size 8', 'PMIX_BFROP_BUFFER_TYPE': 'PMIX_BFROP_BUFFER_NON_DESC', 'LD_PRELOAD': '/opt/conda/lib/python3.8/site-packages/gethostname.cpython-38-x86_64-linux-gnu.so', 'NV_CUDA_CUDART_VERSION': '11.3.109-1', 'PMIX_PTL_MODULE': 'tcp,usock', 'HOME': '/root', 'FI_PROVIDER': 'efa', 'OMPI_NUM_APP_CTX': '1', 'LANG': 'C.UTF-8', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'PMIX_DSTORE_21_BASE_PATH': '/tmp/ompi.algo-1.0/pid.120/pmix_dstor_ds21_120', 'SM_IS_HETERO': 'false', 'OMPI_MCA_orte_num_nodes': '2', 'SM_CURRENT_INSTANCE_TYPE': 'ml.p3.16xlarge', 'PMIX_VERSION': '3.2.3', 'CUDA_VERSION': '11.3.1', 'SMDATAPARALLEL_LOCAL_RANK': '3', 'DMLC_INTERFACE': 'eth0', 'OMPI_MCA_orte_tag_output': '1', 'SM_NUM_CPUS': '64', 'CMAKE_PREFIX_PATH': '$(dirname $(which conda))/../', 'DGLBACKEND': 'pytorch', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_HP_BATCH_SIZE': '8', 'USE_SMDEBUG': '0', 'OMPI_MCA_orte_tmpdir_base': '/tmp', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'PMIX_RANK': '3', 'PMIX_SERVER_URI2': '2694709248.0;tcp4://127.0.0.1:32795', 'PMIX_SERVER_URI3': '2694709248.0;tcp4://127.0.0.1:32795', 'SM_CURRENT_HOST': 'algo-1', 'OMPI_MCA_initial_wdir': '/opt/ml/code', 'OMPI_FIRST_RANKS': '0', 'SM_INSTANCE_GROUPS': '[\"homogeneousCluster\"]', 'OMPI_MCA_mpi_oversubscribe': '0', 'SMDATAPARALLEL_WORLD_SIZE': '16', 'OMPI_MCA_orte_jobfam_session_dir': '/tmp/ompi.algo-1.0/pid.120', 'MASTER_ADDR': 'algo-1', 'SM_INPUT_DATA_CONFIG': '{\"data_path\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}', 'SM_NUM_GPUS': '8', 'SM_I[1,mpirank:4,algo-1]<stdout>:environ({'OMPI_MCA_orte_app_num': '0', 'NVIDIA_VISIBLE_DEVICES': 'all', 'OMPI_MCA_btl_vader_single_copy_mechanism': 'none', 'SAGEMAKER_JOB_NAME': 'pytorch-lightning-2022-08-16-04-40-37-950', 'SM_CHANNELS': '[\"data_path\"]', 'SM_FRAMEWORK_MODULE': 'sagemaker_pytorch_container.training:main', 'OMPI_MCA_orte_precondition_transports': '2c6b6180696abc4e-99036dffeeb77785', 'PYTHONUNBUFFERED': '1', 'OMPI_MCA_shmem_RUNTIME_QUERY_hint': 'mmap', 'OMPI_UNIVERSE_SIZE': '16', 'OMPI_MCA_rmaps_base_oversubscribe': '1', 'PMIX_MCA_mca_base_component_show_load_errors': '1', 'SM_HOSTS': '[\"algo-1\",\"algo-2\"]', 'LOCAL_RANK': '4', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-0f66adf8f3e516732efee12a20cd80ab606b21ea2a19d5d7fde97a2cf76019bf-customer', 'PMIX_HOSTNAME': 'algo-1', 'SAGEMAKER_TRAINING_MODULE': 'sagemaker_pytorch_container.training:main', 'HOSTNAME': 'ip-10-2-236-66.ec2.internal', 'OMPI_COMM_WORLD_NODE_RANK': '4', 'OMPI_MCA_ess_base_vpid': '4', 'SM_MODULE_NAME': 'semantic_segmentation', 'PMIX_SECURITY_MODE': 'native', 'MASTER_PORT': '7592', 'OMPI_MCA_orte_hnp_uri': '2694709248.0;tcp://10.2.236.66:44785', 'NVIDIA_REQUIRE_CUDA': 'cuda>=11.3 brand=tesla,driver>=418,driver<419 driver>=450', 'SMDATAPARALLEL_USE_ENA': '1', 'OMPI_MCA_plm_rsh_num_concurrent': '2', 'MANUAL_BUILD': '0', 'SM_INSTANCE_GROUPS_DICT': '{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}}', 'BRANCH_OFI': '1.3.0-aws', 'TORCH_NVCC_FLAGS': '-Xfatbin -compress-all', 'OMPI_MCA_btl': '^openib', 'SAGEMAKER_INSTANCE_TYPE': 'ml.p3.16xlarge', 'OMPI_COMM_WORLD_LOCAL_RANK': '4', 'TORCH_CUDA_ARCH_LIST': '3.7 5.0 7.0+PTX 8.0', 'NCCL_VERSION': '2.10.3', 'NCCL_SOCKET_IFNAME': 'eth0', 'HFI_NO_BACKTRACE': '1', 'AWS_REGION': 'us-east-1', 'PMIX_GDS_MODULE': 'ds21,ds12,hash', 'PWD': '/opt/ml/code', 'SMDATAPARALLEL_WORLD_RANK': '4', 'OMPI_MCA_orte_abort_on_non_zero_status': '1', 'OMPI_MCA_orte_local_daemon_uri': '2694709248.0;tcp://10.2.236.66:44785', 'RDMAV_FORK_SAFE': '1', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility,compat32,graphics,video', 'OMPI_MCA_oob_tcp_if_include': 'eth0', 'NCCL_DEBUG': 'INFO', 'OMPI_MCA_pml': 'ob1', 'HOROVOD_VERSION': '0.24.3', '_': '/opt/conda/bin/python3.8', 'PMIX_SYSTEM_TMPDIR': '/tmp', 'WORLD_SIZE': '16', 'SM_USER_ENTRY_POINT': 'semantic_segmentation.py', 'OPEN_MPI_PATH': '/opt/amazon/openmpi', 'OMPI_ARGV': '/opt/conda/bin/python3.8 -m mpi4py semantic_segmentation.py --batch_size 8', 'PMIX_BFROP_BUFFER_TYPE': 'PMIX_BFROP_BUFFER_NON_DESC', 'LD_PRELOAD': '/opt/conda/lib/python3.8/site-packages/gethostname.cpython-38-x86_64-linux-gnu.so', 'NV_CUDA_CUDART_VERSION': '11.3.109-1', 'PMIX_PTL_MODULE': 'tcp,usock', 'HOME': '/root', 'FI_PROVIDER': 'efa', 'OMPI_NUM_APP_CTX': '1', 'LANG': 'C.UTF-8', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'PMIX_DSTORE_21_BASE_PATH': '/tmp/ompi.algo-1.0/pid.120/pmix_dstor_ds21_120', 'SM_IS_HETERO': 'false', 'OMPI_MCA_orte_num_nodes': '2', 'SM_CURRENT_INSTANCE_TYPE': 'ml.p3.16xlarge', 'PMIX_VERSION': '3.2.3', 'CUDA_VERSION': '11.3.1', 'SMDATAPARALLEL_LOCAL_RANK': '4', 'DMLC_INTERFACE': 'eth0', 'OMPI_MCA_orte_tag_output': '1', 'SM_NUM_CPUS': '64', 'CMAKE_PREFIX_PATH': '$(dirname $(which conda))/../', 'DGLBACKEND': 'pytorch', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_HP_BATCH_SIZE': '8', 'USE_SMDEBUG': '0', 'OMPI_MCA_orte_tmpdir_base': '/tmp', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'PMIX_RANK': '4', 'PMIX_SERVER_URI2': '2694709248.0;tcp4://127.0.0.1:32795', 'PMIX_SERVER_URI3': '2694709248.0;tcp4://127.0.0.1:32795', 'SM_CURRENT_HOST': 'algo-1', 'OMPI_MCA_initial_wdir': '/opt/ml/code', 'OMPI_FIRST_RANKS': '0', 'SM_INSTANCE_GROUPS': '[\"homogeneousCluster\"]', 'OMPI_MCA_mpi_oversubscribe': '0', 'SMDATAPARALLEL_WORLD_SIZE': '16', 'OMPI_MCA_orte_jobfam_session_dir': '/tmp/ompi.algo-1.0/pid.120', 'MASTER_ADDR': 'algo-1', 'SM_INPUT_DATA_CONFIG': '{\"data_path\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}', 'SM_NUM_GPUS': '8', 'SM_I[1,mpirank:7,algo-1]<stdout>:environ({'OMPI_MCA_orte_app_num': '0', 'NVIDIA_VISIBLE_DEVICES': 'all', 'OMPI_MCA_btl_vader_single_copy_mechanism': 'none', 'SAGEMAKER_JOB_NAME': 'pytorch-lightning-2022-08-16-04-40-37-950', 'SM_CHANNELS': '[\"data_path\"]', 'SM_FRAMEWORK_MODULE': 'sagemaker_pytorch_container.training:main', 'OMPI_MCA_orte_precondition_transports': '2c6b6180696abc4e-99036dffeeb77785', 'PYTHONUNBUFFERED': '1', 'OMPI_MCA_shmem_RUNTIME_QUERY_hint': 'mmap', 'OMPI_UNIVERSE_SIZE': '16', 'OMPI_MCA_rmaps_base_oversubscribe': '1', 'PMIX_MCA_mca_base_component_show_load_errors': '1', 'SM_HOSTS': '[\"algo-1\",\"algo-2\"]', 'LOCAL_RANK': '7', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-0f66adf8f3e516732efee12a20cd80ab606b21ea2a19d5d7fde97a2cf76019bf-customer', 'PMIX_HOSTNAME': 'algo-1', 'SAGEMAKER_TRAINING_MODULE': 'sagemaker_pytorch_container.training:main', 'HOSTNAME': 'ip-10-2-236-66.ec2.internal', 'OMPI_COMM_WORLD_NODE_RANK': '7', 'OMPI_MCA_ess_base_vpid': '7', 'SM_MODULE_NAME': 'semantic_segmentation', 'PMIX_SECURITY_MODE': 'native', 'MASTER_PORT': '7592', 'OMPI_MCA_orte_hnp_uri': '2694709248.0;tcp://10.2.236.66:44785', 'NVIDIA_REQUIRE_CUDA': 'cuda>=11.3 brand=tesla,driver>=418,driver<419 driver>=450', 'SMDATAPARALLEL_USE_ENA': '1', 'OMPI_MCA_plm_rsh_num_concurrent': '2', 'MANUAL_BUILD': '0', 'SM_INSTANCE_GROUPS_DICT': '{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}}', 'BRANCH_OFI': '1.3.0-aws', 'TORCH_NVCC_FLAGS': '-Xfatbin -compress-all', 'OMPI_MCA_btl': '^openib', 'SAGEMAKER_INSTANCE_TYPE': 'ml.p3.16xlarge', 'OMPI_COMM_WORLD_LOCAL_RANK': '7', 'TORCH_CUDA_ARCH_LIST': '3.7 5.0 7.0+PTX 8.0', 'NCCL_VERSION': '2.10.3', 'NCCL_SOCKET_IFNAME': 'eth0', 'HFI_NO_BACKTRACE': '1', 'AWS_REGION': 'us-east-1', 'PMIX_GDS_MODULE': 'ds21,ds12,hash', 'PWD': '/opt/ml/code', 'SMDATAPARALLEL_WORLD_RANK': '7', 'OMPI_MCA_orte_abort_on_non_zero_status': '1', 'OMPI_MCA_orte_local_daemon_uri': '2694709248.0;tcp://10.2.236.66:44785', 'RDMAV_FORK_SAFE': '1', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility,compat32,graphics,video', 'OMPI_MCA_oob_tcp_if_include': 'eth0', 'NCCL_DEBUG': 'INFO', 'OMPI_MCA_pml': 'ob1', 'HOROVOD_VERSION': '0.24.3', '_': '/opt/conda/bin/python3.8', 'PMIX_SYSTEM_TMPDIR': '/tmp', 'WORLD_SIZE': '16', 'SM_USER_ENTRY_POINT': 'semantic_segmentation.py', 'OPEN_MPI_PATH': '/opt/amazon/openmpi', 'OMPI_ARGV': '/opt/conda/bin/python3.8 -m mpi4py semantic_segmentation.py --batch_size 8', 'PMIX_BFROP_BUFFER_TYPE': 'PMIX_BFROP_BUFFER_NON_DESC', 'LD_PRELOAD': '/opt/conda/lib/python3.8/site-packages/gethostname.cpython-38-x86_64-linux-gnu.so', 'NV_CUDA_CUDART_VERSION': '11.3.109-1', 'PMIX_PTL_MODULE': 'tcp,usock', 'HOME': '/root', 'FI_PROVIDER': 'efa', 'OMPI_NUM_APP_CTX': '1', 'LANG': 'C.UTF-8', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'PMIX_DSTORE_21_BASE_PATH': '/tmp/ompi.algo-1.0/pid.120/pmix_dstor_ds21_120', 'SM_IS_HETERO': 'false', 'OMPI_MCA_orte_num_nodes': '2', 'SM_CURRENT_INSTANCE_TYPE': 'ml.p3.16xlarge', 'PMIX_VERSION': '3.2.3', 'CUDA_VERSION': '11.3.1', 'SMDATAPARALLEL_LOCAL_RANK': '7', 'DMLC_INTERFACE': 'eth0', 'OMPI_MCA_orte_tag_output': '1', 'SM_NUM_CPUS': '64', 'CMAKE_PREFIX_PATH': '$(dirname $(which conda))/../', 'DGLBACKEND': 'pytorch', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_HP_BATCH_SIZE': '8', 'USE_SMDEBUG': '0', 'OMPI_MCA_orte_tmpdir_base': '/tmp', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'PMIX_RANK': '7', 'PMIX_SERVER_URI2': '2694709248.0;tcp4://127.0.0.1:32795', 'PMIX_SERVER_URI3': '2694709248.0;tcp4://127.0.0.1:32795', 'SM_CURRENT_HOST': 'algo-1', 'OMPI_MCA_initial_wdir': '/opt/ml/code', 'OMPI_FIRST_RANKS': '0', 'SM_INSTANCE_GROUPS': '[\"homogeneousCluster\"]', 'OMPI_MCA_mpi_oversubscribe': '0', 'SMDATAPARALLEL_WORLD_SIZE': '16', 'OMPI_MCA_orte_jobfam_session_dir': '/tmp/ompi.algo-1.0/pid.120', 'MASTER_ADDR': 'algo-1', 'SM_INPUT_DATA_CONFIG': '{\"data_path\":{\"RecordWra\u001b[0m\n",
      "\u001b[34mpperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}', 'SM_NUM_GPUS': '8', 'SM_I[1,mpirank:0,algo-1]<stdout>:NPUT_DIR': '/opt/ml/input', 'SM_RESOURCE_CONFIG': '{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.16xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}],\"network_interface_name\":\"eth0\"}', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'PYTHONPATH': '/opt/ml/code:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220722-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg', 'PMIX_SERVER_URI21': '2694709248.0;tcp4://127.0.0.1:32795', 'SM_LOG_LEVEL': '20', 'SM_DISTRIBUTION_INSTANCE_GROUPS': '[\"homogeneousCluster\"]', 'PMIX_DSTORE_ESH_BASE_PATH': '/tmp/ompi.algo-1.0/pid.120/pmix_dstor_ds12_120', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_pytorch_ddp_enabled\":true},\"channel_input_dirs\":{\"data_path\":\"/opt/ml/input/data/data_path\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.p3.16xlarge\",\"distribution_hosts\":[\"algo-1\",\"algo-2\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"batch_size\":8},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"data_path\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"pytorch-lightning-2022-08-16-04-40-37-950\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-631450739534/pytorch-lightning-2022-08-16-04-40-37-950/source/sourcedir.tar.gz\",\"module_name\":\"semantic_segmentation\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.16xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"semantic_segmentation.py\"}', 'SM_CURRENT_INSTANCE_GROUP': 'homogeneousCluster', 'OMPI_MCA_orte_ess_num_procs': '16', 'OMPI_FILE_LOCATION': '/tmp/ompi.algo-1.0/pid.120/0/0', 'PYTHONIOENCODING': 'UTF-8', 'OMPI_MCA_plm_rsh_no_tree_spawn': '1', 'OMPI_COMM_WORLD_SIZE': '16', 'OMPI_MCA_orte_ess_node_rank': '0', 'SHLVL': '4', 'SAGEMAKER_REGION': 'us-east-1', 'SMDATAPARALLEL_SERVER_PORT': '7592', 'NVARCH': 'x86_64', 'PMIX_ID': '2694709249.0', 'CUDNN_VERSION': '8.2.0.53', 'SMDATAPARALLEL_SERVER_ADDR': 'algo-1', 'OMPI_COMM_WORLD_LOCAL_SIZE': '8', 'EFA_VERSION': '1.15.1', 'PYTHONDONTWRITEBYTECODE': '1', 'NV_CUDA_COMPAT_PACKAGE': 'cuda-compat-11-3', 'PMIX_SERVER_TMPDIR': '/tmp/ompi.algo-1.0/pid.120', 'SM_CURRENT_INSTANCE_GROUP_HOSTS': '[\"algo-1\",\"algo-2\"]', 'LD_LIBRARY_PATH': '/opt/amazon/openmpi/lib:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/amazon/openmpi/lib/:/opt/amazon/efa/lib/:/opt/conda/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64', 'NCCL_IB_DISABLE': '1', 'OMPI_COMMAND': 'smddprun', 'RANK': '0', 'OMPI_MCA_ess': '^singleton', 'OMPI_VERSION': '4.1.1', 'SM_FRAMEWORK_PARAMS': '{\"sagemaker_instance_type\":\"ml.p3.[1,mpirank:3,algo-1]<stdout>:NPUT_DIR': '/opt/ml/input', 'SM_RESOURCE_CONFIG': '{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.16xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}],\"network_interface_name\":\"eth0\"}', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'PYTHONPATH': '/opt/ml/code:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220722-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg', 'PMIX_SERVER_URI21': '2694709248.0;tcp4://127.0.0.1:32795', 'SM_LOG_LEVEL': '20', 'SM_DISTRIBUTION_INSTANCE_GROUPS': '[\"homogeneousCluster\"]', 'PMIX_DSTORE_ESH_BASE_PATH': '/tmp/ompi.algo-1.0/pid.120/pmix_dstor_ds12_120', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_pytorch_ddp_enabled\":true},\"channel_input_dirs\":{\"data_path\":\"/opt/ml/input/data/data_path\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.p3.16xlarge\",\"distribution_hosts\":[\"algo-1\",\"algo-2\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"batch_size\":8},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"data_path\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"pytorch-lightning-2022-08-16-04-40-37-950\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-631450739534/pytorch-lightning-2022-08-16-04-40-37-950/source/sourcedir.tar.gz\",\"module_name\":\"semantic_segmentation\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.16xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"semantic_segmentation.py\"}', 'SM_CURRENT_INSTANCE_GROUP': 'homogeneousCluster', 'OMPI_MCA_orte_ess_num_procs': '16', 'OMPI_FILE_LOCATION': '/tmp/ompi.algo-1.0/pid.120/0/0', 'PYTHONIOENCODING': 'UTF-8', 'OMPI_MCA_plm_rsh_no_tree_spawn': '1', 'OMPI_COMM_WORLD_SIZE': '16', 'OMPI_MCA_orte_ess_node_rank': '3', 'SHLVL': '4', 'SAGEMAKER_REGION': 'us-east-1', 'SMDATAPARALLEL_SERVER_PORT': '7592', 'NVARCH': 'x86_64', 'PMIX_ID': '2694709249.3', 'CUDNN_VERSION': '8.2.0.53', 'SMDATAPARALLEL_SERVER_ADDR': 'algo-1', 'OMPI_COMM_WORLD_LOCAL_SIZE': '8', 'EFA_VERSION': '1.15.1', 'PYTHONDONTWRITEBYTECODE': '1', 'NV_CUDA_COMPAT_PACKAGE': 'cuda-compat-11-3', 'PMIX_SERVER_TMPDIR': '/tmp/ompi.algo-1.0/pid.120', 'SM_CURRENT_INSTANCE_GROUP_HOSTS': '[\"algo-1\",\"algo-2\"]', 'LD_LIBRARY_PATH': '/opt/amazon/openmpi/lib:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/amazon/openmpi/lib/:/opt/amazon/efa/lib/:/opt/conda/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64', 'NCCL_IB_DISABLE': '1', 'OMPI_COMMAND': 'smddprun', 'RANK': '3', 'OMPI_MCA_ess': '^singleton', 'OMPI_VERSION': '4.1.1', 'SM_FRAMEWORK_PARAMS': '{\"sagemaker_instance_type\":\"ml.p3.[1,mpirank:4,algo-1]<stdout>:NPUT_DIR': '/opt/ml/input', 'SM_RESOURCE_CONFIG': '{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.16xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}],\"network_interface_name\":\"eth0\"}', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'PYTHONPATH': '/opt/ml/code:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220722-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg', 'PMIX_SERVER_URI21': '2694709248.0;tcp4://127.0.0.1:32795', 'SM_LOG_LEVEL': '20', 'SM_DISTRIBUTION_INSTANCE_GROUPS': '[\"homogeneousCluster\"]', 'PMIX_DSTORE_ESH_BASE_PATH': '/tmp/ompi.algo-1.0/pid.120/pmix_dstor_ds12_120', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_pytorch_ddp_enabled\":true},\"channel_input_dirs\":{\"data_path\":\"/opt/ml/input/data/data_path\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.p3.16xlarge\",\"distribution_hosts\":[\"algo-1\",\"algo-2\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"batch_size\":8},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"data_path\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"pytorch-lightning-2022-08-16-04-40-37-950\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-631450739534/pytorch-lightning-2022-08-16-04-40-37-950/source/sourcedir.tar.gz\",\"module_name\":\"semantic_segmentation\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.16xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"semantic_segmentation.py\"}', 'SM_CURRENT_INSTANCE_GROUP': 'homogeneousCluster', 'OMPI_MCA_orte_ess_num_procs': '16', 'OMPI_FILE_LOCATION': '/tmp/ompi.algo-1.0/pid.120/0/0', 'PYTHONIOENCODING': 'UTF-8', 'OMPI_MCA_plm_rsh_no_tree_spawn': '1', 'OMPI_COMM_WORLD_SIZE': '16', 'OMPI_MCA_orte_ess_node_rank': '4', 'SHLVL': '4', 'SAGEMAKER_REGION': 'us-east-1', 'SMDATAPARALLEL_SERVER_PORT': '7592', 'NVARCH': 'x86_64', 'PMIX_ID': '2694709249.4', 'CUDNN_VERSION': '8.2.0.53', 'SMDATAPARALLEL_SERVER_ADDR': 'algo-1', 'OMPI_COMM_WORLD_LOCAL_SIZE': '8', 'EFA_VERSION': '1.15.1', 'PYTHONDONTWRITEBYTECODE': '1', 'NV_CUDA_COMPAT_PACKAGE': 'cuda-compat-11-3', 'PMIX_SERVER_TMPDIR': '/tmp/ompi.algo-1.0/pid.120', 'SM_CURRENT_INSTANCE_GROUP_HOSTS': '[\"algo-1\",\"algo-2\"]', 'LD_LIBRARY_PATH': '/opt/amazon/openmpi/lib:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/amazon/openmpi/lib/:/opt/amazon/efa/lib/:/opt/conda/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64', 'NCCL_IB_DISABLE': '1', 'OMPI_COMMAND': 'smddprun', 'RANK': '4', 'OMPI_MCA_ess': '^singleton', 'OMPI_VERSION': '4.1.1', 'SM_FRAMEWORK_PARAMS': '{\"sagemaker_instance_type\":\"ml.p3.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:NPUT_DIR': '/opt/ml/input', 'SM_RESOURCE_CONFIG': '{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.16xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}],\"network_interface_name\":\"eth0\"}', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'PYTHONPATH': '/opt/ml/code:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220722-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg', 'PMIX_SERVER_URI21': '2694709248.0;tcp4://127.0.0.1:32795', 'SM_LOG_LEVEL': '20', 'SM_DISTRIBUTION_INSTANCE_GROUPS': '[\"homogeneousCluster\"]', 'PMIX_DSTORE_ESH_BASE_PATH': '/tmp/ompi.algo-1.0/pid.120/pmix_dstor_ds12_120', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_pytorch_ddp_enabled\":true},\"channel_input_dirs\":{\"data_path\":\"/opt/ml/input/data/data_path\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.p3.16xlarge\",\"distribution_hosts\":[\"algo-1\",\"algo-2\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"batch_size\":8},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"data_path\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"pytorch-lightning-2022-08-16-04-40-37-950\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-631450739534/pytorch-lightning-2022-08-16-04-40-37-950/source/sourcedir.tar.gz\",\"module_name\":\"semantic_segmentation\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.16xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"semantic_segmentation.py\"}', 'SM_CURRENT_INSTANCE_GROUP': 'homogeneousCluster', 'OMPI_MCA_orte_ess_num_procs': '16', 'OMPI_FILE_LOCATION': '/tmp/ompi.algo-1.0/pid.120/0/0', 'PYTHONIOENCODING': 'UTF-8', 'OMPI_MCA_plm_rsh_no_tree_spawn': '1', 'OMPI_COMM_WORLD_SIZE': '16', 'OMPI_MCA_orte_ess_node_rank': '7', 'SHLVL': '4', 'SAGEMAKER_REGION': 'us-east-1', 'SMDATAPARALLEL_SERVER_PORT': '7592', 'NVARCH': 'x86_64', 'PMIX_ID': '2694709249.7', 'CUDNN_VERSION': '8.2.0.53', 'SMDATAPARALLEL_SERVER_ADDR': 'algo-1', 'OMPI_COMM_WORLD_LOCAL_SIZE': '8', 'EFA_VERSION': '1.15.1', 'PYTHONDONTWRITEBYTECODE': '1', 'NV_CUDA_COMPAT_PACKAGE': 'cuda-compat-11-3', 'PMIX_SERVER_TMPDIR': '/tmp/ompi.algo-1.0/pid.120', 'SM_CURRENT_INSTANCE_GROUP_HOSTS': '[\"algo-1\",\"algo-2\"]', 'LD_LIBRARY_PATH': '/opt/amazon/openmpi/lib:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/amazon/openmpi/lib/:/opt/amazon/efa/lib/:/opt/conda/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64', 'NCCL_IB_DISABLE': '1', 'OMPI_COMMAND': 'smddprun', 'RANK': '7', 'OMPI_MCA_ess': '^singleton', 'OMPI_VERSION': '4.1.1', 'SM_FRAMEWORK_PARAMS': '{\"sagemaker_instance_type\":\"ml.p3.[1,mpirank:1,algo-1]<stdout>:environ({'OMPI_MCA_orte_app_num': '0', 'NVIDIA_VISIBLE_DEVICES': 'all', 'OMPI_MCA_btl_vader_single_copy_mechanism': 'none', 'SAGEMAKER_JOB_NAME': 'pytorch-lightning-2022-08-16-04-40-37-950', 'SM_CHANNELS': '[\"data_path\"]', 'SM_FRAMEWORK_MODULE': 'sagemaker_pytorch_container.training:main', 'OMPI_MCA_orte_precondition_transports': '2c6b6180696abc4e-99036dffeeb77785', 'PYTHONUNBUFFERED': '1', 'OMPI_MCA_shmem_RUNTIME_QUERY_hint': 'mmap', 'OMPI_UNIVERSE_SIZE': '16', 'OMPI_MCA_rmaps_base_oversubscribe': '1', 'PMIX_MCA_mca_base_component_show_load_errors': '1', 'SM_HOSTS': '[\"algo-1\",\"algo-2\"]', 'LOCAL_RANK': '1', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-0f66adf8f3e516732efee12a20cd80ab606b21ea2a19d5d7fde97a2cf76019bf-customer', 'PMIX_HOSTNAME': 'algo-1', 'SAGEMAKER_TRAINING_MODULE': 'sagemaker_pytorch_container.training:main', 'HOSTNAME': 'ip-10-2-236-66.ec2.internal', 'OMPI_COMM_WORLD_NODE_RANK': '1', 'OMPI_MCA_ess_base_vpid': '1', 'SM_MODULE_NAME': 'semantic_segmentation', 'PMIX_SECURITY_MODE': 'native', 'MASTER_PORT': '7592', 'OMPI_MCA_orte_hnp_uri': '2694709248.0;tcp://10.2.236.66:44785', 'NVIDIA_REQUIRE_CUDA': 'cuda>=11.3 brand=tesla,driver>=418,driver<419 driver>=450', 'SMDATAPARALLEL_USE_ENA': '1', 'OMPI_MCA_plm_rsh_num_concurrent': '2', 'MANUAL_BUILD': '0', 'SM_INSTANCE_GROUPS_DICT': '{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}}', 'BRANCH_OFI': '1.3.0-aws', 'TORCH_NVCC_FLAGS': '-Xfatbin -compress-all', 'OMPI_MCA_btl': '^openib', 'SAGEMAKER_INSTANCE_TYPE': 'ml.p3.16xlarge', 'OMPI_COMM_WORLD_LOCAL_RANK': '1', 'TORCH_CUDA_ARCH_LIST': '3.7 5.0 7.0+PTX 8.0', 'NCCL_VERSION': '2.10.3', 'NCCL_SOCKET_IFNAME': 'eth0', 'HFI_NO_BACKTRACE': '1', 'AWS_REGION': 'us-east-1', 'PMIX_GDS_MODULE': 'ds21,ds12,hash', 'PWD': '/opt/ml/code', 'SMDATAPARALLEL_WORLD_RANK': '1', 'OMPI_MCA_orte_abort_on_non_zero_status': '1', 'OMPI_MCA_orte_local_daemon_uri': '2694709248.0;tcp://10.2.236.66:44785', 'RDMAV_FORK_SAFE': '1', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility,compat32,graphics,video', 'OMPI_MCA_oob_tcp_if_include': 'eth0', 'NCCL_DEBUG': 'INFO', 'OMPI_MCA_pml': 'ob1', 'HOROVOD_VERSION': '0.24.3', '_': '/opt/conda/bin/python3.8', 'PMIX_SYSTEM_TMPDIR': '/tmp', 'WORLD_SIZE': '16', 'SM_USER_ENTRY_POINT': 'semantic_segmentation.py', 'OPEN_MPI_PATH': '/opt/amazon/openmpi', 'OMPI_ARGV': '/opt/conda/bin/python3.8 -m mpi4py semantic_segmentation.py --batch_size 8', 'PMIX_BFROP_BUFFER_TYPE': 'PMIX_BFROP_BUFFER_NON_DESC', 'LD_PRELOAD': '/opt/conda/lib/python3.8/site-packages/gethostname.cpython-38-x86_64-linux-gnu.so', 'NV_CUDA_CUDART_VERSION': '11.3.109-1', 'PMIX_PTL_MODULE': 'tcp,usock', 'HOME': '/root', 'FI_PROVIDER': 'efa', 'OMPI_NUM_APP_CTX': '1', 'LANG': 'C.UTF-8', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'PMIX_DSTORE_21_BASE_PATH': '/tmp/ompi.algo-1.0/pid.120/pmix_dstor_ds21_120', 'SM_IS_HETERO': 'false', 'OMPI_MCA_orte_num_nodes': '2', 'SM_CURRENT_INSTANCE_TYPE': 'ml.p3.16xlarge', 'PMIX_VERSION': '3.2.3', 'CUDA_VERSION': '11.3.1', 'SMDATAPARALLEL_LOCAL_RANK': '1', 'DMLC_INTERFACE': 'eth0', 'OMPI_MCA_orte_tag_output': '1', 'SM_NUM_CPUS': '64', 'CMAKE_PREFIX_PATH': '$(dirname $(which conda))/../', 'DGLBACKEND': 'pytorch', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_HP_BATCH_SIZE': '8', 'USE_SMDEBUG': '0', 'OMPI_MCA_orte_tmpdir_base': '/tmp', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'PMIX_RANK': '1', 'PMIX_SERVER_URI2': '2694709248.0;tcp4://127.0.0.1:32795', 'PMIX_SERVER_URI3': '2694709248.0;tcp4://127.0.0.1:32795', 'SM_CURRENT_HOST': 'algo-1', 'OMPI_MCA_initial_wdir': '/opt/ml/code', 'OMPI_FIRST_RANKS': '0', 'SM_INSTANCE_GROUPS': '[\"homogeneousCluster\"]', 'OMPI_MCA_mpi_oversubscribe': '0', 'SMDATAPARALLEL_WORLD_SIZE': '16', 'OMPI_MCA_orte_jobfam_session_dir': '/tmp/ompi.algo-1.0/pid.120', 'MASTER_ADDR': 'algo-1', 'SM_INPUT_DATA_CONFIG': '{\"data_path\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}', 'SM_NUM_GPUS': '8', 'SM_I[1,mpirank:2,algo-1]<stdout>:environ({'OMPI_MCA_orte_app_num': '0', 'NVIDIA_VISIBLE_DEVICES': 'all', 'OMPI_MCA_btl_vader_single_copy_mechanism': 'none', 'SAGEMAKER_JOB_NAME': 'pytorch-lightning-2022-08-16-04-40-37-950', 'SM_CHANNELS': '[\"data_path\"]', 'SM_FRAMEWORK_MODULE': 'sagemaker_pytorch_container.training:main', 'OMPI_MCA_orte_precondition_transports': '2c6b6180696abc4e-99036dffeeb77785', 'PYTHONUNBUFFERED': '1', 'OMPI_MCA_shmem_RUNTIME_QUERY_hint': 'mmap', 'OMPI_UNIVERSE_SIZE': '16', 'OMPI_MCA_rmaps_base_oversubscribe': '1', 'PMIX_MCA_mca_base_component_show_load_errors': '1', 'SM_HOSTS': '[\"algo-1\",\"algo-2\"]', 'LOCAL_RANK': '2', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-0f66adf8f3e516732efee12a20cd80ab606b21ea2a19d5d7fde97a2cf76019bf-customer', 'PMIX_HOSTNAME': 'algo-1', 'SAGEMAKER_TRAINING_MODULE': 'sagemaker_pytorch_container.training:main', 'HOSTNAME': 'ip-10-2-236-66.ec2.internal', 'OMPI_COMM_WORLD_NODE_RANK': '2', 'OMPI_MCA_ess_base_vpid': '2', 'SM_MODULE_NAME': 'semantic_segmentation', 'PMIX_SECURITY_MODE': 'native', 'MASTER_PORT': '7592', 'OMPI_MCA_orte_hnp_uri': '2694709248.0;tcp://10.2.236.66:44785', 'NVIDIA_REQUIRE_CUDA': 'cuda>=11.3 brand=tesla,driver>=418,driver<419 driver>=450', 'SMDATAPARALLEL_USE_ENA': '1', 'OMPI_MCA_plm_rsh_num_concurrent': '2', 'MANUAL_BUILD': '0', 'SM_INSTANCE_GROUPS_DICT': '{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}}', 'BRANCH_OFI': '1.3.0-aws', 'TORCH_NVCC_FLAGS': '-Xfatbin -compress-all', 'OMPI_MCA_btl': '^openib', 'SAGEMAKER_INSTANCE_TYPE': 'ml.p3.16xlarge', 'OMPI_COMM_WORLD_LOCAL_RANK': '2', 'TORCH_CUDA_ARCH_LIST': '3.7 5.0 7.0+PTX 8.0', 'NCCL_VERSION': '2.10.3', 'NCCL_SOCKET_IFNAME': 'eth0', 'HFI_NO_BACKTRACE': '1', 'AWS_REGION': 'us-east-1', 'PMIX_GDS_MODULE': 'ds21,ds12,hash', 'PWD': '/opt/ml/code', 'SMDATAPARALLEL_WORLD_RANK': '2', 'OMPI_MCA_orte_abort_on_non_zero_status': '1', 'OMPI_MCA_orte_local_daemon_uri': '2694709248.0;tcp://10.2.236.66:44785', 'RDMAV_FORK_SAFE': '1', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility,compat32,graphics,video', 'OMPI_MCA_oob_tcp_if_include': 'eth0', 'NCCL_DEBUG': 'INFO', 'OMPI_MCA_pml': 'ob1', 'HOROVOD_VERSION': '0.24.3', '_': '/opt/conda/bin/python3.8', 'PMIX_SYSTEM_TMPDIR': '/tmp', 'WORLD_SIZE': '16', 'SM_USER_ENTRY_POINT': 'semantic_segmentation.py', 'OPEN_MPI_PATH': '/opt/amazon/openmpi', 'OMPI_ARGV': '/opt/conda/bin/python3.8 -m mpi4py semantic_segmentation.py --batch_size 8', 'PMIX_BFROP_BUFFER_TYPE': 'PMIX_BFROP_BUFFER_NON_DESC', 'LD_PRELOAD': '/opt/conda/lib/python3.8/site-packages/gethostname.cpython-38-x86_64-linux-gnu.so', 'NV_CUDA_CUDART_VERSION': '11.3.109-1', 'PMIX_PTL_MODULE': 'tcp,usock', 'HOME': '/root', 'FI_PROVIDER': 'efa', 'OMPI_NUM_APP_CTX': '1', 'LANG': 'C.UTF-8', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'PMIX_DSTORE_21_BASE_PATH': '/tmp/ompi.algo-1.0/pid.120/pmix_dstor_ds21_120', 'SM_IS_HETERO': 'false', 'OMPI_MCA_orte_num_nodes': '2', 'SM_CURRENT_INSTANCE_TYPE': 'ml.p3.16xlarge', 'PMIX_VERSION': '3.2.3', 'CUDA_VERSION': '11.3.1', 'SMDATAPARALLEL_LOCAL_RANK': '2', 'DMLC_INTERFACE': 'eth0', 'OMPI_MCA_orte_tag_output': '1', 'SM_NUM_CPUS': '64', 'CMAKE_PREFIX_PATH': '$(dirname $(which conda))/../', 'DGLBACKEND': 'pytorch', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_HP_BATCH_SIZE': '8', 'USE_SMDEBUG': '0', 'OMPI_MCA_orte_tmpdir_base': '/tmp', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'PMIX_RANK': '2', 'PMIX_SERVER_URI2': '2694709248.0;tcp4://127.0.0.1:32795', 'PMIX_SERVER_URI3': '2694709248.0;tcp4://127.0.0.1:32795', 'SM_CURRENT_HOST': 'algo-1', 'OMPI_MCA_initial_wdir': '/opt/ml/code', 'OMPI_FIRST_RANKS': '0', 'SM_INSTANCE_GROUPS': '[\"homogeneousCluster\"]', 'OMPI_MCA_mpi_oversubscribe': '0', 'SMDATAPARALLEL_WORLD_SIZE': '16', 'OMPI_MCA_orte_jobfam_session_dir': '/tmp/ompi.algo-1.0/pid.120', 'MASTER_ADDR': 'algo-1', 'SM_INPUT_DATA_CONFIG': '{\"data_path\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}', 'SM_NUM_GPUS': '8', 'SM_I[1,mpirank:4,algo-1]<stdout>:16xlarge\",\"sagemaker_pytorch_ddp_enabled\":true}', 'SM_MODULE_DIR': 's3://sagemaker-us-east-1-631450739534/pytorch-lightning-2022-08-16-04-40-37-950/source/sourcedir.tar.gz', 'PMIX_NAMESPACE': '2694709249', 'TRAINING_JOB_NAME': 'pytorch-lightning-2022-08-16-04-40-37-950', 'CURRENT_HOST': 'algo-1', 'LC_ALL': 'C.UTF-8', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:631450739534:training-job/pytorch-lightning-2022-08-16-04-40-37-950', 'SM_CHANNEL_DATA_PATH': '/opt/ml/input/data/data_path', 'PATH': '/opt/amazon/openmpi/bin:/opt/amazon/openmpi/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'SM_USER_ARGS': '[\"--batch_size\",\"8\"]', 'OMPI_MCA_pmix': '^s1,s2,cray,isolated', 'OMPI_MCA_ess_base_jobid': '2694709249', 'OMPI_MCA_btl_tcp_if_include': 'eth0', 'SM_HPS': '{\"batch_size\":8}', 'OMPI_APP_CTX_NUM_PROCS': '16', 'SMDATAPARALLEL_USE_HOMOGENEOUS': '1', 'IPATH_NO_BACKTRACE': '1', 'OMPI_MCA_orte_top_session_dir': '/tmp/ompi.algo-1.0', 'OMPI_MCA_orte_launch': '1', 'SMDATAPARALLEL_NUM_CONN': '5', 'SM_MODEL_DIR': '/opt/ml/model', 'DLC_CONTAINER_TYPE': 'training', 'OMPI_COMM_WORLD_RANK': '4'})\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:16xlarge\",\"sagemaker_pytorch_ddp_enabled\":true}', 'SM_MODULE_DIR': 's3://sagemaker-us-east-1-631450739534/pytorch-lightning-2022-08-16-04-40-37-950/source/sourcedir.tar.gz', 'PMIX_NAMESPACE': '2694709249', 'TRAINING_JOB_NAME': 'pytorch-lightning-2022-08-16-04-40-37-950', 'CURRENT_HOST': 'algo-1', 'LC_ALL': 'C.UTF-8', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:631450739534:training-job/pytorch-lightning-2022-08-16-04-40-37-950', 'SM_CHANNEL_DATA_PATH': '/opt/ml/input/data/data_path', 'PATH': '/opt/amazon/openmpi/bin:/opt/amazon/openmpi/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'SM_USER_ARGS': '[\"--batch_size\",\"8\"]', 'OMPI_MCA_pmix': '^s1,s2,cray,isolated', 'OMPI_MCA_ess_base_jobid': '2694709249', 'OMPI_MCA_btl_tcp_if_include': 'eth0', 'SM_HPS': '{\"batch_size\":8}', 'OMPI_APP_CTX_NUM_PROCS': '16', 'SMDATAPARALLEL_USE_HOMOGENEOUS': '1', 'IPATH_NO_BACKTRACE': '1', 'OMPI_MCA_orte_top_session_dir': '/tmp/ompi.algo-1.0', 'OMPI_MCA_orte_launch': '1', 'SMDATAPARALLEL_NUM_CONN': '5', 'SM_MODEL_DIR': '/opt/ml/model', 'DLC_CONTAINER_TYPE': 'training', 'OMPI_COMM_WORLD_RANK': '0'})\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:environ({'OMPI_MCA_orte_app_num': '0', 'NVIDIA_VISIBLE_DEVICES': 'all', 'OMPI_MCA_btl_vader_single_copy_mechanism': 'none', 'SAGEMAKER_JOB_NAME': 'pytorch-lightning-2022-08-16-04-40-37-950', 'SM_CHANNELS': '[\"data_path\"]', 'SM_FRAMEWORK_MODULE': 'sagemaker_pytorch_container.training:main', 'OMPI_MCA_orte_precondition_transports': '2c6b6180696abc4e-99036dffeeb77785', 'PYTHONUNBUFFERED': '1', 'OMPI_MCA_shmem_RUNTIME_QUERY_hint': 'mmap', 'OMPI_UNIVERSE_SIZE': '16', 'OMPI_MCA_rmaps_base_oversubscribe': '1', 'PMIX_MCA_mca_base_component_show_load_errors': '1', 'SM_HOSTS': '[\"algo-1\",\"algo-2\"]', 'LOCAL_RANK': '5', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-0f66adf8f3e516732efee12a20cd80ab606b21ea2a19d5d7fde97a2cf76019bf-customer', 'PMIX_HOSTNAME': 'algo-1', 'SAGEMAKER_TRAINING_MODULE': 'sagemaker_pytorch_container.training:main', 'HOSTNAME': 'ip-10-2-236-66.ec2.internal', 'OMPI_COMM_WORLD_NODE_RANK': '5', 'OMPI_MCA_ess_base_vpid': '5', 'SM_MODULE_NAME': 'semantic_segmentation', 'PMIX_SECURITY_MODE': 'native', 'MASTER_PORT': '7592', 'OMPI_MCA_orte_hnp_uri': '2694709248.0;tcp://10.2.236.66:44785', 'NVIDIA_REQUIRE_CUDA': 'cuda>=11.3 brand=tesla,driver>=418,driver<419 driver>=450', 'SMDATAPARALLEL_USE_ENA': '1', 'OMPI_MCA_plm_rsh_num_concurrent': '2', 'MANUAL_BUILD': '0', 'SM_INSTANCE_GROUPS_DICT': '{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}}', 'BRANCH_OFI': '1.3.0-aws', 'TORCH_NVCC_FLAGS': '-Xfatbin -compress-all', 'OMPI_MCA_btl': '^openib', 'SAGEMAKER_INSTANCE_TYPE': 'ml.p3.16xlarge', 'OMPI_COMM_WORLD_LOCAL_RANK': '5', 'TORCH_CUDA_ARCH_LIST': '3.7 5.0 7.0+PTX 8.0', 'NCCL_VERSION': '2.10.3', 'NCCL_SOCKET_IFNAME': 'eth0', 'HFI_NO_BACKTRACE': '1', 'AWS_REGION': 'us-east-1', 'PMIX_GDS_MODULE': 'ds21,ds12,hash', 'PWD': '/opt/ml/code', 'SMDATAPARALLEL_WORLD_RANK': '5', 'OMPI_MCA_orte_abort_on_non_zero_status': '1', 'OMPI_MCA_orte_local_daemon_uri': '2694709248.0;tcp://10.2.236.66:44785', 'RDMAV_FORK_SAFE': '1', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility,compat32,graphics,video', 'OMPI_MCA_oob_tcp_if_include': 'eth0', 'NCCL_DEBUG': 'INFO', 'OMPI_MCA_pml': 'ob1', 'HOROVOD_VERSION': '0.24.3', '_': '/opt/conda/bin/python3.8', 'PMIX_SYSTEM_TMPDIR': '/tmp', 'WORLD_SIZE': '16', 'SM_USER_ENTRY_POINT': 'semantic_segmentation.py', 'OPEN_MPI_PATH': '/opt/amazon/openmpi', 'OMPI_ARGV': '/opt/conda/bin/python3.8 -m mpi4py semantic_segmentation.py --batch_size 8', 'PMIX_BFROP_BUFFER_TYPE': 'PMIX_BFROP_BUFFER_NON_DESC', 'LD_PRELOAD': '/opt/conda/lib/python3.8/site-packages/gethostname.cpython-38-x86_64-linux-gnu.so', 'NV_CUDA_CUDART_VERSION': '11.3.109-1', 'PMIX_PTL_MODULE': 'tcp,usock', 'HOME': '/root', 'FI_PROVIDER': 'efa', 'OMPI_NUM_APP_CTX': '1', 'LANG': 'C.UTF-8', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'PMIX_DSTORE_21_BASE_PATH': '/tmp/ompi.algo-1.0/pid.120/pmix_dstor_ds21_120', 'SM_IS_HETERO': 'false', 'OMPI_MCA_orte_num_nodes': '2', 'SM_CURRENT_INSTANCE_TYPE': 'ml.p3.16xlarge', 'PMIX_VERSION': '3.2.3', 'CUDA_VERSION': '11.3.1', 'SMDATAPARALLEL_LOCAL_RANK': '5', 'DMLC_INTERFACE': 'eth0', 'OMPI_MCA_orte_tag_output': '1', 'SM_NUM_CPUS': '64', 'CMAKE_PREFIX_PATH': '$(dirname $(which conda))/../', 'DGLBACKEND': 'pytorch', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_HP_BATCH_SIZE': '8', 'USE_SMDEBUG': '0', 'OMPI_MCA_orte_tmpdir_base': '/tmp', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'PMIX_RANK': '5', 'PMIX_SERVER_URI2': '2694709248.0;tcp4://127.0.0.1:32795', 'PMIX_SERVER_URI3': '2694709248.0;tcp4://127.0.0.1:32795', 'SM_CURRENT_HOST': 'algo-1', 'OMPI_MCA_initial_wdir': '/opt/ml/code', 'OMPI_FIRST_RANKS': '0', 'SM_INSTANCE_GROUPS': '[\"homogeneousCluster\"]', 'OMPI_MCA_mpi_oversubscribe': '0', 'SMDATAPARALLEL_WORLD_SIZE': '16', 'OMPI_MCA_orte_jobfam_session_dir': '/tmp/ompi.algo-1.0/pid.120', 'MASTER_ADDR': 'algo-1', 'SM_INPUT_DATA_CONFIG': '{\"data_path\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}', 'SM_NUM_GPUS': '8', 'SM_I[1,mpirank:6,algo-1]<stdout>:environ({'OMPI_MCA_orte_app_num': '0', 'NVIDIA_VISIBLE_DEVICES': 'all', 'OMPI_MCA_btl_vader_single_copy_mechanism': 'none', 'SAGEMAKER_JOB_NAME': 'pytorch-lightning-2022-08-16-04-40-37-950', 'SM_CHANNELS': '[\"data_path\"]', 'SM_FRAMEWORK_MODULE': 'sagemaker_pytorch_container.training:main', 'OMPI_MCA_orte_precondition_transports': '2c6b6180696abc4e-99036dffeeb77785', 'PYTHONUNBUFFERED': '1', 'OMPI_MCA_shmem_RUNTIME_QUERY_hint': 'mmap', 'OMPI_UNIVERSE_SIZE': '16', 'OMPI_MCA_rmaps_base_oversubscribe': '1', 'PMIX_MCA_mca_base_component_show_load_errors': '1', 'SM_HOSTS': '[\"algo-1\",\"algo-2\"]', 'LOCAL_RANK': '6', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-0f66adf8f3e516732efee12a20cd80ab606b21ea2a19d5d7fde97a2cf76019bf-customer', 'PMIX_HOSTNAME': 'algo-1', 'SAGEMAKER_TRAINING_MODULE': 'sagemaker_pytorch_container.training:main', 'HOSTNAME': 'ip-10-2-236-66.ec2.internal', 'OMPI_COMM_WORLD_NODE_RANK': '6', 'OMPI_MCA_ess_base_vpid': '6', 'SM_MODULE_NAME': 'semantic_segmentation', 'PMIX_SECURITY_MODE': 'native', 'MASTER_PORT': '7592', 'OMPI_MCA_orte_hnp_uri': '2694709248.0;tcp://10.2.236.66:44785', 'NVIDIA_REQUIRE_CUDA': 'cuda>=11.3 brand=tesla,driver>=418,driver<419 driver>=450', 'SMDATAPARALLEL_USE_ENA': '1', 'OMPI_MCA_plm_rsh_num_concurrent': '2', 'MANUAL_BUILD': '0', 'SM_INSTANCE_GROUPS_DICT': '{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}}', 'BRANCH_OFI': '1.3.0-aws', 'TORCH_NVCC_FLAGS': '-Xfatbin -compress-all', 'OMPI_MCA_btl': '^openib', 'SAGEMAKER_INSTANCE_TYPE': 'ml.p3.16xlarge', 'OMPI_COMM_WORLD_LOCAL_RANK': '6', 'TORCH_CUDA_ARCH_LIST': '3.7 5.0 7.0+PTX 8.0', 'NCCL_VERSION': '2.10.3', 'NCCL_SOCKET_IFNAME': 'eth0', 'HFI_NO_BACKTRACE': '1', 'AWS_REGION': 'us-east-1', 'PMIX_GDS_MODULE': 'ds21,ds12,hash', 'PWD': '/opt/ml/code', 'SMDATAPARALLEL_WORLD_RANK': '6', 'OMPI_MCA_orte_abort_on_non_zero_status': '1', 'OMPI_MCA_orte_local_daemon_uri': '2694709248.0;tcp://10.2.236.66:44785', 'RDMAV_FORK_SAFE': '1', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility,compat32,graphics,video', 'OMPI_MCA_oob_tcp_if_include': 'eth0', 'NCCL_DEBUG': 'INFO', 'OMPI_MCA_pml': 'ob1', 'HOROVOD_VERSION': '0.24.3', '_': '/opt/conda/bin/python3.8', 'PMIX_SYSTEM_TMPDIR': '/tmp', 'WORLD_SIZE': '16', 'SM_USER_ENTRY_POINT': 'semantic_segmentation.py', 'OPEN_MPI_PATH': '/opt/amazon/openmpi', 'OMPI_ARGV': '/opt/conda/bin/python3.8 -m mpi4py semantic_segmentation.py --batch_size 8', 'PMIX_BFROP_BUFFER_TYPE': 'PMIX_BFROP_BUFFER_NON_DESC', 'LD_PRELOAD': '/opt/conda/lib/python3.8/site-packages/gethostname.cpython-38-x86_64-linux-gnu.so', 'NV_CUDA_CUDART_VERSION': '11.3.109-1', 'PMIX_PTL_MODULE': 'tcp,usock', 'HOME': '/root', 'FI_PROVIDER': 'efa', 'OMPI_NUM_APP_CTX': '1', 'LANG': 'C.UTF-8', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'PMIX_DSTORE_21_BASE_PATH': '/tmp/ompi.algo-1.0/pid.120/pmix_dstor_ds21_120', 'SM_IS_HETERO': 'false', 'OMPI_MCA_orte_num_nodes': '2', 'SM_CURRENT_INSTANCE_TYPE': 'ml.p3.16xlarge', 'PMIX_VERSION': '3.2.3', 'CUDA_VERSION': '11.3.1', 'SMDATAPARALLEL_LOCAL_RANK': '6', 'DMLC_INTERFACE': 'eth0', 'OMPI_MCA_orte_tag_output': '1', 'SM_NUM_CPUS': '64', 'CMAKE_PREFIX_PATH': '$(dirname $(which conda))/../', 'DGLBACKEND': 'pytorch', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_HP_BATCH_SIZE': '8', 'USE_SMDEBUG': '0', 'OMPI_MCA_orte_tmpdir_base': '/tmp', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'PMIX_RANK': '6', 'PMIX_SERVER_URI2': '2694709248.0;tcp4://127.0.0.1:32795', 'PMIX_SERVER_URI3': '2694709248.0;tcp4://127.0.0.1:32795', 'SM_CURRENT_HOST': 'algo-1', 'OMPI_MCA_initial_wdir': '/opt/ml/code', 'OMPI_FIRST_RANKS': '0', 'SM_INSTANCE_GROUPS': '[\"homogeneousCluster\"]', 'OMPI_MCA_mpi_oversubscribe': '0', 'SMDATAPARALLEL_WORLD_SIZE': '16', 'OMPI_MCA_orte_jobfam_session_dir': '/tmp/ompi.algo-1.0/pid.120', 'MASTER_ADDR': 'algo-1', 'SM_INPUT_DATA_CONFIG': '{\"data_path\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}', 'SM_NUM_GPUS': '8', 'SM_I[1,mpirank:3,algo-1]<stdout>:16xlarge\",\"sagemaker_pytorch_ddp_enabled\":true}', 'SM_MODULE_DIR': 's3://sagemaker-us-east-1-631450739534/pytorch-lightning-2022-08-16-04-40-37-950/source/sourcedir.tar.gz', 'PMIX_NAMESPACE': '2694709249', 'TRAINING_JOB_NAME': 'pytorch-lightning-2022-08-16-04-40-37-950', 'CURRENT_HOST': 'algo-1', 'LC_ALL': 'C.UTF-8', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:631450739534:training-job/pytorch-lightning-2022-08-16-04-40-37-950', 'SM_CHANNEL_DATA_PATH': '/opt/ml/input/data/data_path', 'PATH': '/opt/amazon/openmpi/bin:/opt/amazon/openmpi/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'SM_USER_ARGS': '[\"--batch_size\",\"8\"]', 'OMPI_MCA_pmix': '^s1,s2,cray,isolated', 'OMPI_MCA_ess_base_jobid': '2694709249', 'OMPI_MCA_btl_tcp_if_include': 'eth0', 'SM_HPS': '{\"batch_size\":8}', 'OMPI_APP_CTX_NUM_PROCS': '16', 'SMDATAPARALLEL_USE_HOMOGENEOUS': '1', 'IPATH_NO_BACKTRACE': '1', 'OMPI_MCA_orte_top_session_dir': '/tmp/ompi.algo-1.0', 'OMPI_MCA_orte_launch': '1', 'SMDATAPARALLEL_NUM_CONN': '5', 'SM_MODEL_DIR': '/opt/ml/model', 'DLC_CONTAINER_TYPE': 'training', 'OMPI_COMM_WORLD_RANK': '3'})\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:16xlarge\",\"sagemaker_pytorch_ddp_enabled\":true}', 'SM_MODULE_DIR': 's3://sagemaker-us-east-1-631450739534/pytorch-lightning-2022-08-16-04-40-37-950/source/sourcedir.tar.gz', 'PMIX_NAMESPACE': '2694709249', 'TRAINING_JOB_NAME': 'pytorch-lightning-2022-08-16-04-40-37-950', 'CURRENT_HOST': 'algo-1', 'LC_ALL': 'C.UTF-8', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:631450739534:training-job/pytorch-lightning-2022-08-16-04-40-37-950', 'SM_CHANNEL_DATA_PATH': '/opt/ml/input/data/data_path', 'PATH': '/opt/amazon/openmpi/bin:/opt/amazon/openmpi/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'SM_USER_ARGS': '[\"--batch_size\",\"8\"]', 'OMPI_MCA_pmix': '^s1,s2,cray,isolated', 'OMPI_MCA_ess_base_jobid': '2694709249', 'OMPI_MCA_btl_tcp_if_include': 'eth0', 'SM_HPS': '{\"batch_size\":8}', 'OMPI_APP_CTX_NUM_PROCS': '16', 'SMDATAPARALLEL_USE_HOMOGENEOUS': '1', 'IPATH_NO_BACKTRACE': '1', 'OMPI_MCA_orte_top_session_dir': '/tmp/ompi.algo-1.0', 'OMPI_MCA_orte_launch': '1', 'SMDATAPARALLEL_NUM_CONN': '5', 'SM_MODEL_DIR': '/opt/ml/model', 'DLC_CONTAINER_TYPE': 'training', 'OMPI_COMM_WORLD_RANK': '7'})\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:NPUT_DIR': '/opt/ml/input', 'SM_RESOURCE_CONFIG': '{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.16xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}],\"network_interface_name\":\"eth0\"}', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'PYTHONPATH': '/opt/ml/code:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220722-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg', 'PMIX_SERVER_URI21': '2694709248.0;tcp4://127.0.0.1:32795', 'SM_LOG_LEVEL': '20', 'SM_DISTRIBUTION_INSTANCE_GROUPS': '[\"homogeneousCluster\"]', 'PMIX_DSTORE_ESH_BASE_PATH': '/tmp/ompi.algo-1.0/pid.120/pmix_dstor_ds12_120', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_pytorch_ddp_enabled\":true},\"channel_input_dirs\":{\"data_path\":\"/opt/ml/input/data/data_path\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.p3.16xlarge\",\"distribution_hosts\":[\"algo-1\",\"algo-2\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"batch_size\":8},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"data_path\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"pytorch-lightning-2022-08-16-04-40-37-950\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-631450739534/pytorch-lightning-2022-08-16-04-40-37-950/source/sourcedir.tar.gz\",\"module_name\":\"semantic_segmentation\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.16xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"semantic_segmentation.py\"}', 'SM_CURRENT_INSTANCE_GROUP': 'homogeneousCluster', 'OMPI_MCA_orte_ess_num_procs': '16', 'OMPI_FILE_LOCATION': '/tmp/ompi.algo-1.0/pid.120/0/0', 'PYTHONIOENCODING': 'UTF-8', 'OMPI_MCA_plm_rsh_no_tree_spawn': '1', 'OMPI_COMM_WORLD_SIZE': '16', 'OMPI_MCA_orte_ess_node_rank': '1', 'SHLVL': '4', 'SAGEMAKER_REGION': 'us-east-1', 'SMDATAPARALLEL_SERVER_PORT': '7592', 'NVARCH': 'x86_64', 'PMIX_ID': '2694709249.1', 'CUDNN_VERSION': '8.2.0.53', 'SMDATAPARALLEL_SERVER_ADDR': 'algo-1', 'OMPI_COMM_WORLD_LOCAL_SIZE': '8', 'EFA_VERSION': '1.15.1', 'PYTHONDONTWRITEBYTECODE': '1', 'NV_CUDA_COMPAT_PACKAGE': 'cuda-compat-11-3', 'PMIX_SERVER_TMPDIR': '/tmp/ompi.algo-1.0/pid.120', 'SM_CURRENT_INSTANCE_GROUP_HOSTS': '[\"algo-1\",\"algo-2\"]', 'LD_LIBRARY_PATH': '/opt/amazon/openmpi/lib:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/amazon/openmpi/lib/:/opt/amazon/efa/lib/:/opt/conda/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64', 'NCCL_IB_DISABLE': '1', 'OMPI_COMMAND': 'smddprun', 'RANK': '1', 'OMPI_MCA_ess': '^singleton', 'OMPI_VERSION': '4.1.1', 'SM_FRAMEWORK_PARAMS': '{\"sagemaker_instance_type\":\"ml.p3.[1,mpirank:2,algo-1]<stdout>:NPUT_DIR': '/opt/ml/input', 'SM_RESOURCE_CONFIG': '{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.16xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}],\"network_interface_name\":\"eth0\"}', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'PYTHONPATH': '/opt/ml/code:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220722-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg', 'PMIX_SERVER_URI21': '2694709248.0;tcp4://127.0.0.1:32795', 'SM_LOG_LEVEL': '20', 'SM_DISTRIBUTION_INSTANCE_GROUPS': '[\"homogeneousCluster\"]', 'PMIX_DSTORE_ESH_BASE_PATH': '/tmp/ompi.algo-1.0/pid.120/pmix_dstor_ds12_120', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_pytorch_ddp_enabled\":true},\"channel_input_dirs\":{\"data_path\":\"/opt/ml/input/data/data_path\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.p3.16xlarge\",\"distribution_hosts\":[\"algo-1\",\"algo-2\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"batch_size\":8},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"data_path\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"pytorch-lightning-2022-08-16-04-40-37-950\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-631450739534/pytorch-lightning-2022-08-16-04-40-37-950/source/sourcedir.tar.gz\",\"module_name\":\"semantic_segmentation\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.16xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"semantic_segmentation.py\"}', 'SM_CURRENT_INSTANCE_GROUP': 'homogeneousCluster', 'OMPI_MCA_orte_ess_num_procs': '16', 'OMPI_FILE_LOCATION': '/tmp/ompi.algo-1.0/pid.120/0/0', 'PYTHONIOENCODING': 'UTF-8', 'OMPI_MCA_plm_rsh_no_tree_spawn': '1', 'OMPI_COMM_WORLD_SIZE': '16', 'OMPI_MCA_orte_ess_node_rank': '2', 'SHLVL': '4', 'SAGEMAKER_REGION': 'us-east-1', 'SMDATAPARALLEL_SERVER_PORT': '7592', 'NVARCH': 'x86_64', 'PMIX_ID': '2694709249.2', 'CUDNN_VERSION': '8.2.0.53', 'SMDATAPARALLEL_SERVER_ADDR': 'algo-1', 'OMPI_COMM_WORLD_LOCAL_SIZE': '8', 'EFA_VERSION': '1.15.1', 'PYTHONDONTWRITEBYTECODE': '1', 'NV_CUDA_COMPAT_PACKAGE': 'cuda-compat-11-3', 'PMIX_SERVER_TMPDIR': '/tmp/ompi.algo-1.0/pid.120', 'SM_CURRENT_INSTANCE_GROUP_HOSTS': '[\"algo-1\",\"algo-2\"]', 'LD_LIBRARY_PATH': '/opt/amazon/openmpi/lib:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/amazon/openmpi/lib/:/opt/amazon/efa/lib/:/opt/conda/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64', 'NCCL_IB_DISABLE': '1', 'OMPI_COMMAND': 'smddprun', 'RANK': '2', 'OMPI_MCA_ess': '^singleton', 'OMPI_VERSION': '4.1.1', 'SM_FRAMEWORK_PARAMS': '{\"sagemaker_instance_type\":\"ml.p3.[1,mpirank:5,algo-1]<stdout>:NPUT_DIR': '/opt/ml/input', 'SM_RESOURCE_CONFIG': '{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.16xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}],\"network_interface_name\":\"eth0\"}', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'PYTHONPATH': '/opt/ml/code:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220722-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg', 'PMIX_SERVER_URI21': '2694709248.0;tcp4://127.0.0.1:32795', 'SM_LOG_LEVEL': '20', 'SM_DISTRIBUTION_INSTANCE_GROUPS': '[\"homogeneousCluster\"]', 'PMIX_DSTORE_ESH_BASE_PATH': '/tmp/ompi.algo-1.0/pid.120/pmix_dstor_ds12_120', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_pytorch_ddp_enabled\":true},\"channel_input_dirs\":{\"data_path\":\"/opt/ml/input/data/data_path\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.p3.16xlarge\",\"distribution_hosts\":[\"algo-1\",\"algo-2\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"batch_size\":8},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"data_path\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"pytorch-lightning-2022-08-16-04-40-37-950\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-631450739534/pytorch-lightning-2022-08-16-04-40-37-950/source/sourcedir.tar.gz\",\"module_name\":\"semantic_segmentation\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.16xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"semantic_segmentation.py\"}', 'SM_CURRENT_INSTANCE_GROUP': 'homogeneousCluster', 'OMPI_MCA_orte_ess_num_procs': '16', 'OMPI_FILE_LOCATION': '/tmp/ompi.algo-1.0/pid.120/0/0', 'PYTHONIOENCODING': 'UTF-8', 'OMPI_MCA_plm_rsh_no_tree_spawn': '1', 'OMPI_COMM_WORLD_SIZE': '16', 'OMPI_MCA_orte_ess_node_rank': '5', 'SHLVL': '4', 'SAGEMAKER_REGION': 'us-east-1', 'SMDATAPARALLEL_SERVER_PORT': '7592', 'NVARCH': 'x86_64', 'PMIX_ID': '2694709249.5', 'CUDNN_VERSION': '8.2.0.53', 'SMDATAPARALLEL_SERVER_ADDR': 'algo-1', 'OMPI_COMM_WORLD_LOCAL_SIZE': '8', 'EFA_VERSION': '1.15.1', 'PYTHONDONTWRITEBYTECODE': '1', 'NV_CUDA_COMPAT_PACKAGE': 'cuda-compat-11-3', 'PMIX_SERVER_TMPDIR': '/tmp/ompi.algo-1.0/pid.120', 'SM_CURRENT_INSTANCE_GROUP_HOSTS': '[\"algo-1\",\"algo-2\"]', 'LD_LIBRARY_PATH': '/opt/amazon/openmpi/lib:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/amazon/openmpi/lib/:/opt/amazon/efa/lib/:/opt/conda/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64', 'NCCL_IB_DISABLE': '1', 'OMPI_COMMAND': 'smddprun', 'RANK': '5', 'OMPI_MCA_ess': '^singleton', 'OMPI_VERSION': '4.1.1', 'SM_FRAMEWORK_PARAMS': '{\"sagemaker_instance_type\":\"ml.p3.[1,mpirank:6,algo-1]<stdout>:NPUT_DIR': '/opt/ml/input', 'SM_RESOURCE_CONFIG': '{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.16xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}],\"network_interface_name\":\"eth0\"}', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'PYTHONPATH': '/opt/ml/code:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220722-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg', 'PMIX_SERVER_URI21': '2694709248.0;tcp4://127.0.0.1:32795', 'SM_LOG_LEVEL': '20', 'SM_DISTRIBUTION_INSTANCE_GROUPS': '[\"homogeneousCluster\"]', 'PMIX_DSTORE_ESH_BASE_PATH': '/tmp/ompi.algo-1.0/pid.120/pmix_dstor_ds12_120', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_pytorch_ddp_enabled\":true},\"channel_input_dirs\":{\"data_path\":\"/opt/ml/input/data/data_path\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.p3.16xlarge\",\"distribution_hosts\":[\"algo-1\",\"algo-2\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"batch_size\":8},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"data_path\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"pytorch-lightning-2022-08-16-04-40-37-950\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-631450739534/pytorch-lightning-2022-08-16-04-40-37-950/source/sourcedir.tar.gz\",\"module_name\":\"semantic_segmentation\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.16xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"semantic_segmentation.py\"}', 'SM_CURRENT_INSTANCE_GROUP': 'homogeneousCluster', 'OMPI_MCA_orte_ess_num_procs': '16', 'OMPI_FILE_LOCATION': '/tmp/ompi.algo-1.0/pid.120/0/0', 'PYTHONIOENCODING': 'UTF-8', 'OMPI_MCA_plm_rsh_no_tree_spawn': '1', 'OMPI_COMM_WORLD_SIZE': '16', 'OMPI_MCA_orte_ess_node_rank': '6', 'SHLVL': '4', 'SAGEMAKER_REGION': 'us-east-1', 'SMDATAPARALLEL_SERVER_PORT': '7592', 'NVARCH': 'x86_64', 'PMIX_ID': '2694709249.6', 'CUDNN_VERSION': '8.2.0.53', 'SMDATAPARALLEL_SERVER_ADDR': 'algo-1', 'OMPI_COMM_WORLD_LOCAL_SIZE': '8', 'EFA_VERSION': '1.15.1', 'PYTHONDONTWRITEBYTECODE': '1', 'NV_CUDA_COMPAT_PACKAGE': 'cuda-compat-11-3', 'PMIX_SERVER_TMPDIR': '/tmp/ompi.algo-1.0/pid.120', 'SM_CURRENT_INSTANCE_GROUP_HOSTS': '[\"algo-1\",\"algo-2\"]', 'LD_LIBRARY_PATH': '/opt/amazon/openmpi/lib:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/amazon/openmpi/lib/:/opt/amazon/efa/lib/:/opt/conda/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64', 'NCCL_IB_DISABLE': '1', 'OMPI_COMMAND': 'smddprun', 'RANK': '6', '\u001b[0m\n",
      "\u001b[34mOMPI_MCA_ess': '^singleton', 'OMPI_VERSION': '4.1.1', 'SM_FRAMEWORK_PARAMS': '{\"sagemaker_instance_type\":\"ml.p3.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:16xlarge\",\"sagemaker_pytorch_ddp_enabled\":true}', 'SM_MODULE_DIR': 's3://sagemaker-us-east-1-631450739534/pytorch-lightning-2022-08-16-04-40-37-950/source/sourcedir.tar.gz', 'PMIX_NAMESPACE': '2694709249', 'TRAINING_JOB_NAME': 'pytorch-lightning-2022-08-16-04-40-37-950', 'CURRENT_HOST': 'algo-1', 'LC_ALL': 'C.UTF-8', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:631450739534:training-job/pytorch-lightning-2022-08-16-04-40-37-950', 'SM_CHANNEL_DATA_PATH': '/opt/ml/input/data/data_path', 'PATH': '/opt/amazon/openmpi/bin:/opt/amazon/openmpi/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'SM_USER_ARGS': '[\"--batch_size\",\"8\"]', 'OMPI_MCA_pmix': '^s1,s2,cray,isolated', 'OMPI_MCA_ess_base_jobid': '2694709249', 'OMPI_MCA_btl_tcp_if_include': 'eth0', 'SM_HPS': '{\"batch_size\":8}', 'OMPI_APP_CTX_NUM_PROCS': '16', 'SMDATAPARALLEL_USE_HOMOGENEOUS': '1', 'IPATH_NO_BACKTRACE': '1', 'OMPI_MCA_orte_top_session_dir': '/tmp/ompi.algo-1.0', 'OMPI_MCA_orte_launch': '1', 'SMDATAPARALLEL_NUM_CONN': '5', 'SM_MODEL_DIR': '/opt/ml/model', 'DLC_CONTAINER_TYPE': 'training', 'OMPI_COMM_WORLD_RANK': '1'})\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:16xlarge\",\"sagemaker_pytorch_ddp_enabled\":true}', 'SM_MODULE_DIR': 's3://sagemaker-us-east-1-631450739534/pytorch-lightning-2022-08-16-04-40-37-950/source/sourcedir.tar.gz', 'PMIX_NAMESPACE': '2694709249', 'TRAINING_JOB_NAME': 'pytorch-lightning-2022-08-16-04-40-37-950', 'CURRENT_HOST': 'algo-1', 'LC_ALL': 'C.UTF-8', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:631450739534:training-job/pytorch-lightning-2022-08-16-04-40-37-950', 'SM_CHANNEL_DATA_PATH': '/opt/ml/input/data/data_path', 'PATH': '/opt/amazon/openmpi/bin:/opt/amazon/openmpi/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'SM_USER_ARGS': '[\"--batch_size\",\"8\"]', 'OMPI_MCA_pmix': '^s1,s2,cray,isolated', 'OMPI_MCA_ess_base_jobid': '2694709249', 'OMPI_MCA_btl_tcp_if_include': 'eth0', 'SM_HPS': '{\"batch_size\":8}', 'OMPI_APP_CTX_NUM_PROCS': '16', 'SMDATAPARALLEL_USE_HOMOGENEOUS': '1', 'IPATH_NO_BACKTRACE': '1', 'OMPI_MCA_orte_top_session_dir': '/tmp/ompi.algo-1.0', 'OMPI_MCA_orte_launch': '1', 'SMDATAPARALLEL_NUM_CONN': '5', 'SM_MODEL_DIR': '/opt/ml/model', 'DLC_CONTAINER_TYPE': 'training', 'OMPI_COMM_WORLD_RANK': '2'})\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:16xlarge\",\"sagemaker_pytorch_ddp_enabled\":true}', 'SM_MODULE_DIR': 's3://sagemaker-us-east-1-631450739534/pytorch-lightning-2022-08-16-04-40-37-950/source/sourcedir.tar.gz', 'PMIX_NAMESPACE': '2694709249', 'TRAINING_JOB_NAME': 'pytorch-lightning-2022-08-16-04-40-37-950', 'CURRENT_HOST': 'algo-1', 'LC_ALL': 'C.UTF-8', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:631450739534:training-job/pytorch-lightning-2022-08-16-04-40-37-950', 'SM_CHANNEL_DATA_PATH': '/opt/ml/input/data/data_path', 'PATH': '/opt/amazon/openmpi/bin:/opt/amazon/openmpi/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'SM_USER_ARGS': '[\"--batch_size\",\"8\"]', 'OMPI_MCA_pmix': '^s1,s2,cray,isolated', 'OMPI_MCA_ess_base_jobid': '2694709249', 'OMPI_MCA_btl_tcp_if_include': 'eth0', 'SM_HPS': '{\"batch_size\":8}', 'OMPI_APP_CTX_NUM_PROCS': '16', 'SMDATAPARALLEL_USE_HOMOGENEOUS': '1', 'IPATH_NO_BACKTRACE': '1', 'OMPI_MCA_orte_top_session_dir': '/tmp/ompi.algo-1.0', 'OMPI_MCA_orte_launch': '1', 'SMDATAPARALLEL_NUM_CONN': '5', 'SM_MODEL_DIR': '/opt/ml/model', 'DLC_CONTAINER_TYPE': 'training', 'OMPI_COMM_WORLD_RANK': '5'})\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:16xlarge\",\"sagemaker_pytorch_ddp_enabled\":true}', 'SM_MODULE_DIR': 's3://sagemaker-us-east-1-631450739534/pytorch-lightning-2022-08-16-04-40-37-950/source/sourcedir.tar.gz', 'PMIX_NAMESPACE': '2694709249', 'TRAINING_JOB_NAME': 'pytorch-lightning-2022-08-16-04-40-37-950', 'CURRENT_HOST': 'algo-1', 'LC_ALL': 'C.UTF-8', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:631450739534:training-job/pytorch-lightning-2022-08-16-04-40-37-950', 'SM_CHANNEL_DATA_PATH': '/opt/ml/input/data/data_path', 'PATH': '/opt/amazon/openmpi/bin:/opt/amazon/openmpi/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'SM_USER_ARGS': '[\"--batch_size\",\"8\"]', 'OMPI_MCA_pmix': '^s1,s2,cray,isolated', 'OMPI_MCA_ess_base_jobid': '2694709249', 'OMPI_MCA_btl_tcp_if_include': 'eth0', 'SM_HPS': '{\"batch_size\":8}', 'OMPI_APP_CTX_NUM_PROCS': '16', 'SMDATAPARALLEL_USE_HOMOGENEOUS': '1', 'IPATH_NO_BACKTRACE': '1', 'OMPI_MCA_orte_top_session_dir': '/tmp/ompi.algo-1.0', 'OMPI_MCA_orte_launch': '1', 'SMDATAPARALLEL_NUM_CONN': '5', 'SM_MODEL_DIR': '/opt/ml/model', 'DLC_CONTAINER_TYPE': 'training', 'OMPI_COMM_WORLD_RANK': '6'})\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:Using 16bit native Automatic Mixed Precision (AMP)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:GPU available: True, used: True\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:TPU available: False, using: 0 TPU cores\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:IPU available: False, using: 0 IPUs\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:HPU available: False, using: 0 HPUs\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/16\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/16\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/16\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/16\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/16\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/16\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/16\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/16\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:environ({'OMPI_MCA_orte_app_num': '0', 'SHELL': '/bin/bash', 'NVIDIA_VISIBLE_DEVICES': 'all', 'OMPI_MCA_btl_vader_single_copy_mechanism': 'none', 'SAGEMAKER_JOB_NAME': 'pytorch-lightning-2022-08-16-04-40-37-950', 'SM_CHANNELS': '[\"data_path\"]', 'SM_FRAMEWORK_MODULE': 'sagemaker_pytorch_container.training:main', 'OMPI_MCA_orte_precondition_transports': '2c6b6180696abc4e-99036dffeeb77785', 'PYTHONUNBUFFERED': '1', 'OMPI_MCA_shmem_RUNTIME_QUERY_hint': 'mmap', 'OMPI_UNIVERSE_SIZE': '16', 'OMPI_MCA_rmaps_base_oversubscribe': '1', 'PMIX_MCA_mca_base_component_show_load_errors': '1', 'SM_HOSTS': '[\"algo-1\",\"algo-2\"]', 'LOCAL_RANK': '3', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-0f66adf8f3e516732efee12a20cd80ab606b21ea2a19d5d7fde97a2cf76019bf-customer', 'OMPI_MCA_ess_base_num_procs': '2', 'PMIX_HOSTNAME': 'algo-2', 'SAGEMAKER_TRAINING_MODULE': 'sagemaker_pytorch_container.training:main', 'HOSTNAME': 'ip-10-2-242-254.ec2.internal', 'OMPI_COMM_WORLD_NODE_RANK': '3', 'OMPI_MCA_ess_base_vpid': '11', 'SM_MODULE_NAME': 'semantic_segmentation', 'PMIX_SECURITY_MODE': 'native', 'MASTER_PORT': '7592', 'OMPI_MCA_orte_hnp_uri': '2694709248.0;tcp://10.2.236.66:44785', 'NVIDIA_REQUIRE_CUDA': 'cuda>=11.3 brand=tesla,driver>=418,driver<419 driver>=450', 'SMDATAPARALLEL_USE_ENA': '1', 'OMPI_MCA_plm_rsh_num_concurrent': '2', 'MANUAL_BUILD': '0', 'SM_INSTANCE_GROUPS_DICT': '{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}}', 'BRANCH_OFI': '1.3.0-aws', 'TORCH_NVCC_FLAGS': '-Xfatbin -compress-all', 'OMPI_MCA_btl': '^openib', 'SAGEMAKER_INSTANCE_TYPE': 'ml.p3.16xlarge', 'OMPI_COMM_WORLD_LOCAL_RANK': '3', 'TORCH_CUDA_ARCH_LIST': '3.7 5.0 7.0+PTX 8.0', 'NCCL_VERSION': '2.10.3', 'NCCL_SOCKET_IFNAME': 'eth0', 'HFI_NO_BACKTRACE': '1', 'AWS_REGION': 'us-east-1', 'PMIX_GDS_MODULE': 'ds21,ds12,hash', 'PWD': '/opt/ml/code', 'SMDATAPARALLEL_WORLD_RANK': '11', 'OMPI_MCA_orte_abort_on_non_zero_status': '1', 'OMPI_MCA_orte_local_daemon_uri': '2694709248.1;tcp://10.2.242.254:59027', 'LOGNAME': 'root', 'RDMAV_FORK_SAFE': '1', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility,compat32,graphics,video', 'OMPI_MCA_oob_tcp_if_include': 'eth0', 'NCCL_DEBUG': 'INFO', 'OMPI_MCA_pml': 'ob1', 'HOROVOD_VERSION': '0.24.3', '_': '/opt/conda/bin/python3.8', 'PMIX_SYSTEM_TMPDIR': '/tmp', 'WORLD_SIZE': '16', 'SM_USER_ENTRY_POINT': 'semantic_segmentation.py', 'OPEN_MPI_PATH': '/opt/amazon/openmpi', 'OMPI_ARGV': '/opt/conda/bin/python3.8 -m mpi4py semantic_segmentation.py --batch_size 8', 'PMIX_BFROP_BUFFER_TYPE': 'PMIX_BFROP_BUFFER_NON_DESC', 'OMPI_MCA_orte_node_regex': 'algo-[1:1-2]@0(2)', 'MOTD_SHOWN': 'pam', 'LD_PRELOAD': '/opt/conda/lib/python3.8/site-packages/gethostname.cpython-38-x86_64-linux-gnu.so', 'NV_CUDA_CUDART_VERSION': '11.3.109-1', 'PMIX_PTL_MODULE': 'tcp,usock', 'HOME': '/root', 'FI_PROVIDER': 'efa', 'OMPI_NUM_APP_CTX': '1', 'LANG': 'C.UTF-8', 'DYLD_LIBRARY_PATH': '/opt/amazon/openmpi/lib:', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'PMIX_DSTORE_21_BASE_PATH': '/tmp/ompi.algo-2.0/jf.41118/pmix_dstor_ds21_128', 'SM_IS_HETERO': 'false', 'OMPI_MCA_orte_num_nodes': '2', 'OMPI_MCA_orte_daemonize': '1', 'SM_CURRENT_INSTANCE_TYPE': 'ml.p3.16xlarge', 'PMIX_VERSION': '3.2.3', 'CUDA_VERSION': '11.3.1', 'SMDATAPARALLEL_LOCAL_RANK': '3', 'DMLC_INTERFACE': 'eth0', 'OMPI_MCA_orte_tag_output': '1', 'SM_NUM_CPUS': '64', 'CMAKE_PREFIX_PATH': '$(dirname $(which conda))/../', 'DGLBACKEND': 'pytorch', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_HP_BATCH_SIZE': '8', 'USE_SMDEBUG': '0', 'OMPI_MCA_orte_tmpdir_base': '/tmp', 'SSH_CONNECTION': '10.2.236.66 51900 10.2.242.254 22', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'PMIX_RANK': '11', 'PMIX_SERVER_URI2': '2694709248.1;tcp4://127.0.0.1:33499', 'PMIX_SERVER_URI3': '2694709248.1;tcp4://127.0.0.1:33499', 'SM_CURRENT_HOST': 'algo-2', 'OMPI_MCA_initial_wdir': '/opt/ml/code', 'OMPI_FIRST_RANKS': '0', 'SM_INSTANCE_GROUPS': '[\"homogeneousCluster\"]', 'OMPI_MCA_mpi_oversubscribe': '0'[1,mpirank:13,algo-2]<stdout>:environ({'OMPI_MCA_orte_app_num': '0', 'SHELL': '/bin/bash', 'NVIDIA_VISIBLE_DEVICES': 'all', 'OMPI_MCA_btl_vader_single_copy_mechanism': 'none', 'SAGEMAKER_JOB_NAME': 'pytorch-lightning-2022-08-16-04-40-37-950', 'SM_CHANNELS': '[\"data_path\"]', 'SM_FRAMEWORK_MODULE': 'sagemaker_pytorch_container.training:main', 'OMPI_MCA_orte_precondition_transports': '2c6b6180696abc4e-99036dffeeb77785', 'PYTHONUNBUFFERED': '1', 'OMPI_MCA_shmem_RUNTIME_QUERY_hint': 'mmap', 'OMPI_UNIVERSE_SIZE': '16', 'OMPI_MCA_rmaps_base_oversubscribe': '1', 'PMIX_MCA_mca_base_component_show_load_errors': '1', 'SM_HOSTS': '[\"algo-1\",\"algo-2\"]', 'LOCAL_RANK': '5', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-0f66adf8f3e516732efee12a20cd80ab606b21ea2a19d5d7fde97a2cf76019bf-customer', 'OMPI_MCA_ess_base_num_procs': '2', 'PMIX_HOSTNAME': 'algo-2', 'SAGEMAKER_TRAINING_MODULE': 'sagemaker_pytorch_container.training:main', 'HOSTNAME': 'ip-10-2-242-254.ec2.internal', 'OMPI_COMM_WORLD_NODE_RANK': '5', 'OMPI_MCA_ess_base_vpid': '13', 'SM_MODULE_NAME': 'semantic_segmentation', 'PMIX_SECURITY_MODE': 'native', 'MASTER_PORT': '7592', 'OMPI_MCA_orte_hnp_uri': '2694709248.0;tcp://10.2.236.66:44785', 'NVIDIA_REQUIRE_CUDA': 'cuda>=11.3 brand=tesla,driver>=418,driver<419 driver>=450', 'SMDATAPARALLEL_USE_ENA': '1', 'OMPI_MCA_plm_rsh_num_concurrent': '2', 'MANUAL_BUILD': '0', 'SM_INSTANCE_GROUPS_DICT': '{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}}', 'BRANCH_OFI': '1.3.0-aws', 'TORCH_NVCC_FLAGS': '-Xfatbin -compress-all', 'OMPI_MCA_btl': '^openib', 'SAGEMAKER_INSTANCE_TYPE': 'ml.p3.16xlarge', 'OMPI_COMM_WORLD_LOCAL_RANK': '5', 'TORCH_CUDA_ARCH_LIST': '3.7 5.0 7.0+PTX 8.0', 'NCCL_VERSION': '2.10.3', 'NCCL_SOCKET_IFNAME': 'eth0', 'HFI_NO_BACKTRACE': '1', 'AWS_REGION': 'us-east-1', 'PMIX_GDS_MODULE': 'ds21,ds12,hash', 'PWD': '/opt/ml/code', 'SMDATAPARALLEL_WORLD_RANK': '13', 'OMPI_MCA_orte_abort_on_non_zero_status': '1', 'OMPI_MCA_orte_local_daemon_uri': '2694709248.1;tcp://10.2.242.254:59027', 'LOGNAME': 'root', 'RDMAV_FORK_SAFE': '1', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility,compat32,graphics,video', 'OMPI_MCA_oob_tcp_if_include': 'eth0', 'NCCL_DEBUG': 'INFO', 'OMPI_MCA_pml': 'ob1', 'HOROVOD_VERSION': '0.24.3', '_': '/opt/conda/bin/python3.8', 'PMIX_SYSTEM_TMPDIR': '/tmp', 'WORLD_SIZE': '16', 'SM_USER_ENTRY_POINT': 'semantic_segmentation.py', 'OPEN_MPI_PATH': '/opt/amazon/openmpi', 'OMPI_ARGV': '/opt/conda/bin/python3.8 -m mpi4py semantic_segmentation.py --batch_size 8', 'PMIX_BFROP_BUFFER_TYPE': 'PMIX_BFROP_BUFFER_NON_DESC', 'OMPI_MCA_orte_node_regex': 'algo-[1:1-2]@0(2)', 'MOTD_SHOWN': 'pam', 'LD_PRELOAD': '/opt/conda/lib/python3.8/site-packages/gethostname.cpython-38-x86_64-linux-gnu.so', 'NV_CUDA_CUDART_VERSION': '11.3.109-1', 'PMIX_PTL_MODULE': 'tcp,usock', 'HOME': '/root', 'FI_PROVIDER': 'efa', 'OMPI_NUM_APP_CTX': '1', 'LANG': 'C.UTF-8', 'DYLD_LIBRARY_PATH': '/opt/amazon/openmpi/lib:', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'PMIX_DSTORE_21_BASE_PATH': '/tmp/ompi.algo-2.0/jf.41118/pmix_dstor_ds21_128', 'SM_IS_HETERO': 'false', 'OMPI_MCA_orte_num_nodes': '2', 'OMPI_MCA_orte_daemonize': '1', 'SM_CURRENT_INSTANCE_TYPE': 'ml.p3.16xlarge', 'PMIX_VERSION': '3.2.3', 'CUDA_VERSION': '11.3.1', 'SMDATAPARALLEL_LOCAL_RANK': '5', 'DMLC_INTERFACE': 'eth0', 'OMPI_MCA_orte_tag_output': '1', 'SM_NUM_CPUS': '64', 'CMAKE_PREFIX_PATH': '$(dirname $(which conda))/../', 'DGLBACKEND': 'pytorch', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_HP_BATCH_SIZE': '8', 'USE_SMDEBUG': '0', 'OMPI_MCA_orte_tmpdir_base': '/tmp', 'SSH_CONNECTION': '10.2.236.66 51900 10.2.242.254 22', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'PMIX_RANK': '13', 'PMIX_SERVER_URI2': '2694709248.1;tcp4://127.0.0.1:33499', 'PMIX_SERVER_URI3': '2694709248.1;tcp4://127.0.0.1:33499', 'SM_CURRENT_HOST': 'algo-2', 'OMPI_MCA_initial_wdir': '/opt/ml/code', 'OMPI_FIRST_RANKS': '0', 'SM_INSTANCE_GROUPS': '[\"homogeneousCluster\"]', 'OMPI_MCA_mpi_oversubscribe': '0'\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:environ({'OMPI_MCA_orte_app_num': '0', 'SHELL': '/bin/bash', 'NVIDIA_VISIBLE_DEVICES': 'all', 'OMPI_MCA_btl_vader_single_copy_mechanism': 'none', 'SAGEMAKER_JOB_NAME': 'pytorch-lightning-2022-08-16-04-40-37-950', 'SM_CHANNELS': '[\"data_path\"]', 'SM_FRAMEWORK_MODULE': 'sagemaker_pytorch_container.training:main', 'OMPI_MCA_orte_precondition_transports': '2c6b6180696abc4e-99036dffeeb77785', 'PYTHONUNBUFFERED': '1', 'OMPI_MCA_shmem_RUNTIME_QUERY_hint': 'mmap', 'OMPI_UNIVERSE_SIZE': '16', 'OMPI_MCA_rmaps_base_oversubscribe': '1', 'PMIX_MCA_mca_base_component_show_load_errors': '1', 'SM_HOSTS': '[\"algo-1\",\"algo-2\"]', 'LOCAL_RANK': '7', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-0f66adf8f3e516732efee12a20cd80ab606b21ea2a19d5d7fde97a2cf76019bf-customer', 'OMPI_MCA_ess_base_num_procs': '2', 'PMIX_HOSTNAME': 'algo-2', 'SAGEMAKER_TRAINING_MODULE': 'sagemaker_pytorch_container.training:main', 'HOSTNAME': 'ip-10-2-242-254.ec2.internal', 'OMPI_COMM_WORLD_NODE_RANK': '7', 'OMPI_MCA_ess_base_vpid': '15', 'SM_MODULE_NAME': 'semantic_segmentation', 'PMIX_SECURITY_MODE': 'native', 'MASTER_PORT': '7592', 'OMPI_MCA_orte_hnp_uri': '2694709248.0;tcp://10.2.236.66:44785', 'NVIDIA_REQUIRE_CUDA': 'cuda>=11.3 brand=tesla,driver>=418,driver<419 driver>=450', 'SMDATAPARALLEL_USE_ENA': '1', 'OMPI_MCA_plm_rsh_num_concurrent': '2', 'MANUAL_BUILD': '0', 'SM_INSTANCE_GROUPS_DICT': '{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}}', 'BRANCH_OFI': '1.3.0-aws', 'TORCH_NVCC_FLAGS': '-Xfatbin -compress-all', 'OMPI_MCA_btl': '^openib', 'SAGEMAKER_INSTANCE_TYPE': 'ml.p3.16xlarge', 'OMPI_COMM_WORLD_LOCAL_RANK': '7', 'TORCH_CUDA_ARCH_LIST': '3.7 5.0 7.0+PTX 8.0', 'NCCL_VERSION': '2.10.3', 'NCCL_SOCKET_IFNAME': 'eth0', 'HFI_NO_BACKTRACE': '1', 'AWS_REGION': 'us-east-1', 'PMIX_GDS_MODULE': 'ds21,ds12,hash', 'PWD': '/opt/ml/code', 'SMDATAPARALLEL_WORLD_RANK': '15', 'OMPI_MCA_orte_abort_on_non_zero_status': '1', 'OMPI_MCA_orte_local_daemon_uri': '2694709248.1;tcp://10.2.242.254:59027', 'LOGNAME': 'root', 'RDMAV_FORK_SAFE': '1', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility,compat32,graphics,video', 'OMPI_MCA_oob_tcp_if_include': 'eth0', 'NCCL_DEBUG': 'INFO', 'OMPI_MCA_pml': 'ob1', 'HOROVOD_VERSION': '0.24.3', '_': '/opt/conda/bin/python3.8', 'PMIX_SYSTEM_TMPDIR': '/tmp', 'WORLD_SIZE': '16', 'SM_USER_ENTRY_POINT': 'semantic_segmentation.py', 'OPEN_MPI_PATH': '/opt/amazon/openmpi', 'OMPI_ARGV': '/opt/conda/bin/python3.8 -m mpi4py semantic_segmentation.py --batch_size 8', 'PMIX_BFROP_BUFFER_TYPE': 'PMIX_BFROP_BUFFER_NON_DESC', 'OMPI_MCA_orte_node_regex': 'algo-[1:1-2]@0(2)', 'MOTD_SHOWN': 'pam', 'LD_PRELOAD': '/opt/conda/lib/python3.8/site-packages/gethostname.cpython-38-x86_64-linux-gnu.so', 'NV_CUDA_CUDART_VERSION': '11.3.109-1', 'PMIX_PTL_MODULE': 'tcp,usock', 'HOME': '/root', 'FI_PROVIDER': 'efa', 'OMPI_NUM_APP_CTX': '1', 'LANG': 'C.UTF-8', 'DYLD_LIBRARY_PATH': '/opt/amazon/openmpi/lib:', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'PMIX_DSTORE_21_BASE_PATH': '/tmp/ompi.algo-2.0/jf.41118/pmix_dstor_ds21_128', 'SM_IS_HETERO': 'false', 'OMPI_MCA_orte_num_nodes': '2', 'OMPI_MCA_orte_daemonize': '1', 'SM_CURRENT_INSTANCE_TYPE': 'ml.p3.16xlarge', 'PMIX_VERSION': '3.2.3', 'CUDA_VERSION': '11.3.1', 'SMDATAPARALLEL_LOCAL_RANK': '7', 'DMLC_INTERFACE': 'eth0', 'OMPI_MCA_orte_tag_output': '1', 'SM_NUM_CPUS': '64', 'CMAKE_PREFIX_PATH': '$(dirname $(which conda))/../', 'DGLBACKEND': 'pytorch', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_HP_BATCH_SIZE': '8', 'USE_SMDEBUG': '0', 'OMPI_MCA_orte_tmpdir_base': '/tmp', 'SSH_CONNECTION': '10.2.236.66 51900 10.2.242.254 22', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'PMIX_RANK': '15', 'PMIX_SERVER_URI2': '2694709248.1;tcp4://127.0.0.1:33499', 'PMIX_SERVER_URI3': '2694709248.1;tcp4://127.0.0.1:33499', 'SM_CURRENT_HOST': 'algo-2', 'OMPI_MCA_initial_wdir': '/opt/ml/code', 'OMPI_FIRST_RANKS': '0', 'SM_INSTANCE_GROUPS': '[\"homogeneousCluster\"]', 'OMPI_MCA_mpi_oversubscribe': '0'[1,mpirank:11,algo-2]<stdout>:, 'SMDATAPARALLEL_WORLD_SIZE': '16', 'OMPI_MCA_orte_jobfam_session_dir': '/tmp/ompi.algo-2.0/jf.41118', 'MASTER_ADDR': 'algo-1', 'SM_INPUT_DATA_CONFIG': '{\"data_path\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}', 'SM_NUM_GPUS': '8', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_RESOURCE_CONFIG': '{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.p3.16xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}],\"network_interface_name\":\"eth0\"}', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'PYTHONPATH': '/opt/ml/code:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220722-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg', 'PMIX_SERVER_URI21': '2694709248.1;tcp4://127.0.0.1:33499', 'SM_LOG_LEVEL': '20', 'SM_DISTRIBUTION_INSTANCE_GROUPS': '[\"homogeneousCluster\"]', 'PMIX_DSTORE_ESH_BASE_PATH': '/tmp/ompi.algo-2.0/jf.41118/pmix_dstor_ds12_128', 'USER': 'root', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_pytorch_ddp_enabled\":true},\"channel_input_dirs\":{\"data_path\":\"/opt/ml/input/data/data_path\"},\"current_host\":\"algo-2\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.p3.16xlarge\",\"distribution_hosts\":[\"algo-1\",\"algo-2\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"batch_size\":8},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"data_path\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}},\"is_hetero\":false,\"is_master\":false,\"is_modelpara', 'OMPI_MCA_plm': 'rsh', 'SM_CURRENT_INSTANCE_GROUP': 'homogeneousCluster', 'OMPI_MCA_orte_ess_num_procs': '16', 'OMPI_FILE_LOCATION': '/tmp/ompi.algo-2.0/jf.41118/0/1', 'PYTHONIOENCODING': 'UTF-8', 'OMPI_MCA_plm_rsh_no_tree_spawn': '1', 'OMPI_COMM_WORLD_SIZE': '16', 'OMPI_MCA_orte_ess_node_rank': '3', 'SHLVL': '4', 'SAGEMAKER_REGION': 'us-east-1', 'SMDATAPARALLEL_SERVER_PORT': '7592', 'NVARCH': 'x86_64', 'PMIX_ID': '2694709249.11', 'CUDNN_VERSION': '8.2.0.53', 'SMDATAPARALLEL_SERVER_ADDR': 'algo-1', 'OMPI_COMM_WORLD_LOCAL_SIZE': '8', 'EFA_VERSION': '1.15.1', 'PYTHONDONTWRITEBYTECODE': '1', 'NV_CUDA_COMPAT_PACKAGE': 'cuda-compat-11-3', 'PMIX_SERVER_TMPDIR': '/tmp/ompi.algo-2.0/jf.41118', 'SM_CURRENT_INSTANCE_GROUP_HOSTS': '[\"algo-1\",\"algo-2\"]', 'LD_LIBRARY_PATH': '/opt/amazon/openmpi/lib:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/amazon/openmpi/lib/:/opt/amazon/efa/lib/:/opt/conda/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64', 'NCCL_IB_DISABLE': '1', 'OMPI_COMMAND': 'smddprun', 'RANK': '11', 'OMPI_MCA_ess': '^singleton', 'OMPI_VERSION': '4.1.1', 'SSH_CLIENT': '10.2.236.66 51900 22', 'SM_FRAMEWORK_PARAMS': '{\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_pytorch_ddp_enabled\":true}', 'SM_MODULE_DIR': 's3://sagemaker-us-east-1-631450739534/pytorch-lightning-2022-08-16-04-40-37-950/source/sourcedir.tar.gz', 'PMIX_NAMESPACE': '2694709249', 'TRAINING_JOB_NAME': 'pytorch-lightning-2022-08-16-04-40-37-950', 'CURRENT_HOST': 'algo-2', 'LC_ALL': 'C.UTF-8', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:631450739534:training-job/pytorch-lightning-2022-08-16-04-40-37-950', 'SM_CHANNEL_DATA_PATH': '/opt/ml/i[1,mpirank:13,algo-2]<stdout>:, 'SMDATAPARALLEL_WORLD_SIZE': '16', 'OMPI_MCA_orte_jobfam_session_dir': '/tmp/ompi.algo-2.0/jf.41118', 'MASTER_ADDR': 'algo-1', 'SM_INPUT_DATA_CONFIG': '{\"data_path\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}', 'SM_NUM_GPUS': '8', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_RESOURCE_CONFIG': '{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.p3.16xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}],\"network_interface_name\":\"eth0\"}', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'PYTHONPATH': '/opt/ml/code:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220722-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg', 'PMIX_SERVER_URI21': '2694709248.1;tcp4://127.0.0.1:33499', 'SM_LOG_LEVEL': '20', 'SM_DISTRIBUTION_INSTANCE_GROUPS': '[\"homogeneousCluster\"]', 'PMIX_DSTORE_ESH_BASE_PATH': '/tmp/ompi.algo-2.0/jf.41118/pmix_dstor_ds12_128', 'USER': 'root', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_pytorch_ddp_enabled\":true},\"channel_input_dirs\":{\"data_path\":\"/opt/ml/input/data/data_path\"},\"current_host\":\"algo-2\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.p3.16xlarge\",\"distribution_hosts\":[\"algo-1\",\"algo-2\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"batch_size\":8},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"data_path\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}},\"is_hetero\":false,\"is_master\":false,\"is_modelpara', 'OMPI_MCA_plm': 'rsh', 'SM_CURRENT_INSTANCE_GROUP': 'homogeneousCluster', 'OMPI_MCA_orte_ess_num_procs': '16', 'OMPI_FILE_LOCATION': '/tmp/ompi.algo-2.0/jf.41118/0/1', 'PYTHONIOENCODING': 'UTF-8', 'OMPI_MCA_plm_rsh_no_tree_spawn': '1', 'OMPI_COMM_WORLD_SIZE': '16', 'OMPI_MCA_orte_ess_node_rank': '5', 'SHLVL': '4', 'SAGEMAKER_REGION': 'us-east-1', 'SMDATAPARALLEL_SERVER_PORT': '7592', 'NVARCH': 'x86_64', 'PMIX_ID': '2694709249.13', 'CUDNN_VERSION': '8.2.0.53', 'SMDATAPARALLEL_SERVER_ADDR': 'algo-1', 'OMPI_COMM_WORLD_LOCAL_SIZE': '8', 'EFA_VERSION': '1.15.1', 'PYTHONDONTWRITEBYTECODE': '1', 'NV_CUDA_COMPAT_PACKAGE': 'cuda-compat-11-3', 'PMIX_SERVER_TMPDIR': '/tmp/ompi.algo-2.0/jf.41118', 'SM_CURRENT_INSTANCE_GROUP_HOSTS': '[\"algo-1\",\"algo-2\"]', 'LD_LIBRARY_PATH': '/opt/amazon/openmpi/lib:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/amazon/openmpi/lib/:/opt/amazon/efa/lib/:/opt/conda/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64', 'NCCL_IB_DISABLE': '1', 'OMPI_COMMAND': 'smddprun', 'RANK': '13', 'OMPI_MCA_ess': '^singleton', 'OMPI_VERSION': '4.1.1', 'SSH_CLIENT': '10.2.236.66 51900 22', 'SM_FRAMEWORK_PARAMS': '{\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_pytorch_ddp_enabled\":true}', 'SM_MODULE_DIR': 's3://sagemaker-us-east-1-631450739534/pytorch-lightning-2022-08-16-04-40-37-950/source/sourcedir.tar.gz', 'PMIX_NAMESPACE': '2694709249', 'TRAINING_JOB_NAME': 'pytorch-lightning-2022-08-16-04-40-37-950', 'CURRENT_HOST': 'algo-2', 'LC_ALL': 'C.UTF-8', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:631450739534:training-job/pytorch-lightning-2022-08-16-04-40-37-950', 'SM_CHANNEL_DATA_PATH': '/opt/ml/i[1,mpirank:15,algo-2]<stdout>:, 'SMDATAPARALLEL_WORLD_SIZE': '16', 'OMPI_MCA_orte_jobfam_session_dir': '/tmp/ompi.algo-2.0/jf.41118', 'MASTER_ADDR': 'algo-1', 'SM_INPUT_DATA_CONFIG': '{\"data_path\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}', 'SM_NUM_GPUS': '8', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_RESOURCE_CONFIG': '{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.p3.16xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}],\"network_interface_name\":\"eth0\"}', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'PYTHONPATH': '/opt/ml/code:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220722-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg', 'PMIX_SERVER_URI21': '2694709248.1;tcp4://127.0.0.1:33499', 'SM_LOG_LEVEL': '20', 'SM_DISTRIBUTION_INSTANCE_GROUPS': '[\"homogeneousCluster\"]', 'PMIX_DSTORE_ESH_BASE_PATH': '/tmp/ompi.algo-2.0/jf.41118/pmix_dstor_ds12_128', 'USER': 'root', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_pytorch_ddp_enabled\":true},\"channel_input_dirs\":{\"data_path\":\"/opt/ml/input/data/data_path\"},\"current_host\":\"algo-2\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.p3.16xlarge\",\"distribution_hosts\":[\"algo-1\",\"algo-2\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"batch_size\":8},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"data_path\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}},\"is_hetero\":false,\"is_master\":false,\"is_modelpara', 'OMPI_MCA_plm': 'rsh', 'SM_CURRENT_INSTANCE_GROUP': 'homogeneousCluster', 'OMPI_MCA_orte_ess_num_procs': '16', 'OMPI_FILE_LOCATION': '/tmp/ompi.algo-2.0/jf.41118/0/1', 'PYTHONIOENCODING': 'UTF-8', 'OMPI_MCA_plm_rsh_no_tree_spawn': '1', 'OMPI_COMM_WORLD_SIZE': '16', 'OMPI_MCA_orte_ess_node_rank': '7', 'SHLVL': '4', 'SAGEMAKER_REGION': 'us-east-1', 'SMDATAPARALLEL_SERVER_PORT': '7592', 'NVARCH': 'x86_64', 'PMIX_ID': '2694709249.15', 'CUDNN_VERSION': '8.2.0.53', 'SMDATAPARALLEL_SERVER_ADDR': 'algo-1', 'OMPI_COMM_WORLD_LOCAL_SIZE': '8', 'EFA_VERSION': '1.15.1', 'PYTHONDONTWRITEBYTECODE': '1', 'NV_CUDA_COMPAT_PACKAGE': 'cuda-compat-11-3', 'PMIX_SERVER_TMPDIR': '/tmp/ompi.algo-2.0/jf.41118', 'SM_CURRENT_INSTANCE_GROUP_HOSTS': '[\"algo-1\",\"algo-2\"]', 'LD_LIBRARY_PATH': '/opt/amazon/openmpi/lib:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/amazon/openmpi/lib/:/opt/amazon/efa/lib/:/opt/conda/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64', 'NCCL_IB_DISABLE': '1', 'OMPI_COMMAND': 'smddprun', 'RANK': '15', 'OMPI_MCA_ess': '^singleton', 'OMPI_VERSION': '4.1.1', 'SSH_CLIENT': '10.2.236.66 51900 22', 'SM_FRAMEWORK_PARAMS': '{\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_pytorch_ddp_enabled\":true}', 'SM_MODULE_DIR': 's3://sagemaker-us-east-1-631450739534/pytorch-lightning-2022-08-16-04-40-37-950/source/sourcedir.tar.gz', 'PMIX_NAMESPACE': '2694709249', 'TRAINING_JOB_NAME': 'pytorch-lightning-2022-08-16-04-40-37-950', 'CURRENT_HOST': 'algo-2', 'LC_ALL': 'C.UTF-8', 'TRAINING_JOB_ARN': 'arn:aws:sagemake\u001b[0m\n",
      "\u001b[34mr:us-east-1:631450739534:training-job/pytorch-lightning-2022-08-16-04-40-37-950', 'SM_CHANNEL_DATA_PATH': '/opt/ml/i[1,mpirank:13,algo-2]<stdout>:nput/data/data_path', 'PATH': '/opt/amazon/openmpi/bin:/opt/amazon/openmpi/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'SM_USER_ARGS': '[\"--batch_size\",\"8\"]', 'OMPI_MCA_pmix': '^s1,s2,cray,isolated', 'OMPI_MCA_ess_base_jobid': '2694709249', 'OMPI_MCA_btl_tcp_if_include': 'eth0', 'SM_HPS': '{\"batch_size\":8}', 'OMPI_APP_CTX_NUM_PROCS': '16', 'SMDATAPARALLEL_USE_HOMOGENEOUS': '1', 'IPATH_NO_BACKTRACE': '1', 'OMPI_MCA_orte_top_session_dir': '/tmp/ompi.algo-2.0', 'OMPI_MCA_orte_launch': '1', 'SMDATAPARALLEL_NUM_CONN': '5', 'SM_MODEL_DIR': '/opt/ml/model', 'DLC_CONTAINER_TYPE': 'training', 'OMPI_COMM_WORLD_RANK': '13'})\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:nput/data/data_path', 'PATH': '/opt/amazon/openmpi/bin:/opt/amazon/openmpi/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'SM_USER_ARGS': '[\"--batch_size\",\"8\"]', 'OMPI_MCA_pmix': '^s1,s2,cray,isolated', 'OMPI_MCA_ess_base_jobid': '2694709249', 'OMPI_MCA_btl_tcp_if_include': 'eth0', 'SM_HPS': '{\"batch_size\":8}', 'OMPI_APP_CTX_NUM_PROCS': '16', 'SMDATAPARALLEL_USE_HOMOGENEOUS': '1', 'IPATH_NO_BACKTRACE': '1', 'OMPI_MCA_orte_top_session_dir': '/tmp/ompi.algo-2.0', 'OMPI_MCA_orte_launch': '1', 'SMDATAPARALLEL_NUM_CONN': '5', 'SM_MODEL_DIR': '/opt/ml/model', 'DLC_CONTAINER_TYPE': 'training', 'OMPI_COMM_WORLD_RANK': '11'})\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:nput/data/data_path', 'PATH': '/opt/amazon/openmpi/bin:/opt/amazon/openmpi/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'SM_USER_ARGS': '[\"--batch_size\",\"8\"]', 'OMPI_MCA_pmix': '^s1,s2,cray,isolated', 'OMPI_MCA_ess_base_jobid': '2694709249', 'OMPI_MCA_btl_tcp_if_include': 'eth0', 'SM_HPS': '{\"batch_size\":8}', 'OMPI_APP_CTX_NUM_PROCS': '16', 'SMDATAPARALLEL_USE_HOMOGENEOUS': '1', 'IPATH_NO_BACKTRACE': '1', 'OMPI_MCA_orte_top_session_dir': '/tmp/ompi.algo-2.0', 'OMPI_MCA_orte_launch': '1', 'SMDATAPARALLEL_NUM_CONN': '5', 'SM_MODEL_DIR': '/opt/ml/model', 'DLC_CONTAINER_TYPE': 'training', 'OMPI_COMM_WORLD_RANK': '15'})\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:environ({'OMPI_MCA_orte_app_num': '0', 'SHELL': '/bin/bash', 'NVIDIA_VISIBLE_DEVICES': 'all', 'OMPI_MCA_btl_vader_single_copy_mechanism': 'none', 'SAGEMAKER_JOB_NAME': 'pytorch-lightning-2022-08-16-04-40-37-950', 'SM_CHANNELS': '[\"data_path\"]', 'SM_FRAMEWORK_MODULE': 'sagemaker_pytorch_container.training:main', 'OMPI_MCA_orte_precondition_transports': '2c6b6180696abc4e-99036dffeeb77785', 'PYTHONUNBUFFERED': '1', 'OMPI_MCA_shmem_RUNTIME_QUERY_hint': 'mmap', 'OMPI_UNIVERSE_SIZE': '16', 'OMPI_MCA_rmaps_base_oversubscribe': '1', 'PMIX_MCA_mca_base_component_show_load_errors': '1', 'SM_HOSTS': '[\"algo-1\",\"algo-2\"]', 'LOCAL_RANK': '0', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-0f66adf8f3e516732efee12a20cd80ab606b21ea2a19d5d7fde97a2cf76019bf-customer', 'OMPI_MCA_ess_base_num_procs': '2', 'PMIX_HOSTNAME': 'algo-2', 'SAGEMAKER_TRAINING_MODULE': 'sagemaker_pytorch_container.training:main', 'HOSTNAME': 'ip-10-2-242-254.ec2.internal', 'OMPI_COMM_WORLD_NODE_RANK': '0', 'OMPI_MCA_ess_base_vpid': '8', 'SM_MODULE_NAME': 'semantic_segmentation', 'PMIX_SECURITY_MODE': 'native', 'MASTER_PORT': '7592', 'OMPI_MCA_orte_hnp_uri': '2694709248.0;tcp://10.2.236.66:44785', 'NVIDIA_REQUIRE_CUDA': 'cuda>=11.3 brand=tesla,driver>=418,driver<419 driver>=450', 'SMDATAPARALLEL_USE_ENA': '1', 'OMPI_MCA_plm_rsh_num_concurrent': '2', 'MANUAL_BUILD': '0', 'SM_INSTANCE_GROUPS_DICT': '{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}}', 'BRANCH_OFI': '1.3.0-aws', 'TORCH_NVCC_FLAGS': '-Xfatbin -compress-all', 'OMPI_MCA_btl': '^openib', 'SAGEMAKER_INSTANCE_TYPE': 'ml.p3.16xlarge', 'OMPI_COMM_WORLD_LOCAL_RANK': '0', 'TORCH_CUDA_ARCH_LIST': '3.7 5.0 7.0+PTX 8.0', 'NCCL_VERSION': '2.10.3', 'NCCL_SOCKET_IFNAME': 'eth0', 'HFI_NO_BACKTRACE': '1', 'AWS_REGION': 'us-east-1', 'PMIX_GDS_MODULE': 'ds21,ds12,hash', 'PWD': '/opt/ml/code', 'SMDATAPARALLEL_WORLD_RANK': '8', 'OMPI_MCA_orte_abort_on_non_zero_status': '1', 'OMPI_MCA_orte_local_daemon_uri': '2694709248.1;tcp://10.2.242.254:59027', 'LOGNAME': 'root', 'RDMAV_FORK_SAFE': '1', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility,compat32,graphics,video', 'OMPI_MCA_oob_tcp_if_include': 'eth0', 'NCCL_DEBUG': 'INFO', 'OMPI_MCA_pml': 'ob1', 'HOROVOD_VERSION': '0.24.3', '_': '/opt/conda/bin/python3.8', 'PMIX_SYSTEM_TMPDIR': '/tmp', 'WORLD_SIZE': '16', 'SM_USER_ENTRY_POINT': 'semantic_segmentation.py', 'OPEN_MPI_PATH': '/opt/amazon/openmpi', 'OMPI_ARGV': '/opt/conda/bin/python3.8 -m mpi4py semantic_segmentation.py --batch_size 8', 'PMIX_BFROP_BUFFER_TYPE': 'PMIX_BFROP_BUFFER_NON_DESC', 'OMPI_MCA_orte_node_regex': 'algo-[1:1-2]@0(2)', 'MOTD_SHOWN': 'pam', 'LD_PRELOAD': '/opt/conda/lib/python3.8/site-packages/gethostname.cpython-38-x86_64-linux-gnu.so', 'NV_CUDA_CUDART_VERSION': '11.3.109-1', 'PMIX_PTL_MODULE': 'tcp,usock', 'HOME': '/root', 'FI_PROVIDER': 'efa', 'OMPI_NUM_APP_CTX': '1', 'LANG': 'C.UTF-8', 'DYLD_LIBRARY_PATH': '/opt/amazon/openmpi/lib:', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'PMIX_DSTORE_21_BASE_PATH': '/tmp/ompi.algo-2.0/jf.41118/pmix_dstor_ds21_128', 'SM_IS_HETERO': 'false', 'OMPI_MCA_orte_num_nodes': '2', 'OMPI_MCA_orte_daemonize': '1', 'SM_CURRENT_INSTANCE_TYPE': 'ml.p3.16xlarge', 'PMIX_VERSION': '3.2.3', 'CUDA_VERSION': '11.3.1', 'SMDATAPARALLEL_LOCAL_RANK': '0', 'DMLC_INTERFACE': 'eth0', 'OMPI_MCA_orte_tag_output': '1', 'SM_NUM_CPUS': '64', 'CMAKE_PREFIX_PATH': '$(dirname $(which conda))/../', 'DGLBACKEND': 'pytorch', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_HP_BATCH_SIZE': '8', 'USE_SMDEBUG': '0', 'OMPI_MCA_orte_tmpdir_base': '/tmp', 'SSH_CONNECTION': '10.2.236.66 51900 10.2.242.254 22', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'PMIX_RANK': '8', 'PMIX_SERVER_URI2': '2694709248.1;tcp4://127.0.0.1:33499', 'PMIX_SERVER_URI3': '2694709248.1;tcp4://127.0.0.1:33499', 'SM_CURRENT_HOST': 'algo-2', 'OMPI_MCA_initial_wdir': '/opt/ml/code', 'OMPI_FIRST_RANKS': '0', 'SM_INSTANCE_GROUPS': '[\"homogeneousCluster\"]', 'OMPI_MCA_mpi_oversubscribe': '0', '[1,mpirank:12,algo-2]<stdout>:environ({'OMPI_MCA_orte_app_num': '0', 'SHELL': '/bin/bash', 'NVIDIA_VISIBLE_DEVICES': 'all', 'OMPI_MCA_btl_vader_single_copy_mechanism': 'none', 'SAGEMAKER_JOB_NAME': 'pytorch-lightning-2022-08-16-04-40-37-950', 'SM_CHANNELS': '[\"data_path\"]', 'SM_FRAMEWORK_MODULE': 'sagemaker_pytorch_container.training:main', 'OMPI_MCA_orte_precondition_transports': '2c6b6180696abc4e-99036dffeeb77785', 'PYTHONUNBUFFERED': '1', 'OMPI_MCA_shmem_RUNTIME_QUERY_hint': 'mmap', 'OMPI_UNIVERSE_SIZE': '16', 'OMPI_MCA_rmaps_base_oversubscribe': '1', 'PMIX_MCA_mca_base_component_show_load_errors': '1', 'SM_HOSTS': '[\"algo-1\",\"algo-2\"]', 'LOCAL_RANK': '4', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-0f66adf8f3e516732efee12a20cd80ab606b21ea2a19d5d7fde97a2cf76019bf-customer', 'OMPI_MCA_ess_base_num_procs': '2', 'PMIX_HOSTNAME': 'algo-2', 'SAGEMAKER_TRAINING_MODULE': 'sagemaker_pytorch_container.training:main', 'HOSTNAME': 'ip-10-2-242-254.ec2.internal', 'OMPI_COMM_WORLD_NODE_RANK': '4', 'OMPI_MCA_ess_base_vpid': '12', 'SM_MODULE_NAME': 'semantic_segmentation', 'PMIX_SECURITY_MODE': 'native', 'MASTER_PORT': '7592', 'OMPI_MCA_orte_hnp_uri': '2694709248.0;tcp://10.2.236.66:44785', 'NVIDIA_REQUIRE_CUDA': 'cuda>=11.3 brand=tesla,driver>=418,driver<419 driver>=450', 'SMDATAPARALLEL_USE_ENA': '1', 'OMPI_MCA_plm_rsh_num_concurrent': '2', 'MANUAL_BUILD': '0', 'SM_INSTANCE_GROUPS_DICT': '{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}}', 'BRANCH_OFI': '1.3.0-aws', 'TORCH_NVCC_FLAGS': '-Xfatbin -compress-all', 'OMPI_MCA_btl': '^openib', 'SAGEMAKER_INSTANCE_TYPE': 'ml.p3.16xlarge', 'OMPI_COMM_WORLD_LOCAL_RANK': '4', 'TORCH_CUDA_ARCH_LIST': '3.7 5.0 7.0+PTX 8.0', 'NCCL_VERSION': '2.10.3', 'NCCL_SOCKET_IFNAME': 'eth0', 'HFI_NO_BACKTRACE': '1', 'AWS_REGION': 'us-east-1', 'PMIX_GDS_MODULE': 'ds21,ds12,hash', 'PWD': '/opt/ml/code', 'SMDATAPARALLEL_WORLD_RANK': '12', 'OMPI_MCA_orte_abort_on_non_zero_status': '1', 'OMPI_MCA_orte_local_daemon_uri': '2694709248.1;tcp://10.2.242.254:59027', 'LOGNAME': 'root', 'RDMAV_FORK_SAFE': '1', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility,compat32,graphics,video', 'OMPI_MCA_oob_tcp_if_include': 'eth0', 'NCCL_DEBUG': 'INFO', 'OMPI_MCA_pml': 'ob1', 'HOROVOD_VERSION': '0.24.3', '_': '/opt/conda/bin/python3.8', 'PMIX_SYSTEM_TMPDIR': '/tmp', 'WORLD_SIZE': '16', 'SM_USER_ENTRY_POINT': 'semantic_segmentation.py', 'OPEN_MPI_PATH': '/opt/amazon/openmpi', 'OMPI_ARGV': '/opt/conda/bin/python3.8 -m mpi4py semantic_segmentation.py --batch_size 8', 'PMIX_BFROP_BUFFER_TYPE': 'PMIX_BFROP_BUFFER_NON_DESC', 'OMPI_MCA_orte_node_regex': 'algo-[1:1-2]@0(2)', 'MOTD_SHOWN': 'pam', 'LD_PRELOAD': '/opt/conda/lib/python3.8/site-packages/gethostname.cpython-38-x86_64-linux-gnu.so', 'NV_CUDA_CUDART_VERSION': '11.3.109-1', 'PMIX_PTL_MODULE': 'tcp,usock', 'HOME': '/root', 'FI_PROVIDER': 'efa', 'OMPI_NUM_APP_CTX': '1', 'LANG': 'C.UTF-8', 'DYLD_LIBRARY_PATH': '/opt/amazon/openmpi/lib:', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'PMIX_DSTORE_21_BASE_PATH': '/tmp/ompi.algo-2.0/jf.41118/pmix_dstor_ds21_128', 'SM_IS_HETERO': 'false', 'OMPI_MCA_orte_num_nodes': '2', 'OMPI_MCA_orte_daemonize': '1', 'SM_CURRENT_INSTANCE_TYPE': 'ml.p3.16xlarge', 'PMIX_VERSION': '3.2.3', 'CUDA_VERSION': '11.3.1', 'SMDATAPARALLEL_LOCAL_RANK': '4', 'DMLC_INTERFACE': 'eth0', 'OMPI_MCA_orte_tag_output': '1', 'SM_NUM_CPUS': '64', 'CMAKE_PREFIX_PATH': '$(dirname $(which conda))/../', 'DGLBACKEND': 'pytorch', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_HP_BATCH_SIZE': '8', 'USE_SMDEBUG': '0', 'OMPI_MCA_orte_tmpdir_base': '/tmp', 'SSH_CONNECTION': '10.2.236.66 51900 10.2.242.254 22', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'PMIX_RANK': '12', 'PMIX_SERVER_URI2': '2694709248.1;tcp4://127.0.0.1:33499', 'PMIX_SERVER_URI3': '2694709248.1;tcp4://127.0.0.1:33499', 'SM_CURRENT_HOST': 'algo-2', 'OMPI_MCA_initial_wdir': '/opt/ml/code', 'OMPI_FIRST_RANKS': '0', 'SM_INSTANCE_GROUPS': '[\"homogeneousCluster\"]', 'OMPI_MCA_mpi_oversubscribe': '0'\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:SMDATAPARALLEL_WORLD_SIZE': '16', 'OMPI_MCA_orte_jobfam_session_dir': '/tmp/ompi.algo-2.0/jf.41118', 'MASTER_ADDR': 'algo-1', 'SM_INPUT_DATA_CONFIG': '{\"data_path\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}', 'SM_NUM_GPUS': '8', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_RESOURCE_CONFIG': '{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.p3.16xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}],\"network_interface_name\":\"eth0\"}', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'PYTHONPATH': '/opt/ml/code:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220722-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg', 'PMIX_SERVER_URI21': '2694709248.1;tcp4://127.0.0.1:33499', 'SM_LOG_LEVEL': '20', 'SM_DISTRIBUTION_INSTANCE_GROUPS': '[\"homogeneousCluster\"]', 'PMIX_DSTORE_ESH_BASE_PATH': '/tmp/ompi.algo-2.0/jf.41118/pmix_dstor_ds12_128', 'USER': 'root', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_pytorch_ddp_enabled\":true},\"channel_input_dirs\":{\"data_path\":\"/opt/ml/input/data/data_path\"},\"current_host\":\"algo-2\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.p3.16xlarge\",\"distribution_hosts\":[\"algo-1\",\"algo-2\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"batch_size\":8},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"data_path\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}},\"is_hetero\":false,\"is_master\":false,\"is_modelpara', 'OMPI_MCA_plm': 'rsh', 'SM_CURRENT_INSTANCE_GROUP': 'homogeneousCluster', 'OMPI_MCA_orte_ess_num_procs': '16', 'OMPI_FILE_LOCATION': '/tmp/ompi.algo-2.0/jf.41118/0/1', 'PYTHONIOENCODING': 'UTF-8', 'OMPI_MCA_plm_rsh_no_tree_spawn': '1', 'OMPI_COMM_WORLD_SIZE': '16', 'OMPI_MCA_orte_ess_node_rank': '0', 'SHLVL': '4', 'SAGEMAKER_REGION': 'us-east-1', 'SMDATAPARALLEL_SERVER_PORT': '7592', 'NVARCH': 'x86_64', 'PMIX_ID': '2694709249.8', 'CUDNN_VERSION': '8.2.0.53', 'SMDATAPARALLEL_SERVER_ADDR': 'algo-1', 'OMPI_COMM_WORLD_LOCAL_SIZE': '8', 'EFA_VERSION': '1.15.1', 'PYTHONDONTWRITEBYTECODE': '1', 'NV_CUDA_COMPAT_PACKAGE': 'cuda-compat-11-3', 'PMIX_SERVER_TMPDIR': '/tmp/ompi.algo-2.0/jf.41118', 'SM_CURRENT_INSTANCE_GROUP_HOSTS': '[\"algo-1\",\"algo-2\"]', 'LD_LIBRARY_PATH': '/opt/amazon/openmpi/lib:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/amazon/openmpi/lib/:/opt/amazon/efa/lib/:/opt/conda/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64', 'NCCL_IB_DISABLE': '1', 'OMPI_COMMAND': 'smddprun', 'RANK': '8', 'OMPI_MCA_ess': '^singleton', 'OMPI_VERSION': '4.1.1', 'SSH_CLIENT': '10.2.236.66 51900 22', 'SM_FRAMEWORK_PARAMS': '{\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_pytorch_ddp_enabled\":true}', 'SM_MODULE_DIR': 's3://sagemaker-us-east-1-631450739534/pytorch-lightning-2022-08-16-04-40-37-950/source/sourcedir.tar.gz', 'PMIX_NAMESPACE': '2694709249', 'TRAINING_JOB_NAME': 'pytorch-lightning-2022-08-16-04-40-37-950', 'CURRENT_HOST': 'algo-2', 'LC_ALL': 'C.UTF-8', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:631450739534:training-job/pytorch-lightning-2022-08-16-04-40-37-950', 'SM_CHANNEL_DATA_PATH': '/opt/ml/input/[1,mpirank:12,algo-2]<stdout>:, 'SMDATAPARALLEL_WORLD_SIZE': '16', 'OMPI_MCA_orte_jobfam_session_dir': '/tmp/ompi.algo-2.0/jf.41118', 'MASTER_ADDR': 'algo-1', 'SM_INPUT_DATA_CONFIG': '{\"data_path\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}', 'SM_NUM_GPUS': '8', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_RESOURCE_CONFIG': '{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.p3.16xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}],\"network_interface_name\":\"eth0\"}', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'PYTHONPATH': '/opt/ml/code:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220722-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg', 'PMIX_SERVER_URI21': '2694709248.1;tcp4://127.0.0.1:33499', 'SM_LOG_LEVEL': '20', 'SM_DISTRIBUTION_INSTANCE_GROUPS': '[\"homogeneousCluster\"]', 'PMIX_DSTORE_ESH_BASE_PATH': '/tmp/ompi.algo-2.0/jf.41118/pmix_dstor_ds12_128', 'USER': 'root', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_pytorch_ddp_enabled\":true},\"channel_input_dirs\":{\"data_path\":\"/opt/ml/input/data/data_path\"},\"current_host\":\"algo-2\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.p3.16xlarge\",\"distribution_hosts\":[\"algo-1\",\"algo-2\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"batch_size\":8},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"data_path\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}},\"is_hetero\":false,\"is_master\":false,\"is_modelpara', 'OMPI_MCA_plm': 'rsh', 'SM_CURRENT_INSTANCE_GROUP': 'homogeneousCluster', 'OMPI_MCA_orte_ess_num_procs': '16', 'OMPI_FILE_LOCATION': '/tmp/ompi.algo-2.0/jf.41118/0/1', 'PYTHONIOENCODING': 'UTF-8', 'OMPI_MCA_plm_rsh_no_tree_spawn': '1', 'OMPI_COMM_WORLD_SIZE': '16', 'OMPI_MCA_orte_ess_node_rank': '4', 'SHLVL': '4', 'SAGEMAKER_REGION': 'us-east-1', 'SMDATAPARALLEL_SERVER_PORT': '7592', 'NVARCH': 'x86_64', 'PMIX_ID': '2694709249.12', 'CUDNN_VERSION': '8.2.0.53', 'SMDATAPARALLEL_SERVER_ADDR': 'algo-1', 'OMPI_COMM_WORLD_LOCAL_SIZE': '8', 'EFA_VERSION': '1.15.1', 'PYTHONDONTWRITEBYTECODE': '1', 'NV_CUDA_COMPAT_PACKAGE': 'cuda-compat-11-3', 'PMIX_SERVER_TMPDIR': '/tmp/ompi.algo-2.0/jf.41118', 'SM_CURRENT_INSTANCE_GROUP_HOSTS': '[\"algo-1\",\"algo-2\"]', 'LD_LIBRARY_PATH': '/opt/amazon/openmpi/lib:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/amazon/openmpi/lib/:/opt/amazon/efa/lib/:/opt/conda/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64', 'NCCL_IB_DISABLE': '1', 'OMPI_COMMAND': 'smddprun', 'RANK': '12', 'OMPI_MCA_ess': '^singleton', 'OMPI_VERSION': '4.1.1', 'SSH_CLIENT': '10.2.236.66 51900 22', 'SM_FRAMEWORK_PARAMS': '{\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_pytorch_ddp_enabled\":true}', 'SM_MODULE_DIR': 's3://sagemaker-us-east-1-631450739534/pytorch-lightning-2022-08-16-04-40-37-950/source/sourcedir.tar.gz', 'PMIX_NAMESPACE': '2694709249', 'TRAINING_JOB_NAME': 'pytorch-lightning-2022-08-16-04-40-37-950', 'CURRENT_HOST': 'algo-2', 'LC_ALL': 'C.UTF-8', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:631450739534:training-job/pytorch-lightning-2022-08-16-04-40-37-950', 'SM_CHANNEL_DATA_PATH': '/opt/ml/i[1,mpirank:8,algo-2]<stdout>:data/data_path', 'PATH': '/opt/amazon/openmpi/bin:/opt/amazon/openmpi/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'SM_USER_ARGS': '[\"--batch_size\",\"8\"]', 'OMPI_MCA_pmix': '^s1,s2,cray,isolated', 'OMPI_MCA_ess_base_jobid': '2694709249', 'OMPI_MCA_btl_tcp_if_include': 'eth0', 'SM_HPS': '{\"batch_size\":8}', 'OMPI_APP_CTX_NUM_PROCS': '16', 'SMDATAPARALLEL_USE_HOMOGENEOUS': '1', 'IPATH_NO_BACKTRACE': '1', 'OMPI_MCA_orte_top_session_dir': '/tmp/ompi.algo-2.0', 'OMPI_MCA_orte_launch': '1', 'SMDATAPARALLEL_NUM_CONN': '5', 'SM_MODEL_DIR': '/opt/ml/model', 'DLC_CONTAINER_TYPE': 'training', 'OMPI_COMM_WORLD_RANK': '8'})\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:nput/data/data_path', 'PATH': '/opt/amazon/openmpi/bin:/opt/amazon/openmpi/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'SM_USER_ARGS': '[\"--batch_size\",\"8\"]', 'OMPI_MCA_pmix': '^s1,s2,cray,isolated', 'OMPI_MCA_ess_base_jobid': '2694709249', 'OMPI_MCA_btl_tcp_if_include': 'eth0', 'SM_HPS': '{\"batch_size\":8}', 'OMPI_APP_CTX_NUM_PROCS': '16', 'SMDATAPARALLEL_USE_HOMOGENEOUS': '1', 'IPATH_NO_BACKTRACE': '1', 'OMPI_MCA_orte_top_session_dir': '/tmp/ompi.algo-2.0', 'OMPI_MCA_orte_launch': '1', 'SMDATAPARALLEL_NUM_CONN': '5', 'SM_MODEL_DIR': '/opt/ml/model', 'DLC_CONTAINER_TYPE': 'training', 'OMPI_COMM_WORLD_RANK': '12'})\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:environ({'OMPI_MCA_orte_app_num': '0', 'SHELL': '/bin/bash', 'NVIDIA_VISIBLE_DEVICES': 'all', 'OMPI_MCA_btl_vader_single_copy_mechanism': 'none', 'SAGEMAKER_JOB_NAME': 'pytorch-lightning-2022-08-16-04-40-37-950', 'SM_CHANNELS': '[\"data_path\"]', 'SM_FRAMEWORK_MODULE': 'sagemaker_pytorch_container.training:main', 'OMPI_MCA_orte_precondition_transports': '2c6b6180696abc4e-99036dffeeb77785', 'PYTHONUNBUFFERED': '1', 'OMPI_MCA_shmem_RUNTIME_QUERY_hint': 'mmap', 'OMPI_UNIVERSE_SIZE': '16', 'OMPI_MCA_rmaps_base_oversubscribe': '1', 'PMIX_MCA_mca_base_component_show_load_errors': '1', 'SM_HOSTS': '[\"algo-1\",\"algo-2\"]', 'LOCAL_RANK': '2', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-0f66adf8f3e516732efee12a20cd80ab606b21ea2a19d5d7fde97a2cf76019bf-customer', 'OMPI_MCA_ess_base_num_procs': '2', 'PMIX_HOSTNAME': 'algo-2', 'SAGEMAKER_TRAINING_MODULE': 'sagemaker_pytorch_container.training:main', 'HOSTNAME': 'ip-10-2-242-254.ec2.internal', 'OMPI_COMM_WORLD_NODE_RANK': '2', 'OMPI_MCA_ess_base_vpid': '10', 'SM_MODULE_NAME': 'semantic_segmentation', 'PMIX_SECURITY_MODE': 'native', 'MASTER_PORT': '7592', 'OMPI_MCA_orte_hnp_uri': '2694709248.0;tcp://10.2.236.66:44785', 'NVIDIA_REQUIRE_CUDA': 'cuda>=11.3 brand=tesla,driver>=418,driver<419 driver>=450', 'SMDATAPARALLEL_USE_ENA': '1', 'OMPI_MCA_plm_rsh_num_concurrent': '2', 'MANUAL_BUILD': '0', 'SM_INSTANCE_GROUPS_DICT': '{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}}', 'BRANCH_OFI': '1.3.0-aws', 'TORCH_NVCC_FLAGS': '-Xfatbin -compress-all', 'OMPI_MCA_btl': '^openib', 'SAGEMAKER_INSTANCE_TYPE': 'ml.p3.16xlarge', 'OMPI_COMM_WORLD_LOCAL_RANK': '2', 'TORCH_CUDA_ARCH_LIST': '3.7 5.0 7.0+PTX 8.0', 'NCCL_VERSION': '2.10.3', 'NCCL_SOCKET_IFNAME': 'eth0', 'HFI_NO_BACKTRACE': '1', 'AWS_REGION': 'us-east-1', 'PMIX_GDS_MODULE': 'ds21,ds12,hash', 'PWD': '/opt/ml/code', 'SMDATAPARALLEL_WORLD_RANK': '10', 'OMPI_MCA_orte_abort_on_non_zero_status': '1', 'OMPI_MCA_orte_local_daemon_uri': '2694709248.1;tcp://10.2.242.254:59027', 'LOGNAME': 'root', 'RDMAV_FORK_SAFE': '1', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility,compat32,graphics,video', 'OMPI_MCA_oob_tcp_if_include': 'eth0', 'NCCL_DEBUG': 'INFO', 'OMPI_MCA_pml': 'ob1', 'HOROVOD_VERSION': '0.24.3', '_': '/opt/conda/bin/python3.8', 'PMIX_SYSTEM_TMPDIR': '/tmp', 'WORLD_SIZE': '16', 'SM_USER_ENTRY_POINT': 'semantic_segmentation.py', 'OPEN_MPI_PATH': '/opt/amazon/openmpi', 'OMPI_ARGV': '/opt/conda/bin/python3.8 -m mpi4py semantic_segmentation.py --batch_size 8', 'PMIX_BFROP_BUFFER_TYPE': 'PMIX_BFROP_BUFFER_NON_DESC', 'OMPI_MCA_orte_node_regex': 'algo-[1:1-2]@0(2)', 'MOTD_SHOWN': 'pam', 'LD_PRELOAD': '/opt/conda/lib/python3.8/site-packages/gethostname.cpython-38-x86_64-linux-gnu.so', 'NV_CUDA_CUDART_VERSION': '11.3.109-1', 'PMIX_PTL_MODULE': 'tcp,usock', 'HOME': '/root', 'FI_PROVIDER': 'efa', 'OMPI_NUM_APP_CTX': '1', 'LANG': 'C.UTF-8', 'DYLD_LIBRARY_PATH': '/opt/amazon/openmpi/lib:', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'PMIX_DSTORE_21_BASE_PATH': '/tmp/ompi.algo-2.0/jf.41118/pmix_dstor_ds21_128', 'SM_IS_HETERO': 'false', 'OMPI_MCA_orte_num_nodes': '2', 'OMPI_MCA_orte_daemonize': '1', 'SM_CURRENT_INSTANCE_TYPE': 'ml.p3.16xlarge', 'PMIX_VERSION': '3.2.3', 'CUDA_VERSION': '11.3.1', 'SMDATAPARALLEL_LOCAL_RANK': '2', 'DMLC_INTERFACE': 'eth0', 'OMPI_MCA_orte_tag_output': '1', 'SM_NUM_CPUS': '64', 'CMAKE_PREFIX_PATH': '$(dirname $(which conda))/../', 'DGLBACKEND': 'pytorch', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_HP_BATCH_SIZE': '8', 'USE_SMDEBUG': '0', 'OMPI_MCA_orte_tmpdir_base': '/tmp', 'SSH_CONNECTION': '10.2.236.66 51900 10.2.242.254 22', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'PMIX_RANK': '10', 'PMIX_SERVER_URI2': '2694709248.1;tcp4://127.0.0.1:33499', 'PMIX_SERVER_URI3': '2694709248.1;tcp4://127.0.0.1:33499', 'SM_CURRENT_HOST': 'algo-2', 'OMPI_MCA_initial_wdir': '/opt/ml/code', 'OMPI_FIRST_RANKS': '0', 'SM_INSTANCE_GROUPS': '[\"homogeneousCluster\"]', 'OMPI_MCA_mpi_oversubscribe': '0'[1,mpirank:10,algo-2]<stdout>:, 'SMDATAPARALLEL_WORLD_SIZE': '16', 'OMPI_MCA_orte_jobfam_session_dir': '/tmp/ompi.algo-2.0/jf.41118', 'MASTER_ADDR': 'algo-1', 'SM_INPUT_DATA_CONFIG': '{\"data_path\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}', 'SM_NUM_GPUS': '8', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_RESOURCE_CONFIG': '{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.p3.16xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}],\"network_interface_name\":\"eth0\"}', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'PYTHONPATH': '/opt/ml/code:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220722-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg', 'PMIX_SERVER_URI21': '2694709248.1;tcp4://127.0.0.1:33499', 'SM_LOG_LEVEL': '20', 'SM_DISTRIBUTION_INSTANCE_GROUPS': '[\"homogeneousCluster\"]', 'PMIX_DSTORE_ESH_BASE_PATH': '/tmp/ompi.algo-2.0/jf.41118/pmix_dstor_ds12_128', 'USER': 'root', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_pytorch_ddp_enabled\":true},\"channel_input_dirs\":{\"data_path\":\"/opt/ml/input/data/data_path\"},\"current_host\":\"algo-2\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.p3.16xlarge\",\"distribution_hosts\":[\"algo-1\",\"algo-2\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"batch_size\":8},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"data_path\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}},\"is_hetero\":false,\"is_master\":false,\"is_modelpara', 'OMPI_MCA_plm': 'rsh', 'SM_CURRENT_INSTANCE_GROUP': 'homogeneousCluster', 'OMPI_MCA_orte_ess_num_procs': '16', 'OMPI_FILE_LOCATION': '/tmp/ompi.algo-2.0/jf.41118/0/1', 'PYTHONIOENCODING': 'UTF-8', 'OMPI_MCA_plm_rsh_no_tree_spawn': '1', 'OMPI_COMM_WORLD_SIZE': '16', 'OMPI_MCA_orte_ess_node_rank': '2', 'SHLVL': '4', 'SAGEMAKER_REGION': 'us-east-1', 'SMDATAPARALLEL_SERVER_PORT': '7592', 'NVARCH': 'x86_64', 'PMIX_ID': '2694709249.10', 'CUDNN_VERSION': '8.2.0.53', 'SMDATAPARALLEL_SERVER_ADDR': 'algo-1', 'OMPI_COMM_WORLD_LOCAL_SIZE': '8', 'EFA_VERSION': '1.15.1', 'PYTHONDONTWRITEBYTECODE': '1', 'NV_CUDA_COMPAT_PACKAGE': 'cuda-compat-11-3', 'PMIX_SERVER_TMPDIR': '/tmp/ompi.algo-2.0/jf.41118', 'SM_CURRENT_INSTANCE_GROUP_HOSTS': '[\"algo-1\",\"algo-2\"]', 'LD_LIBRARY_PATH': '/opt/amazon/openmpi/lib:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/amazon/openmpi/lib/:/opt/amazon/efa/lib/:/opt/conda/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64', 'NCCL_IB_DISABLE': '1', 'OMPI_COMMAND': 'smddprun', 'RANK': '10', 'OMPI_MCA_ess': '^singleton', 'OMPI_VERSION': '4.1.1', 'SSH_CLIENT': '10.2.236.66 51900 22', 'SM_FRAMEWORK_PARAMS': '{\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_pytorch_ddp_enabled\":true}', 'SM_MODULE_DIR': 's3://sagemaker-us-east-1-631450739534/pytorch-lightning-2022-08-16-04-40-37-950/source/sourcedir.tar.gz', 'PMIX_NAMESPACE': '2694709249', 'TRAINING_JOB_NAME': 'pytorch-lightning-2022-08-16-04-40-37-950', 'CURRENT_HOST': 'algo-2', 'LC_ALL': 'C.UTF-8', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:631450739534:training-job/pytorch-lightning-2022-08-16-04-40-37-950', 'SM_CHANNEL_DATA_PATH': '/opt/ml/i[1,mpirank:10,algo-2]<stdout>:nput/data/data_path', 'PATH': '/opt/amazon/openmpi/bin:/opt/amazon/openmpi/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'SM_USER_ARGS': '[\"--batch_size\",\"8\"]', 'OMPI_MCA_pmix': '^s1,s2,cray,isolated', 'OMPI_MCA_ess_base_jobid': '2694709249', 'OMPI_MCA_btl_tcp_if_include': 'eth0', 'SM_HPS': '{\"batch_size\":8}', 'OMPI_APP_CTX_NUM_PROCS': '16', 'SMDATAPARALLEL_USE_HOMOGENEOUS': '1', 'IPATH_NO_BACKTRACE': '1', 'OMPI_MCA_orte_top_session_dir': '/tmp/ompi.algo-2.0', 'OMPI_MCA_orte_launch': '1', 'SMDATAPARALLEL_NUM_CONN': '5', 'SM_MODEL_DIR': '/opt/ml/model', 'DLC_CONTAINER_TYPE': 'training', 'OMPI_COMM_WORLD_RANK': '10'})\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:environ({'OMPI_MCA_orte_app_num': '0', 'SHELL': '/bin/bash', 'NVIDIA_VISIBLE_DEVICES': 'all', 'OMPI_MCA_btl_vader_single_copy_mechanism': 'none', 'SAGEMAKER_JOB_NAME': 'pytorch-lightning-2022-08-16-04-40-37-950', 'SM_CHANNELS': '[\"data_path\"]', 'SM_FRAMEWORK_MODULE': 'sagemaker_pytorch_container.training:main', 'OMPI_MCA_orte_precondition_transports': '2c6b6180696abc4e-99036dffeeb77785', 'PYTHONUNBUFFERED': '1', 'OMPI_MCA_shmem_RUNTIME_QUERY_hint': 'mmap', 'OMPI_UNIVERSE_SIZE': '16', 'OMPI_MCA_rmaps_base_oversubscribe': '1', 'PMIX_MCA_mca_base_component_show_load_errors': '1', 'SM_HOSTS': '[\"algo-1\",\"algo-2\"]', 'LOCAL_RANK': '6', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-0f66adf8f3e516732efee12a20cd80ab606b21ea2a19d5d7fde97a2cf76019bf-customer', 'OMPI_MCA_ess_base_num_procs': '2', 'PMIX_HOSTNAME': 'algo-2', 'SAGEMAKER_TRAINING_MODULE': 'sagemaker_pytorch_container.training:main', 'HOSTNAME': 'ip-10-2-242-254.ec2.internal', 'OMPI_COMM_WORLD_NODE_RANK': '6', 'OMPI_MCA_ess_base_vpid': '14', 'SM_MODULE_NAME': 'semantic_segmentation', 'PMIX_SECURITY_MODE': 'native', 'MASTER_PORT': '7592', 'OMPI_MCA_orte_hnp_uri': '2694709248.0;tcp://10.2.236.66:44785', 'NVIDIA_REQUIRE_CUDA': 'cuda>=11.3 brand=tesla,driver>=418,driver<419 driver>=450', 'SMDATAPARALLEL_USE_ENA': '1', 'OMPI_MCA_plm_rsh_num_concurrent': '2', 'MANUAL_BUILD': '0', 'SM_INSTANCE_GROUPS_DICT': '{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}}', 'BRANCH_OFI': '1.3.0-aws', 'TORCH_NVCC_FLAGS': '-Xfatbin -compress-all', 'OMPI_MCA_btl': '^openib', 'SAGEMAKER_INSTANCE_TYPE': 'ml.p3.16xlarge', 'OMPI_COMM_WORLD_LOCAL_RANK': '6', 'TORCH_CUDA_ARCH_LIST': '3.7 5.0 7.0+PTX 8.0', 'NCCL_VERSION': '2.10.3', 'NCCL_SOCKET_IFNAME': 'eth0', 'HFI_NO_BACKTRACE': '1', 'AWS_REGION': 'us-east-1', 'PMIX_GDS_MODULE': 'ds21,ds12,hash', 'PWD': '/opt/ml/code', 'SMDATAPARALLEL_WORLD_RANK': '14', 'OMPI_MCA_orte_abort_on_non_zero_status': '1', 'OMPI_MCA_orte_local_daemon_uri': '2694709248.1;tcp://10.2.242.254:59027', 'LOGNAME': 'root', 'RDMAV_FORK_SAFE': '1', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility,compat32,graphics,video', 'OMPI_MCA_oob_tcp_if_include': 'eth0', 'NCCL_DEBUG': 'INFO', 'OMPI_MCA_pml': 'ob1', 'HOROVOD_VERSION': '0.24.3', '_': '/opt/conda/bin/python3.8', 'PMIX_SYSTEM_TMPDIR': '/tmp', 'WORLD_SIZE': '16', 'SM_USER_ENTRY_POINT': 'semantic_segmentation.py', 'OPEN_MPI_PATH': '/opt/amazon/openmpi', 'OMPI_ARGV': '/opt/conda/bin/python3.8 -m mpi4py semantic_segmentation.py --batch_size 8', 'PMIX_BFROP_BUFFER_TYPE': 'PMIX_BFROP_BUFFER_NON_DESC', 'OMPI_MCA_orte_node_regex': 'algo-[1:1-2]@0(2)', 'MOTD_SHOWN': 'pam', 'LD_PRELOAD': '/opt/conda/lib/python3.8/site-packages/gethostname.cpython-38-x86_64-linux-gnu.so', 'NV_CUDA_CUDART_VERSION': '11.3.109-1', 'PMIX_PTL_MODULE': 'tcp,usock', 'HOME': '/root', 'FI_PROVIDER': 'efa', 'OMPI_NUM_APP_CTX': '1', 'LANG': 'C.UTF-8', 'DYLD_LIBRARY_PATH': '/opt/amazon/openmpi/lib:', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'PMIX_DSTORE_21_BASE_PATH': '/tmp/ompi.algo-2.0/jf.41118/pmix_dstor_ds21_128', 'SM_IS_HETERO': 'false', 'OMPI_MCA_orte_num_nodes': '2', 'OMPI_MCA_orte_daemonize': '1', 'SM_CURRENT_INSTANCE_TYPE': 'ml.p3.16xlarge', 'PMIX_VERSION': '3.2.3', 'CUDA_VERSION': '11.3.1', 'SMDATAPARALLEL_LOCAL_RANK': '6', 'DMLC_INTERFACE': 'eth0', 'OMPI_MCA_orte_tag_output': '1', 'SM_NUM_CPUS': '64', 'CMAKE_PREFIX_PATH': '$(dirname $(which conda))/../', 'DGLBACKEND': 'pytorch', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_HP_BATCH_SIZE': '8', 'USE_SMDEBUG': '0', 'OMPI_MCA_orte_tmpdir_base': '/tmp', 'SSH_CONNECTION': '10.2.236.66 51900 10.2.242.254 22', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'PMIX_RANK': '14', 'PMIX_SERVER_URI2': '2694709248.1;tcp4://127.0.0.1:33499', 'PMIX_SERVER_URI3': '2694709248.1;tcp4://127.0.0.1:33499', 'SM_CURRENT_HOST': 'algo-2', 'OMPI_MCA_initial_wdir': '/opt/ml/code', 'OMPI_FIRST_RANKS': '0', 'SM_INSTANCE_GROUPS': '[\"homogeneousCluster\"]', 'OMPI_MCA_mpi_oversubscribe': '0'[1,mpirank:14,algo-2]<stdout>:, 'SMDATAPARALLEL_WORLD_SIZE': '16', 'OMPI_MCA_orte_jobfam_session_dir': '/tmp/ompi.algo-2.0/jf.41118', 'MASTER_ADDR': 'algo-1', 'SM_INPUT_DATA_CONFIG': '{\"data_path\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}', 'SM_NUM_GPUS': '8', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_RESOURCE_CONFIG': '{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.p3.16xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}],\"network_interface_name\":\"eth0\"}', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'PYTHONPATH': '/opt/ml/code:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220722-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg', 'PMIX_SERVER_URI21': '2694709248.1;tcp4://127.0.0.1:33499', 'SM_LOG_LEVEL': '20', 'SM_DISTRIBUTION_INSTANCE_GROUPS': '[\"homogeneousCluster\"]', 'PMIX_DSTORE_ESH_BASE_PATH': '/tmp/ompi.algo-2.0/jf.41118/pmix_dstor_ds12_128', 'USER': 'root', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_pytorch_ddp_enabled\":true},\"channel_input_dirs\":{\"data_path\":\"/opt/ml/input/data/data_path\"},\"current_host\":\"algo-2\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.p3.16xlarge\",\"distribution_hosts\":[\"algo-1\",\"algo-2\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"batch_size\":8},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"data_path\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}},\"is_hetero\":false,\"is_master\":false,\"is_modelpara', 'OMPI_MCA_plm': 'rsh', 'SM_CURRENT_INSTANCE_GROUP': 'homogeneousCluster', 'OMPI_MCA_orte_ess_num_procs': '16', 'OMPI_FILE_LOCATION': '/tmp/ompi.algo-2.0/jf.41118/0/1', 'PYTHONIOENCODING': 'UTF-8', 'OMPI_MCA_plm_rsh_no_tree_spawn': '1', 'OMPI_COMM_WORLD_SIZE': '16', 'OMPI_MCA_orte_ess_node_rank': '6', 'SHLVL': '4', 'SAGEMAKER_REGION': 'us-east-1', 'SMDATAPARALLEL_SERVER_PORT': '7592', 'NVARCH': 'x86_64', 'PMIX_ID': '2694709249.14', 'CUDNN_VERSION': '8.2.0.53', 'SMDATAPARALLEL_SERVER_ADDR': 'algo-1', 'OMPI_COMM_WORLD_LOCAL_SIZE': '8', 'EFA_VERSION': '1.15.1', 'PYTHONDONTWRITEBYTECODE': '1', 'NV_CUDA_COMPAT_PACKAGE': 'cuda-compat-11-3', 'PMIX_SERVER_TMPDIR': '/tmp/ompi.algo-2.0/jf.41118', 'SM_CURRENT_INSTANCE_GROUP_HOSTS': '[\"algo-1\",\"algo-2\"]', 'LD_LIBRARY_PATH': '/opt/amazon/openmpi/lib:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/amazon/openmpi/lib/:/opt/amazon/efa/lib/:/opt/conda/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64', 'NCCL_IB_DISABLE': '1', 'OMPI_COMMAND': 'smddprun', 'RANK': '14', 'OMPI_MCA_ess': '^singleton', 'OMPI_VERSION': '4.1.1', 'SSH_CLIENT': '10.2.236.66 51900 22', 'SM_FRAMEWORK_PARAMS': '{\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_pytorch_ddp_enabled\":true}', 'SM_MODULE_DIR': 's3://sagemaker-us-east-1-631450739534/pytorch-lightning-2022-08-16-04-40-37-950/source/sourcedir.tar.gz', 'PMIX_NAMESPACE': '2694709249', 'TRAINING_JOB_NAME': 'pytorch-lightning-2022-08-16-04-40-37-950', 'CURRENT_HOST': 'algo-2', 'LC_ALL': 'C.UTF-8', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:631450739534:training-job/pytorch-lightning-2022-08-16-04-40-37-950', 'SM_CHANNEL_DATA_PATH': '/opt/ml/i[1,mpirank:14,algo-2]<stdout>:nput/data/data_path', 'PATH': '/opt/amazon/openmpi/bin:/opt/amazon/openmpi/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'SM_USER_ARGS': '[\"--batch_size\",\"8\"]', 'OMPI_MCA_pmix': '^s1,s2,cray,isolated', 'OMPI_MCA_ess_base_jobid': '2694709249', 'OMPI_MCA_btl_tcp_if_include': 'eth0', 'SM_HPS': '{\"batch_size\":8}', 'OMPI_APP_CTX_NUM_PROCS': '16', 'SMDATAPARALLEL_USE_HOMOGENEOUS': '1', 'IPATH_NO_BACKTRACE': '1', 'OMPI_MCA_orte_top_session_dir': '/tmp/ompi.algo-2.0', 'OMPI_MCA_orte_launch': '1', 'SMDATAPARALLEL_NUM_CONN': '5', 'SM_MODEL_DIR': '/opt/ml/model', 'DLC_CONTAINER_TYPE': 'training', 'OMPI_COMM_WORLD_RANK': '14'})\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:environ({'OMPI_MCA_orte_app_num': '0', 'SHELL': '/bin/bash', 'NVIDIA_VISIBLE_DEVICES': 'all', 'OMPI_MCA_btl_vader_single_copy_mechanism': 'none', 'SAGEMAKER_JOB_NAME': 'pytorch-lightning-2022-08-16-04-40-37-950', 'SM_CHANNELS': '[\"data_path\"]', 'SM_FRAMEWORK_MODULE': 'sagemaker_pytorch_container.training:main', 'OMPI_MCA_orte_precondition_transports': '2c6b6180696abc4e-99036dffeeb77785', 'PYTHONUNBUFFERED': '1', 'OMPI_MCA_shmem_RUNTIME_QUERY_hint': 'mmap', 'OMPI_UNIVERSE_SIZE': '16', 'OMPI_MCA_rmaps_base_oversubscribe': '1', 'PMIX_MCA_mca_base_component_show_load_errors': '1', 'SM_HOSTS': '[\"algo-1\",\"algo-2\"]', 'LOCAL_RANK': '1', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-0f66adf8f3e516732efee12a20cd80ab606b21ea2a19d5d7fde97a2cf76019bf-customer', 'OMPI_MCA_ess_base_num_procs': '2', 'PMIX_HOSTNAME': 'algo-2', 'SAGEMAKER_TRAINING_MODULE': 'sagemaker_pytorch_container.training:main', 'HOSTNAME': 'ip-10-2-242-254.ec2.internal', 'OMPI_COMM_WORLD_NODE_RANK': '1', 'OMPI_MCA_ess_base_vpid': '9', 'SM_MODULE_NAME': 'semantic_segmentation', 'PMIX_SECURITY_MODE': 'native', 'MASTER_PORT': '7592', 'OMPI_MCA_orte_hnp_uri': '2694709248.0;tcp://10.2.236.66:44785', 'NVIDIA_REQUIRE_CUDA': 'cuda>=11.3 brand=tesla,driver>=418,driver<419 driver>=450', 'SMDATAPARALLEL_USE_ENA': '1', 'OMPI_MCA_plm_rsh_num_concurrent': '2', 'MANUAL_BUILD': '0', 'SM_INSTANCE_GROUPS_DICT': '{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}}', 'BRANCH_OFI': '1.3.0-aws', 'TORCH_NVCC_FLAGS': '-Xfatbin -compress-all', 'OMPI_MCA_btl': '^openib', 'SAGEMAKER_INSTANCE_TYPE': 'ml.p3.16xlarge', 'OMPI_COMM_WORLD_LOCAL_RANK': '1', 'TORCH_CUDA_ARCH_LIST': '3.7 5.0 7.0+PTX 8.0', 'NCCL_VERSION': '2.10.3', 'NCCL_SOCKET_IFNAME': 'eth0', 'HFI_NO_BACKTRACE': '1', 'AWS_REGION': 'us-east-1', 'PMIX_GDS_MODULE': 'ds21,ds12,hash', 'PWD': '/opt/ml/code', 'SMDATAPARALLEL_WORLD_RANK': '9', 'OMPI_MCA_orte_abort_on_non_zero_status': '1', 'OMPI_MCA_orte_local_daemon_uri': '2694709248.1;tcp://10.2.242.254:59027', 'LOGNAME': 'root', 'RDMAV_FORK_SAFE': '1', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility,compat32,graphics,video', 'OMPI_MCA_oob_tcp_if_include': 'eth0', 'NCCL_DEBUG': 'INFO', 'OMPI_MCA_pml': 'ob1', 'HOROVOD_VERSION': '0.24.3', '_': '/opt/conda/bin/python3.8', 'PMIX_SYSTEM_TMPDIR': '/tmp', 'WORLD_SIZE': '16', 'SM_USER_ENTRY_POINT': 'semantic_segmentation.py', 'OPEN_MPI_PATH': '/opt/amazon/openmpi', 'OMPI_ARGV': '/opt/conda/bin/python3.8 -m mpi4py semantic_segmentation.py --batch_size 8', 'PMIX_BFROP_BUFFER_TYPE': 'PMIX_BFROP_BUFFER_NON_DESC', 'OMPI_MCA_orte_node_regex': 'algo-[1:1-2]@0(2)', 'MOTD_SHOWN': 'pam', 'LD_PRELOAD': '/opt/conda/lib/python3.8/site-packages/gethostname.cpython-38-x86_64-linux-gnu.so', 'NV_CUDA_CUDART_VERSION': '11.3.109-1', 'PMIX_PTL_MODULE': 'tcp,usock', 'HOME': '/root', 'FI_PROVIDER': 'efa', 'OMPI_NUM_APP_CTX': '1', 'LANG': 'C.UTF-8', 'DYLD_LIBRARY_PATH': '/opt/amazon/openmpi/lib:', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'PMIX_DSTORE_21_BASE_PATH': '/tmp/ompi.algo-2.0/jf.41118/pmix_dstor_ds21_128', 'SM_IS_HETERO': 'false', 'OMPI_MCA_orte_num_nodes': '2', 'OMPI_MCA_orte_daemonize': '1', 'SM_CURRENT_INSTANCE_TYPE': 'ml.p3.16xlarge', 'PMIX_VERSION': '3.2.3', 'CUDA_VERSION': '11.3.1', 'SMDATAPARALLEL_LOCAL_RANK': '1', 'DMLC_INTERFACE': 'eth0', 'OMPI_MCA_orte_tag_output': '1', 'SM_NUM_CPUS': '64', 'CMAKE_PREFIX_PATH': '$(dirname $(which conda))/../', 'DGLBACKEND': 'pytorch', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_HP_BATCH_SIZE': '8', 'USE_SMDEBUG': '0', 'OMPI_MCA_orte_tmpdir_base': '/tmp', 'SSH_CONNECTION': '10.2.236.66 51900 10.2.242.254 22', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'PMIX_RANK': '9', 'PMIX_SERVER_URI2': '2694709248.1;tcp4://127.0.0.1:33499', 'PMIX_SERVER_URI3': '2694709248.1;tcp4://127.0.0.1:33499', 'SM_CURRENT_HOST': 'algo-2', 'OMPI_MCA_initial_wdir': '/opt/ml/code', 'OMPI_FIRST_RANKS': '0', 'SM_INSTANCE_GROUPS': '[\"homogeneousCluster\"]', 'OMPI_MCA_mpi_oversubscribe': '0', '[1,mpirank:9,algo-2]<stdout>:SMDATAPARALLEL_WORLD_SIZE': '16', 'OMPI_MCA_orte_jobfam_session_dir': '/tmp/ompi.algo-2.0/jf.41118', 'MASTER_ADDR': 'algo-1', 'SM_INPUT_DATA_CONFIG': '{\"data_path\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}', 'SM_NUM_GPUS': '8', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_RESOURCE_CONFIG': '{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.p3.16xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}],\"network_interface_name\":\"eth0\"}', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'PYTHONPATH': '/opt/ml/code:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220722-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg', 'PMIX_SERVER_URI21': '2694709248.1;tcp4://127.0.0.1:33499', 'SM_LOG_LEVEL': '20', 'SM_DISTRIBUTION_INSTANCE_GROUPS': '[\"homogeneousCluster\"]', 'PMIX_DSTORE_ESH_BASE_PATH': '/tmp/ompi.algo-2.0/jf.41118/pmix_dstor_ds12_128', 'USER': 'root', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_pytorch_ddp_enabled\":true},\"channel_input_dirs\":{\"data_path\":\"/opt/ml/input/data/data_path\"},\"current_host\":\"algo-2\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.p3.16xlarge\",\"distribution_hosts\":[\"algo-1\",\"algo-2\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"batch_size\":8},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"data_path\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}},\"is_hetero\":false,\"is_master\":false,\"is_modelpara', 'OMPI_MCA_plm': 'rsh', 'SM_CURRENT_INSTANCE_GROUP': 'homogeneousCluster', 'OMPI_MCA_orte_ess_num_procs': '16', 'OMPI_FILE_LOCATION': '/tmp/ompi.algo-2.0/jf.41118/0/1', 'PYTHONIOENCODING': 'UTF-8', 'OMPI_MCA_plm_rsh_no_tree_spawn': '1', 'OMPI_COMM_WORLD_SIZE': '16', 'OMPI_MCA_orte_ess_node_rank': '1', 'SHLVL': '4', 'SAGEMAKER_REGION': 'us-east-1', 'SMDATAPARALLEL_SERVER_PORT': '7592', 'NVARCH': 'x86_64', 'PMIX_ID': '2694709249.9', 'CUDNN_VERSION': '8.2.0.53', 'SMDATAPARALLEL_SERVER_ADDR': 'algo-1', 'OMPI_COMM_WORLD_LOCAL_SIZE': '8', 'EFA_VERSION': '1.15.1', 'PYTHONDONTWRITEBYTECODE': '1', 'NV_CUDA_COMPAT_PACKAGE': 'cuda-compat-11-3', 'PMIX_SERVER_TMPDIR': '/tmp/ompi.algo-2.0/jf.41118', 'SM_CURRENT_INSTANCE_GROUP_HOSTS': '[\"algo-1\",\"algo-2\"]', 'LD_LIBRARY_PATH': '/opt/amazon/openmpi/lib:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/amazon/openmpi/lib/:/opt/amazon/efa/lib/:/opt/conda/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64', 'NCCL_IB_DISABLE': '1', 'OMPI_COMMAND': 'smddprun', 'RANK': '9', 'OMPI_MCA_ess': '^singleton', 'OMPI_VERSION': '4.1.1', 'SSH_CLIENT': '10.2.236.66 51900 22', 'SM_FRAMEWORK_PARAMS': '{\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_pytorch_ddp_enabled\":true}', 'SM_MODULE_DIR': 's3://sagemaker-us-east-1-631450739534/pytorch-lightning-2022-08-16-04-40-37-950/source/sourcedir.tar.gz', 'PMIX_NAMESPACE': '2694709249', 'TRAINING_JOB_NAME': 'pytorch-lightning-2022-08-16-04-40-37-950', 'CURRENT_HOST': 'algo-2', 'LC_ALL': 'C.UTF-8', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:631450739534:training-job/pytorch-lightning-2022-08-16-04-40-37-950', 'SM_CHANNEL_DATA_PATH': '/opt/ml/input/\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:data/data_path', 'PATH': '/opt/amazon/openmpi/bin:/opt/amazon/openmpi/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'SM_USER_ARGS': '[\"--batch_size\",\"8\"]', 'OMPI_MCA_pmix': '^s1,s2,cray,isolated', 'OMPI_MCA_ess_base_jobid': '2694709249', 'OMPI_MCA_btl_tcp_if_include': 'eth0', 'SM_HPS': '{\"batch_size\":8}', 'OMPI_APP_CTX_NUM_PROCS': '16', 'SMDATAPARALLEL_USE_HOMOGENEOUS': '1', 'IPATH_NO_BACKTRACE': '1', 'OMPI_MCA_orte_top_session_dir': '/tmp/ompi.algo-2.0', 'OMPI_MCA_orte_launch': '1', 'SMDATAPARALLEL_NUM_CONN': '5', 'SM_MODEL_DIR': '/opt/ml/model', 'DLC_CONTAINER_TYPE': 'training', 'OMPI_COMM_WORLD_RANK': '9'})\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:Initializing distributed: GLOBAL_RANK: 15, MEMBER: 16/16\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:Initializing distributed: GLOBAL_RANK: 10, MEMBER: 11/16\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:Initializing distributed: GLOBAL_RANK: 8, MEMBER: 9/16\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:Initializing distributed: GLOBAL_RANK: 11, MEMBER: 12/16\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:Initializing distributed: GLOBAL_RANK: 14, MEMBER: 15/16\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:Initializing distributed: GLOBAL_RANK: 13, MEMBER: 14/16\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:Initializing distributed: GLOBAL_RANK: 12, MEMBER: 13/16\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:Initializing distributed: GLOBAL_RANK: 9, MEMBER: 10/16\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:distributed_backend=nccl\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:All distributed processes registered. Starting with 16 processes\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:Missing logger folder: /opt/ml/code/lightning_logs\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:Missing logger folder: /opt/ml/code/lightning_logs\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:Missing logger folder: /opt/ml/code/lightning_logs\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:Missing logger folder: /opt/ml/code/lightning_logs\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:Missing logger folder: /opt/ml/code/lightning_logs\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:Missing logger folder: /opt/ml/code/lightning_logs\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:Missing logger folder: /opt/ml/code/lightning_logs\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:Missing logger folder: /opt/ml/code/lightning_logs\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:Missing logger folder: /opt/ml/code/lightning_logs\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:Missing logger folder: /opt/ml/code/lightning_logs\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:Missing logger folder: /opt/ml/code/lightning_logs\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:Missing logger folder: /opt/ml/code/lightning_logs\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:Missing logger folder: /opt/ml/code/lightning_logs\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:Missing logger folder: /opt/ml/code/lightning_logs\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:Missing logger folder: /opt/ml/code/lightning_logs\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:Missing logger folder: /opt/ml/code/lightning_logs\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:666:666 [0] NCCL INFO Bootstrap : Using eth0:10.2.236.66<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:666:666 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:666:666 [0] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:666:666 [0] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:666:666 [0] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:666:666 [0] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:666:666 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:666:666 [0] NCCL INFO NET/Socket : Using [0]eth0:10.2.236.66<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:666:666 [0] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:NCCL version 2.10.3+cuda11.3\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:271:271 [6] NCCL INFO Bootstrap : Using eth0:10.2.236.66<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:200:200 [3] NCCL INFO Bootstrap : Using eth0:10.2.236.66<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:202:202 [7] NCCL INFO Bootstrap : Using eth0:10.2.236.66<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:270:270 [5] NCCL INFO Bootstrap : Using eth0:10.2.236.66<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:196:196 [4] NCCL INFO Bootstrap : Using eth0:10.2.236.66<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Bootstrap : Using eth0:10.2.236.66<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:269:269 [2] NCCL INFO Bootstrap : Using eth0:10.2.236.66<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:200:200 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:200:200 [3] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:200:200 [3] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:202:202 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:202:202 [7] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:270:270 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:270:270 [5] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:270:270 [5] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:269:269 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:269:269 [2] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:269:269 [2] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:271:271 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:271:271 [6] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:196:196 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:196:196 [4] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:202:202 [7] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:271:271 [6] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:196:196 [4] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:204:204 [7] NCCL INFO Bootstrap : Using eth0:10.2.242.254<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:202:202 [1] NCCL INFO Bootstrap : Using eth0:10.2.242.254<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:275:275 [6] NCCL INFO Bootstrap : Using eth0:10.2.242.254<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:672:672 [0] NCCL INFO Bootstrap : Using eth0:10.2.242.254<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:270:270 [2] NCCL INFO Bootstrap : Using eth0:10.2.242.254<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:271:271 [5] NCCL INFO Bootstrap : Using eth0:10.2.242.254<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:276:276 [4] NCCL INFO Bootstrap : Using eth0:10.2.242.254<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:277:277 [3] NCCL INFO Bootstrap : Using eth0:10.2.242.254<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:204:204 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:204:204 [7] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:204:204 [7] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:202:202 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:202:202 [1] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:202:202 [1] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:271:271 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:271:271 [5] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:271:271 [5] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:275:275 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:275:275 [6] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:275:275 [6] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:276:276 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:276:276 [4] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:276:276 [4] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:270:270 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:270:270 [2] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:270:270 [2] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:277:277 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:672:672 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:672:672 [0] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:277:277 [3] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:672:672 [0] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:277:277 [3] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:200:200 [3] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:200:200 [3] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:270:270 [5] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:270:270 [5] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:200:200 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:270:270 [5] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:200:200 [3] NCCL INFO NET/Socket : Using [0]eth0:10.2.236.66<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:200:200 [3] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:269:269 [2] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:269:269 [2] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:270:270 [5] NCCL INFO NET/Socket : Using [0]eth0:10.2.236.66<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:270:270 [5] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:269:269 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO NET/Socket : Using [0]eth0:10.2.236.66<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:269:269 [2] NCCL INFO NET/Socket : Using [0]eth0:10.2.236.66<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:269:269 [2] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:196:196 [4] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:196:196 [4] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:196:196 [4] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:202:202 [7] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:202:202 [7] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:196:196 [4] NCCL INFO NET/Socket : Using [0]eth0:10.2.236.66<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:196:196 [4] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:202:202 [7] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:271:271 [6] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:271:271 [6] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:202:202 [7] NCCL INFO NET/Socket : Using [0]eth0:10.2.236.66<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:202:202 [7] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:271:271 [6] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:271:271 [6] NCCL INFO NET/Socket : Using [0]eth0:10.2.236.66<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:271:271 [6] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:270:270 [2] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:270:270 [2] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:204:204 [7] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:204:204 [7] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:202:202 [1] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:202:202 [1] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:271:271 [5] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:271:271 [5] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:275:275 [6] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:275:275 [6] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:672:672 [0] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:672:672 [0] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:276:276 [4] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:276:276 [4] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:277:277 [3] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:277:277 [3] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:270:270 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:204:204 [7] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:271:271 [5] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:672:672 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:277:277 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:276:276 [4] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:202:202 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:275:275 [6] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:672:672 [0] NCCL INFO NET/Socket : Using [0]eth0:10.2.242.254<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:672:672 [0] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:204:204 [7] NCCL INFO NET/Socket : Using [0]eth0:10.2.242.254<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:277:277 [3] NCCL INFO NET/Socket : Using [0]eth0:10.2.242.254<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:277:277 [3] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:270:270 [2] NCCL INFO NET/Socket : Using [0]eth0:10.2.242.254<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:270:270 [2] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:276:276 [4] NCCL INFO NET/Socket : Using [0]eth0:10.2.242.254<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:276:276 [4] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:202:202 [1] NCCL INFO NET/Socket : Using [0]eth0:10.2.242.254<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:202:202 [1] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:271:271 [5] NCCL INFO NET/Socket : Using [0]eth0:10.2.242.254<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:271:271 [5] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:204:204 [7] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:275:275 [6] NCCL INFO NET/Socket : Using [0]eth0:10.2.242.254<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:275:275 [6] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:202:819 [7] NCCL INFO Trees [0] 4/-1/-1->7->6 [1] 4/-1/-1->7->6\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:271:820 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:200:814 [3] NCCL INFO Trees [0] 2/-1/-1->3->0 [1] 2/-1/-1->3->0\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:269:816 [2] NCCL INFO Trees [0] 1/-1/-1->2->3 [1] 1/-1/-1->2->3\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:666:813 [0] NCCL INFO Channel 00/02 :    0   3   2   1   5   6   7   4   8  11  10   9  13  14  15  12\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:666:813 [0] NCCL INFO Channel 01/02 :    0   3   2   1   5   6   7   4   8  11  10   9  13  14  15  12\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:666:813 [0] NCCL INFO Trees [0] 3/8/-1->0->-1 [1] 3/-1/-1->0->8\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:817 [1] NCCL INFO Trees [0] 5/-1/-1->1->2 [1] 5/-1/-1->1->2\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:196:818 [4] NCCL INFO Trees [0] -1/-1/-1->4->7 [1] -1/-1/-1->4->7\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:270:815 [5] NCCL INFO Trees [0] 6/-1/-1->5->1 [1] 6/-1/-1->5->1\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:271:821 [5] NCCL INFO Trees [0] 14/-1/-1->13->9 [1] 14/-1/-1->13->9\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:204:818 [7] NCCL INFO Trees [0] 12/-1/-1->15->14 [1] 12/-1/-1->15->14\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:277:820 [3] NCCL INFO Trees [0] 10/-1/-1->11->8 [1] 10/-1/-1->11->8\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:270:819 [2] NCCL INFO Trees [0] 9/-1/-1->10->11 [1] 9/-1/-1->10->11\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:672:817 [0] NCCL INFO Trees [0] 11/-1/-1->8->0 [1] 11/0/-1->8->-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:276:822 [4] NCCL INFO Trees [0] -1/-1/-1->12->15 [1] -1/-1/-1->12->15\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:202:823 [1] NCCL INFO Trees [0] 13/-1/-1->9->10 [1] 13/-1/-1->9->10\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:275:824 [6] NCCL INFO Trees [0] 15/-1/-1->14->13 [1] 15/-1/-1->14->13\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:202:823 [1] NCCL INFO Channel 00 : 9[180] -> 13[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:817 [1] NCCL INFO Channel 00 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:270:815 [5] NCCL INFO Channel 00 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:666:813 [0] NCCL INFO Channel 00 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:672:817 [0] NCCL INFO Channel 00 : 8[170] -> 11[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:202:823 [1] NCCL INFO Channel 01 : 9[180] -> 13[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:271:821 [5] NCCL INFO Channel 00 : 13[1c0] -> 14[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:271:820 [6] NCCL INFO Channel 00 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:270:815 [5] NCCL INFO Channel 01 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:817 [1] NCCL INFO Channel 01 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:666:813 [0] NCCL INFO Channel 01 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:672:817 [0] NCCL INFO Channel 01 : 8[170] -> 11[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:271:820 [6] NCCL INFO Channel 01 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:196:818 [4] NCCL INFO Channel 00 : 4[1b0] -> 8[170] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:271:821 [5] NCCL INFO Channel 01 : 13[1c0] -> 14[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:276:822 [4] NCCL INFO Channel 00 : 12[1b0] -> 0[170] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:269:816 [2] NCCL INFO Channel 00 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:270:819 [2] NCCL INFO Channel 00 : 10[190] -> 9[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:275:824 [6] NCCL INFO Channel 00 : 14[1d0] -> 15[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:270:819 [2] NCCL INFO Channel 01 : 10[190] -> 9[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:275:824 [6] NCCL INFO Channel 01 : 14[1d0] -> 15[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:277:820 [3] NCCL INFO Channel 00 : 11[1a0] -> 10[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:269:816 [2] NCCL INFO Channel 01 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:277:820 [3] NCCL INFO Channel 01 : 11[1a0] -> 10[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:200:814 [3] NCCL INFO Channel 00 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:196:818 [4] NCCL INFO Channel 01 : 4[1b0] -> 8[170] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:276:822 [4] NCCL INFO Channel 01 : 12[1b0] -> 0[170] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:202:819 [7] NCCL INFO Channel 00 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:200:814 [3] NCCL INFO Channel 01 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:271:820 [6] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:204:818 [7] NCCL INFO Channel 00 : 15[1e0] -> 12[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:277:820 [3] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:202:819 [7] NCCL INFO Channel 01 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:666:813 [0] NCCL INFO Channel 00 : 12[1b0] -> 0[170] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:666:813 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:672:817 [0] NCCL INFO Channel 00 : 4[1b0] -> 8[170] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:275:824 [6] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:672:817 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:204:818 [7] NCCL INFO Channel 01 : 15[1e0] -> 12[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:200:814 [3] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:270:815 [5] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:270:815 [5] NCCL INFO Channel 00 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:271:821 [5] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:271:820 [6] NCCL INFO Channel 00 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:271:821 [5] NCCL INFO Channel 00 : 13[1c0] -> 9[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:275:824 [6] NCCL INFO Channel 00 : 14[1d0] -> 13[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:270:815 [5] NCCL INFO Channel 01 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:271:820 [6] NCCL INFO Channel 01 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:271:821 [5] NCCL INFO Channel 01 : 13[1c0] -> 9[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:275:824 [6] NCCL INFO Channel 01 : 14[1d0] -> 13[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:666:813 [0] NCCL INFO Channel 01 : 12[1b0] -> 0[170] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:666:813 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:817 [1] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:672:817 [0] NCCL INFO Channel 01 : 4[1b0] -> 8[170] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:672:817 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:817 [1] NCCL INFO Channel 00 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:202:823 [1] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:269:816 [2] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:817 [1] NCCL INFO Channel 01 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:202:823 [1] NCCL INFO Channel 00 : 9[180] -> 10[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:270:819 [2] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:202:823 [1] NCCL INFO Channel 01 : 9[180] -> 10[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:269:816 [2] NCCL INFO Channel 00 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:269:816 [2] NCCL INFO Channel 01 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:270:819 [2] NCCL INFO Channel 00 : 10[190] -> 11[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:270:819 [2] NCCL INFO Channel 01 : 10[190] -> 11[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:666:813 [0] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:672:817 [0] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:200:814 [3] NCCL INFO Channel 00 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:277:820 [3] NCCL INFO Channel 00 : 11[1a0] -> 8[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:269:816 [2] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:269:816 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:269:816 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:270:819 [2] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:270:819 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:270:819 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:200:814 [3] NCCL INFO Channel 01 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:277:820 [3] NCCL INFO Channel 01 : 11[1a0] -> 8[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:817 [1] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:817 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:817 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:276:822 [4] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:204:818 [7] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:202:823 [1] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:202:823 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:202:823 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:196:818 [4] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:202:819 [7] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:666:813 [0] NCCL INFO Channel 00 : 8[170] -> 0[170] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:672:817 [0] NCCL INFO Channel 00 : 0[170] -> 8[170] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:666:813 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:672:817 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:276:822 [4] NCCL INFO Channel 00 : 12[1b0] -> 15[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:196:818 [4] NCCL INFO Channel 00 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:269:816 [2] NCCL INFO Channel 00 : 2[190] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:276:822 [4] NCCL INFO Channel 01 : 12[1b0] -> 15[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:196:818 [4] NCCL INFO Channel 01 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:276:822 [4] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:276:822 [4] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:276:822 [4] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:271:821 [5] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:271:821 [5] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:271:821 [5] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:204:818 [7] NCCL INFO Channel 00 : 15[1e0] -> 14[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:270:815 [5] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:270:815 [5] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:270:815 [5] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:196:818 [4] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:196:818 [4] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:196:818 [4] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:204:818 [7] NCCL INFO Channel 01 : 15[1e0] -> 14[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:202:819 [7] NCCL INFO Channel 00 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:202:819 [7] NCCL INFO Channel 01 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:204:818 [7] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:204:818 [7] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:204:818 [7] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:270:819 [2] NCCL INFO Channel 00 : 10[190] -> 12[1b0] via P2P/indirect/8[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:672:817 [0] NCCL INFO Channel 01 : 0[170] -> 8[170] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:672:817 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:666:813 [0] NCCL INFO Channel 01 : 8[170] -> 0[170] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:275:824 [6] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:275:824 [6] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:202:819 [7] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:666:813 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:275:824 [6] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:202:819 [7] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:202:819 [7] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:202:823 [1] NCCL INFO Channel 01 : 9[180] -> 12[1b0] via P2P/indirect/8[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:817 [1] NCCL INFO Channel 01 : 1[180] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:271:820 [6] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:271:820 [6] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:271:820 [6] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:672:817 [0] NCCL INFO Channel 00 : 8[170] -> 0[170] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:666:813 [0] NCCL INFO Channel 00 : 0[170] -> 8[170] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:672:817 [0] NCCL INFO Channel 01 : 8[170] -> 0[170] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:666:813 [0] NCCL INFO Channel 01 : 0[170] -> 8[170] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:672:817 [0] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:672:817 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:672:817 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:277:820 [3] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:277:820 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:666:813 [0] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:277:820 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:666:813 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:666:813 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:200:814 [3] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:200:814 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:200:814 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:672:817 [0] NCCL INFO Channel 01 : 8[170] -> 13[1c0] via P2P/indirect/9[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:666:813 [0] NCCL INFO Channel 01 : 0[170] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:200:814 [3] NCCL INFO Channel 01 : 3[1a0] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:277:820 [3] NCCL INFO Channel 01 : 11[1a0] -> 12[1b0] via P2P/indirect/8[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:200:814 [3] NCCL INFO Channel 00 : 3[1a0] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:277:820 [3] NCCL INFO Channel 00 : 11[1a0] -> 13[1c0] via P2P/indirect/9[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:270:819 [2] NCCL INFO Channel 01 : 10[190] -> 13[1c0] via P2P/indirect/9[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:277:820 [3] NCCL INFO Channel 01 : 11[1a0] -> 14[1d0] via P2P/indirect/15[1e0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:200:814 [3] NCCL INFO Channel 01 : 3[1a0] -> 6[1d0] via P2P/indirect/7[1e0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:269:816 [2] NCCL INFO Channel 01 : 2[190] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:276:822 [4] NCCL INFO Channel 01 : 12[1b0] -> 9[180] via P2P/indirect/13[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:202:823 [1] NCCL INFO Channel 01 : 9[180] -> 14[1d0] via P2P/indirect/13[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:196:818 [4] NCCL INFO Channel 01 : 4[1b0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:269:816 [2] NCCL INFO Channel 01 : 2[190] -> 7[1e0] via P2P/indirect/6[1d0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:270:819 [2] NCCL INFO Channel 01 : 10[190] -> 15[1e0] via P2P/indirect/14[1d0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:817 [1] NCCL INFO Channel 01 : 1[180] -> 6[1d0] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:202:823 [1] NCCL INFO Channel 00 : 9[180] -> 15[1e0] via P2P/indirect/11[1a0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:817 [1] NCCL INFO Channel 00 : 1[180] -> 7[1e0] via P2P/indirect/3[1a0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:666:813 [0] NCCL INFO Channel 00 : 0[170] -> 6[1d0] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:271:821 [5] NCCL INFO Channel 01 : 13[1c0] -> 8[170] via P2P/indirect/12[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:270:815 [5] NCCL INFO Channel 01 : 5[1c0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:672:817 [0] NCCL INFO Channel 00 : 8[170] -> 14[1d0] via P2P/indirect/12[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:672:817 [0] NCCL INFO Channel 01 : 8[170] -> 15[1e0] via P2P/indirect/12[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:271:820 [6] NCCL INFO Channel 00 : 6[1d0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:275:824 [6] NCCL INFO Channel 00 : 14[1d0] -> 8[170] via P2P/indirect/12[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:666:813 [0] NCCL INFO Channel 01 : 0[170] -> 7[1e0] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:204:818 [7] NCCL INFO Channel 01 : 15[1e0] -> 8[170] via P2P/indirect/12[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:202:819 [7] NCCL INFO Channel 01 : 7[1e0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:204:818 [7] NCCL INFO Channel 00 : 15[1e0] -> 9[180] via P2P/indirect/13[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:202:819 [7] NCCL INFO Channel 00 : 7[1e0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:204:818 [7] NCCL INFO Channel 01 : 15[1e0] -> 10[190] via P2P/indirect/11[1a0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:202:819 [7] NCCL INFO Channel 01 : 7[1e0] -> 2[190] via P2P/indirect/3[1a0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:271:820 [6] NCCL INFO Channel 01 : 6[1d0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:275:824 [6] NCCL INFO Channel 01 : 14[1d0] -> 9[180] via P2P/indirect/13[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:271:821 [5] NCCL INFO Channel 01 : 13[1c0] -> 10[190] via P2P/indirect/9[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:275:824 [6] NCCL INFO Channel 01 : 14[1d0] -> 11[1a0] via P2P/indirect/10[190]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:271:820 [6] NCCL INFO Channel 01 : 6[1d0] -> 3[1a0] via P2P/indirect/2[190]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:270:815 [5] NCCL INFO Channel 01 : 5[1c0] -> 2[190] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:271:821 [5] NCCL INFO Channel 00 : 13[1c0] -> 11[1a0] via P2P/indirect/9[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:276:822 [4] NCCL INFO Channel 00 : 12[1b0] -> 10[190] via P2P/indirect/14[1d0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:196:818 [4] NCCL INFO Channel 00 : 4[1b0] -> 2[190] via P2P/indirect/6[1d0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:270:815 [5] NCCL INFO Channel 00 : 5[1c0] -> 3[1a0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:276:822 [4] NCCL INFO Channel 01 : 12[1b0] -> 11[1a0] via P2P/indirect/8[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:196:818 [4] NCCL INFO Channel 01 : 4[1b0] -> 3[1a0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:202:823 [1] NCCL INFO comm 0x7fe694002fb0 rank 9 nranks 16 cudaDev 1 busId 180 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:204:818 [7] NCCL INFO comm 0x7f6abc002fb0 rank 15 nranks 16 cudaDev 7 busId 1e0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:271:821 [5] NCCL INFO comm 0x7fe508002fb0 rank 13 nranks 16 cudaDev 5 busId 1c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:672:817 [0] NCCL INFO comm 0x7f5bac002fb0 rank 8 nranks 16 cudaDev 0 busId 170 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:276:822 [4] NCCL INFO comm 0x7f7aac002fb0 rank 12 nranks 16 cudaDev 4 busId 1b0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:275:824 [6] NCCL INFO comm 0x7fd0dc002fb0 rank 14 nranks 16 cudaDev 6 busId 1d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:277:820 [3] NCCL INFO comm 0x7f47b0002fb0 rank 11 nranks 16 cudaDev 3 busId 1a0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:270:819 [2] NCCL INFO comm 0x7fa250002fb0 rank 10 nranks 16 cudaDev 2 busId 190 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:271:820 [6] NCCL INFO comm 0x7fa1c0002fb0 rank 6 nranks 16 cudaDev 6 busId 1d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:196:818 [4] NCCL INFO comm 0x7f6ee8002fb0 rank 4 nranks 16 cudaDev 4 busId 1b0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:202:819 [7] NCCL INFO comm 0x7f5e30002fb0 rank 7 nranks 16 cudaDev 7 busId 1e0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:817 [1] NCCL INFO comm 0x7f021c002fb0 rank 1 nranks 16 cudaDev 1 busId 180 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:270:815 [5] NCCL INFO comm 0x7f2ca8002fb0 rank 5 nranks 16 cudaDev 5 busId 1c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:269:816 [2] NCCL INFO comm 0x7f62c4002fb0 rank 2 nranks 16 cudaDev 2 busId 190 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:666:813 [0] NCCL INFO comm 0x7fbda4002fb0 rank 0 nranks 16 cudaDev 0 busId 170 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:200:814 [3] NCCL INFO comm 0x7f7ff8002fb0 rank 3 nranks 16 cudaDev 3 busId 1a0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:666:666 [0] NCCL INFO Launch mode Parallel\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:  | Name | Type | Params\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:------------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:0 | net  | UNet | 31.0 M\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:------------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:31.0 M    Trainable params\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:0         Non-trainable params\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:31.0 M    Total params\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:62.089    Total estimated model params size (MB)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Sanity Checking: 0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:  rank_zero_warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Sanity Checking:   0% 0/1 [00:00<?, ?it/s]#015Sanity Checking DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Sanity Checking DataLoader 0: 100% 1/1 [00:06<00:00,  6.07s/it]#015Sanity Checking DataLoader 0: 100% 1/1 [00:06<00:00,  6.07s/it]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:  rank_zero_warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1927: PossibleUserWarning: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:  rank_zero_warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Training: 0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Training:   0% 0/3 [00:00<?, ?it/s][1,mpirank:0,algo-1]<stdout>:#015Epoch 0:   0% 0/3 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 0:  33% 1/3 [00:12<00:25, 12.94s/it][1,mpirank:0,algo-1]<stdout>:#015Epoch 0:  33% 1/3 [00:12<00:25, 12.94s/it]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 0:  33% 1/3 [00:12<00:25, 12.94s/it, loss=2.92, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 0:  67% 2/3 [00:17<00:08,  8.84s/it, loss=2.92, v_num=0]#015Epoch 0:  67% 2/3 [00:17<00:08,  8.84s/it, loss=2.92, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 0:  67% 2/3 [00:17<00:08,  8.84s/it, loss=2.62, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation: 0it [00:00, ?it/s][1,mpirank:0,algo-1]<stdout>:#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation:   0% 0/1 [00:00<?, ?it/s]#033[A[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation DataLoader 0: 100% 1/1 [00:00<00:00, 37.58it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 0: 100% 3/3 [00:17<00:00,  5.95s/it, loss=2.62, v_num=0][1,mpirank:0,algo-1]<stdout>:#015Epoch 0: 100% 3/3 [00:17<00:00,  5.95s/it, loss=2.62, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 0: 100% 3/3 [00:17<00:00,  5.96s/it, loss=2.62, v_num=0][1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015                                                          [1,mpirank:0,algo-1]<stdout>:#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 0: 100% 3/3 [00:17<00:00,  5.96s/it, loss=2.62, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 0:   0% 0/3 [00:00<?, ?it/s, loss=2.62, v_num=0]        [1,mpirank:0,algo-1]<stdout>:#015Epoch 1:   0% 0/3 [00:00<?, ?it/s, loss=2.62, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 1:  33% 1/3 [00:00<00:01,  1.36it/s, loss=2.62, v_num=0][1,mpirank:0,algo-1]<stdout>:#015Epoch 1:  33% 1/3 [00:00<00:01,  1.36it/s, loss=2.62, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 1:  33% 1/3 [00:00<00:01,  1.36it/s, loss=2.43, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 1:  67% 2/3 [00:00<00:00,  2.01it/s, loss=2.43, v_num=0]#015Epoch 1:  67% 2/3 [00:00<00:00,  2.01it/s, loss=2.43, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 1:  67% 2/3 [00:00<00:00,  2.00it/s, loss=2.41, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation:   0% 0/1 [00:00<?, ?it/s][1,mpirank:0,algo-1]<stdout>:#033[A[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation DataLoader 0: 100% 1/1 [00:00<00:00, 94.79it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 1: 100% 3/3 [00:01<00:00,  2.65it/s, loss=2.41, v_num=0][1,mpirank:0,algo-1]<stdout>:#015Epoch 1: 100% 3/3 [00:01<00:00,  2.65it/s, loss=2.41, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 1: 100% 3/3 [00:01<00:00,  2.52it/s, loss=2.41, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015                                                          #033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 1: 100% 3/3 [00:01<00:00,  2.52it/s, loss=2.41, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 1:   0% 0/3 [00:00<?, ?it/s, loss=2.41, v_num=0]        #015Epoch 2:   0% 0/3 [00:00<?, ?it/s, loss=2.41, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 2:  33% 1/3 [00:00<00:01,  1.32it/s, loss=2.41, v_num=0][1,mpirank:0,algo-1]<stdout>:#015Epoch 2:  33% 1/3 [00:00<00:01,  1.32it/s, loss=2.41, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 2:  33% 1/3 [00:00<00:01,  1.32it/s, loss=2.36, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 2:  67% 2/3 [00:01<00:00,  1.97it/s, loss=2.36, v_num=0]#015Epoch 2:  67% 2/3 [00:01<00:00,  1.97it/s, loss=2.36, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 2:  67% 2/3 [00:01<00:00,  1.96it/s, loss=2.26, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation:   0% 0/1 [00:00<?, ?it/s]#033[A[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation DataLoader 0: 100% 1/1 [00:00<00:00, 93.82it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 2: 100% 3/3 [00:01<00:00,  2.60it/s, loss=2.26, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 2: 100% 3/3 [00:01<00:00,  2.60it/s, loss=2.26, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 2: 100% 3/3 [00:01<00:00,  2.48it/s, loss=2.26, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015                                                          [1,mpirank:0,algo-1]<stdout>:#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 2: 100% 3/3 [00:01<00:00,  2.48it/s, loss=2.26, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 2:   0% 0/3 [00:00<?, ?it/s, loss=2.26, v_num=0]        #015Epoch 3:   0% 0/3 [00:00<?, ?it/s, loss=2.26, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 3:  33% 1/3 [00:00<00:01,  1.34it/s, loss=2.26, v_num=0]#015Epoch 3:  33% 1/3 [00:00<00:01,  1.34it/s, loss=2.26, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 3:  33% 1/3 [00:00<00:01,  1.34it/s, loss=2.17, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 3:  67% 2/3 [00:01<00:00,  1.99it/s, loss=2.17, v_num=0]#015Epoch 3:  67% 2/3 [00:01<00:00,  1.99it/s, loss=2.17, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 3:  67% 2/3 [00:01<00:00,  1.99it/s, loss=2.15, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation:   0% 0/1 [00:00<?, ?it/s]#033[A[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation DataLoader 0: 100% 1/1 [00:00<00:00, 94.56it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 3: 100% 3/3 [00:01<00:00,  2.62it/s, loss=2.15, v_num=0][1,mpirank:0,algo-1]<stdout>:#015Epoch 3: 100% 3/3 [00:01<00:00,  2.62it/s, loss=2.15, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 3: 100% 3/3 [00:01<00:00,  2.51it/s, loss=2.15, v_num=0][1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015                                                          [1,mpirank:0,algo-1]<stdout>:#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 3: 100% 3/3 [00:01<00:00,  2.50it/s, loss=2.15, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 3:   0% 0/3 [00:00<?, ?it/s, loss=2.15, v_num=0]        #015Epoch 4:   0% 0/3 [00:00<?, ?it/s, loss=2.15, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 4:  33% 1/3 [00:00<00:01,  1.36it/s, loss=2.15, v_num=0]#015Epoch 4:  33% 1/3 [00:00<00:01,  1.36it/s, loss=2.15, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 4:  33% 1/3 [00:00<00:01,  1.36it/s, loss=2.11, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 4:  67% 2/3 [00:01<00:00,  1.98it/s, loss=2.11, v_num=0][1,mpirank:0,algo-1]<stdout>:#015Epoch 4:  67% 2/3 [00:01<00:00,  1.98it/s, loss=2.11, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 4:  67% 2/3 [00:01<00:00,  1.98it/s, loss=2.09, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation:   0% 0/1 [00:00<?, ?it/s]#033[A[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation DataLoader 0: 100% 1/1 [00:00<00:00, 93.31it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 4: 100% 3/3 [00:01<00:00,  2.62it/s, loss=2.09, v_num=0][1,mpirank:0,algo-1]<stdout>:#015Epoch 4: 100% 3/3 [00:01<00:00,  2.62it/s, loss=2.09, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 4: 100% 3/3 [00:01<00:00,  2.49it/s, loss=2.09, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015                                                          [1,mpirank:0,algo-1]<stdout>:#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 4: 100% 3/3 [00:01<00:00,  2.49it/s, loss=2.09, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 4:   0% 0/3 [00:00<?, ?it/s, loss=2.09, v_num=0]        [1,mpirank:0,algo-1]<stdout>:#015Epoch 5:   0% 0/3 [00:00<?, ?it/s, loss=2.09, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 5:  33% 1/3 [00:00<00:01,  1.33it/s, loss=2.09, v_num=0][1,mpirank:0,algo-1]<stdout>:#015Epoch 5:  33% 1/3 [00:00<00:01,  1.33it/s, loss=2.09, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 5:  33% 1/3 [00:00<00:01,  1.32it/s, loss=2.05, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 5:  67% 2/3 [00:01<00:00,  1.96it/s, loss=2.05, v_num=0][1,mpirank:0,algo-1]<stdout>:#015Epoch 5:  67% 2/3 [00:01<00:00,  1.96it/s, loss=2.05, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 5:  67% 2/3 [00:01<00:00,  1.96it/s, loss=2, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation:   0% 0/1 [00:00<?, ?it/s]#033[A[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation DataLoader 0: 100% 1/1 [00:00<00:00, 93.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 5: 100% 3/3 [00:01<00:00,  2.59it/s, loss=2, v_num=0][1,mpirank:0,algo-1]<stdout>:#015Epoch 5: 100% 3/3 [00:01<00:00,  2.59it/s, loss=2, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 5: 100% 3/3 [00:01<00:00,  2.48it/s, loss=2, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015                                                          #033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 5: 100% 3/3 [00:01<00:00,  2.47it/s, loss=2, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 5:   0% 0/3 [00:00<?, ?it/s, loss=2, v_num=0]        #015Epoch 6:   0% 0/3 [00:00<?, ?it/s, loss=2, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 6:  33% 1/3 [00:00<00:01,  1.31it/s, loss=2, v_num=0]#015Epoch 6:  33% 1/3 [00:00<00:01,  1.31it/s, loss=2, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 6:  33% 1/3 [00:00<00:01,  1.31it/s, loss=1.97, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 6:  67% 2/3 [00:01<00:00,  1.93it/s, loss=1.97, v_num=0][1,mpirank:0,algo-1]<stdout>:#015Epoch 6:  67% 2/3 [00:01<00:00,  1.92it/s, loss=1.97, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 6:  67% 2/3 [00:01<00:00,  1.92it/s, loss=1.97, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation:   0% 0/1 [00:00<?, ?it/s]#033[A[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation DataLoader 0: 100% 1/1 [00:00<00:00, 90.41it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 6: 100% 3/3 [00:01<00:00,  2.49it/s, loss=1.97, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 6: 100% 3/3 [00:01<00:00,  2.49it/s, loss=1.97, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 6: 100% 3/3 [00:01<00:00,  2.40it/s, loss=1.97, v_num=0][1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015                                                          #033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 6: 100% 3/3 [00:01<00:00,  2.39it/s, loss=1.97, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 6:   0% 0/3 [00:00<?, ?it/s, loss=1.97, v_num=0]        [1,mpirank:0,algo-1]<stdout>:#015Epoch 7:   0% 0/3 [00:00<?, ?it/s, loss=1.97, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 7:  33% 1/3 [00:00<00:01,  1.34it/s, loss=1.97, v_num=0][1,mpirank:0,algo-1]<stdout>:#015Epoch 7:  33% 1/3 [00:00<00:01,  1.34it/s, loss=1.97, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 7:  33% 1/3 [00:00<00:01,  1.34it/s, loss=1.94, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 7:  67% 2/3 [00:01<00:00,  1.98it/s, loss=1.94, v_num=0]#015Epoch 7:  67% 2/3 [00:01<00:00,  1.98it/s, loss=1.94, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 7:  67% 2/3 [00:01<00:00,  1.98it/s, loss=1.93, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation:   0% 0/1 [00:00<?, ?it/s]#033[A[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation DataLoader 0: 100% 1/1 [00:00<00:00, 93.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 7: 100% 3/3 [00:01<00:00,  2.62it/s, loss=1.93, v_num=0][1,mpirank:0,algo-1]<stdout>:#015Epoch 7: 100% 3/3 [00:01<00:00,  2.62it/s, loss=1.93, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 7: 100% 3/3 [00:01<00:00,  2.50it/s, loss=1.93, v_num=0][1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015                                                          [1,mpirank:0,algo-1]<stdout>:#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 7: 100% 3/3 [00:01<00:00,  2.49it/s, loss=1.93, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 7:   0% 0/3 [00:00<?, ?it/s, loss=1.93, v_num=0]        #015Epoch 8:   0% 0/3 [00:00<?, ?it/s, loss=1.93, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 8:  33% 1/3 [00:00<00:01,  1.35it/s, loss=1.93, v_num=0]#015Epoch 8:  33% 1/3 [00:00<00:01,  1.35it/s, loss=1.93, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 8:  33% 1/3 [00:00<00:01,  1.35it/s, loss=1.9, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 8:  67% 2/3 [00:00<00:00,  2.02it/s, loss=1.9, v_num=0][1,mpirank:0,algo-1]<stdout>:#015Epoch 8:  67% 2/3 [00:00<00:00,  2.02it/s, loss=1.9, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 8:  67% 2/3 [00:00<00:00,  2.02it/s, loss=1.9, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation:   0% 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation DataLoader 0: 100% 1/1 [00:00<00:00, 95.15it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 8: 100% 3/3 [00:01<00:00,  2.66it/s, loss=1.9, v_num=0][1,mpirank:0,algo-1]<stdout>:#015Epoch 8: 100% 3/3 [00:01<00:00,  2.66it/s, loss=1.9, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 8: 100% 3/3 [00:01<00:00,  2.55it/s, loss=1.9, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015                                                          #033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 8: 100% 3/3 [00:01<00:00,  2.55it/s, loss=1.9, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 8:   0% 0/3 [00:00<?, ?it/s, loss=1.9, v_num=0]        #015Epoch 9:   0% 0/3 [00:00<?, ?it/s, loss=1.9, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 9:  33% 1/3 [00:00<00:01,  1.36it/s, loss=1.9, v_num=0][1,mpirank:0,algo-1]<stdout>:#015Epoch 9:  33% 1/3 [00:00<00:01,  1.36it/s, loss=1.9, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 9:  33% 1/3 [00:00<00:01,  1.36it/s, loss=1.87, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 9:  67% 2/3 [00:00<00:00,  2.00it/s, loss=1.87, v_num=0][1,mpirank:0,algo-1]<stdout>:#015Epoch 9:  67% 2/3 [00:00<00:00,  2.00it/s, loss=1.87, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 9:  67% 2/3 [00:00<00:00,  2.00it/s, loss=1.88, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation:   0% 0/1 [00:00<?, ?it/s]#033[A[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation DataLoader 0: 100% 1/1 [00:00<00:00, 92.80it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 9: 100% 3/3 [00:01<00:00,  2.64it/s, loss=1.88, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 9: 100% 3/3 [00:01<00:00,  2.64it/s, loss=1.88, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 9: 100% 3/3 [00:01<00:00,  2.53it/s, loss=1.88, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015                                                          #033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 9: 100% 3/3 [00:01<00:00,  2.52it/s, loss=1.88, v_num=0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 9: 100% 3/3 [00:02<00:00,  1.37it/s, loss=1.88, v_num=0]\u001b[0m\n",
      "\u001b[34m2022-08-16 04:49:15,103 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2022-08-16 04:49:15,103 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2022-08-16 04:49:15,103 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\u001b[35m2022-08-16 04:49:15,101 sagemaker-training-toolkit INFO     Orted process exited\u001b[0m\n",
      "\u001b[35m2022-08-16 04:49:45,131 sagemaker-training-toolkit INFO     MPI process finished.\u001b[0m\n",
      "\u001b[35m2022-08-16 04:49:45,132 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2022-08-16 04:50:13 Uploading - Uploading generated training model\n",
      "2022-08-16 04:50:13 Completed - Training job completed\n",
      "Training seconds: 828\n",
      "Billable seconds: 828\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {\"batch_size\": 8}\n",
    "enable_local_mode_training = False\n",
    "\n",
    "if enable_local_mode_training:\n",
    "    train_instance_type = \"local_gpu\"\n",
    "    inputs = {\"data_path\": f\"file:///home/ec2-user/SageMaker/amazon-sagemaker-pytorch-lightning-distributed-training/data_semantics\"}\n",
    "else:\n",
    "    train_instance_type = \"ml.p3.16xlarge\"\n",
    "    inputs = {\"data_path\": data_url}\n",
    "    \n",
    "\n",
    "estimator_parameters = {\n",
    "    \"entry_point\": \"semantic_segmentation.py\",\n",
    "    \"source_dir\": \"code\",\n",
    "    \"instance_type\": train_instance_type,\n",
    "    \"instance_count\": 2,\n",
    "    \"hyperparameters\": hyperparameters,\n",
    "    \"role\": role,\n",
    "    \"base_job_name\": \"pytorch-lightning\",\n",
    "    \"image_uri\": \"570106654206.dkr.ecr.us-east-1.amazonaws.com/pt-ddp-custom:1.12.0-gpu-py38-cu113-ubuntu20.04-sagemaker-2.6.0-numproc\",\n",
    "    \"py_version\": \"py3\",\n",
    "    \"distribution\": {\"pytorchddp\":{\"enabled\": True}},\n",
    "    \"debugger_hook_config\": False\n",
    "}\n",
    "\n",
    "estimator = PyTorch(**estimator_parameters)\n",
    "estimator.fit(inputs)#, wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b08f66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
